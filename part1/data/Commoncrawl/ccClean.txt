download pdf robot proof higher education in the age of artificial intelligence by joseph e aoun epub pdf link https kindleuploadsale icu q robot proof a higher education in the age of artificial intelligence read online pdf robot proof higher education in the age of artificial intelligence download pdf robot proof higher education in the age of artificial intelligence download full pdf robot proof higher education in the age of artificial intelligence download pdf and epub robot proof higher education in the age of artificial intelligence read pdf epub mobi robot proof higher education in the age of artificial intelligence reading pdf robot proof higher education in the age of artificial intelligence read book pdf robot proof higher education in the age of artificial intelligence read online robot proof higher education in the age of artificial intelligence download robot proof higher education in the age of artificial intelligence joseph e aoun pdf download joseph e aoun epub robot proof higher education in the age of artificial intelligence read pdf joseph e aoun robot proof higher education in the age of artificial intelligence download joseph e aoun ebook robot proof higher education in the age of artificial intelligence read pdf robot proof higher education in the age of artificial intelligence robot proof higher education in the age of artificial intelligence online download best book online robot proof higher education in the age of artificial intelligence read online robot proof higher education in the age of artificial intelligence book read online robot proof higher education in the age of artificial intelligence e books read robot proof higher education in the age of artificial intelligence online read best book robot proof higher education in the age of artificial intelligence online read robot proof higher education in the age of artificial intelligence books online download robot proof higher education in the age of artificial intelligence full collection download robot proof higher education in the age of artificial intelligence book read robot proof higher education in the age of artificial intelligence ebook robot proof higher education in the age of artificial intelligence pdf read online robot proof higher education in the age of artificial intelligence pdf download online robot proof higher education in the age of artificial intelligence read download robot proof higher education in the age of artificial intelligence full pdf read robot proof higher education in the age of artificial intelligence pdf online read robot proof higher education in the age of artificial intelligence books online read robot proof higher education in the age of artificial intelligence full popular pdf pdf robot proof higher education in the age of artificial intelligence read book pdf robot proof higher education in the age of artificial intelligence read online pdf robot proof higher education in the age of artificial intelligence download best book robot proof higher education in the age of artificial intelligence read pdf robot proof higher education in the age of artificial intelligence collection read pdf robot proof higher education in the age of artificial intelligence full online read best book online robot proof higher education in the age of artificial intelligence download robot proof higher education in the age of artificial intelligence pdf files
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
in my last post about ai i briefly broke down a survey of artificial and machine learnings experts rather then doing forensics of the survey i started at the very top what is an expert
in that survey experts were asked for their probabilities that we would get ai that was able to accomplish every task better and more cheaply than human workers the experts thought on average there was a chance of this happening by and a chance of it happening by
they were also asked by what year for any occupation machines could be built to carry out the task better and more cheaply than human workers the experts thought on average that there was a chance of this happening by and a chance of it happening by
the survery authors point out these two questions are basically the same they were put in just to test if there was any framing effect the framing effect was apparently strong enough to shift the median date of strong human level ai from to this makes it hard to argue ai experts actually have a strong opinion on this
also these averages are deceptive several experts thought there was basically a chance of strong ai by others thought there was only a chance or less by this is less ai experts have spoken and it will happen in and more ai experts have spoken and everything they say contradicts each other and quite often themselves
the next thing we can take from this paper is a timeline of what will happen when the authors give a bunch of different tasks jobs and milestones and ask the researchers when ai will be able to complete them average answers range from nearly fifty years off for machines being able to do original high level mathematical research to only three years away for machines achieving the venerable accomplishment of being able to outperform humans at angry birds along the way they ll beat humans at poker four years writing high school essays ten years be able to outrun humans in a k foot race years and write a new york times bestseller years
artifical intelligence experts years of course
h t slate star codex
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
investor extreme salesman always interested sometimes interesting lurks at www adamtownsend me
artificial intelligence is the most fascinating topic of our time not only because of being an important topic but because of being the simplest among all important ones compare it with the question for instance of what happens when you enter a black hole this would require people to first get comfortable with the fact that its black because its gravity sucked all the light from around it
what you can suck light are you sure about that
of course not but that s what brian greene seems to be saying sometimes
the one about black holes is an important question but it s also a tough one to get your head around now compare it with the following question what would you do if you were faced with someone who could do everything that you can and that too better than you
nothing difficult to understand and an incredible amazement to connect with slowly this question gets everyone thinking and i dont need to give examples of the kind of thoughts that follow the answer often is a personal one for everyone
so almost everyone who has heard of artificial intelligence gets it and everybody wants to know with a sense of anticipation not enjoyed by any technology in the past are we there yet
most people believe we re not there okay but how far have we come and what part is left
foxconn removed workers from its factory in china and got robots to do their jobs but siri still hasn t got attracted to your warm personality and proposed to you in the voice of scarlett johansson there s a robot now that can build a brick house in days but the robot that predicts farts in a crowded metro and disengages them before the explosions is still nowhere to be found there is some disagreement as to what marks the arrival of ai for some people what matters is super intelligence and they have an easy way to detect it the onset of super intelligence would be marked by a singularity event what is a singularity fuck knows
no quite literally
singularity is supposed to be a point in time beyond which what happens is not known to anybody and possibly cannot be known to anybody before it actually happens it s a good time to bring attention back to our cute black holes we started with because they share the concept of singularity with artificial super intelligence the currently accepted answer to the question i posted in the beginning of this piece is exactly this
what happens when you enter a black hole fuck knows
so for this set of people we ve clearly not created ai yet but according to some of them we re not quite far here s a fancy name you can remember to feel closer to this group of people ray not fancy enough try weil kurzweil yup you guessed it james bond happens to be the kurz weil of the fiction world not that kurzweil s world is considered anywhere close to being realistic
on the other side is the group of people without much hope the girlfriends of the world for whom your love would never be enough oh your new car is nice but its not a jaguar trust me some critics don t sound very different when they dismiss every new development in ai as just another program and not real ai this kind of girlfriend effect is very common in the ai world although their term for it is more politically correct its called the ai effect
so although you might not have witnessed the wonderful or horrible things you ve been made to imagine there are changes taking place in the employment structure should we be anxious already should we worry about our jobs or our lives the terminator salvation or the matrix revolution
i ve delved into these questions for a long time now and have tried to answer some of the popular ones through the course of this article i have tried to compile the answers into an exhaustive account of the entire artificial intelligence landscape in other words the next time you come across anything regarding ai you would be able to place it in one of these buckets in your head it might not be a straightforward way of understanding things but it sure would help to resolve some of the mysteries surrounding ai lets start with the first mystery consciousness
whether you re deep into learning technology or can t even get your phone to stop misbehaving because you didn t know there s something called a reboot you do expect artificial intelligence to be able to think like humans this way you can have your most intimate conversations with it think samantha conversations that you might not be able to have with your closest friends because somehow you are assured that you won t get judged would you be bothered by what a machine thinks about you not as long as you know its a machine and that s the interesting part in the near future you might not know whether you re interacting with a machine or a human being the single important thing that people expect from ai is to be exactly like a human at least for sometime before it flashes past us on the evolutionary path in this pursuit the question of how the mind works or how consciousness works is among the toughest unsolved problems all the other pieces are relatively easier to take care of with consciousness the world doesn t even agree on how to define it yet
this brings us to the first important objective of the study of ai replicate human consciousness with a technology that is not biological reproduction a technology that we introduce ourselves at this point you should recollect all the initiatives in ai you are aware of and see which ones have this as their immediate objective i don t think deepmind falls in this category although they are the pioneers of intelligence research in the world search for consciousness is not one of their immediate goals you would be lucky to find such initiatives in popular press since they are mostly restricted to university labs or to some rare obscure companies what are these people trying should you care about this research how close are they to creating consciousness in the lab how do you go about creating something you don t even fully understand
i can t go in the details of this dimension given the restricted scope of this document but the idea is as follows we might not currently understand exactly what happens in the brain but we can crack open the skull and look at what lies inside we know what it looks like and what it s made of in other words we can observe the hardware of the brain so lets just recreate the hardware and switch it on and see what happens the trick seems smart and simple so why has it not been done till now people are trying but the hardware is just way too powerful
the works of stalwarts like hans moravec and lloyd watts place the estimate of the brains computing capacity at around cps computations per second what does that mean it simply means that the brain is always bustling with a lot of activity imagine you spot angelina jolie walking towards you and you decide something must be done the kind of activity it would require across the universe to transform you into brad pitt and make your shirt come off and finally make her fall for you in that one moment is a lot of activity the brain simply has more than that going on inside it at any point of time it takes super computers like ibm s blue gene l or watson to even come close to achieving that kind of computing power and to imagine that we carry all of that within the size of a football on our shoulders is really very humbling so its not easy and people are really throwing their weights behind their research to getting it done you can get a good account of the kind of research that is already underway in kurzweil s book the singularity is near you would be amazed here s an excerpt from an excerpt in his book
it may seem rash to expect fully intelligent machines in a few decades when the computers have barely matched insect mentality in a half century of development indeed for that reason many long time artificial intelligence researchers scoff at the suggestion and offer a few centuries as a more believable period
hans moravec when will computer hardware match the human brain
okay that doesn t sound very optimistic i promise the follow up lines to this one are full of optimism this is my way of urging you to go and pick up the book as of now it suffices to know that this pursuit is on in fact the community working in this field is off to the races and we might reach there soon
so what does this imply for a moment lets drift away and think of the possibilities that would entail this achievement in some ways this is nothing new we ve been creating consciousness at a rapid pace in the form of babies all around the world yet something is new and different about artificially created consciousness a good starting point for you to think about this would be to look at your laptop or phone and imagine if you yourself were trapped in there somewhere what would you do with all the hardware touch screen camera and wifi what would you do would you have the same kinds of aspirations you do today
would an artificial consciousness have the same emotions of happiness sorrow confidence or uncertainty as you do all these are important questions but the one we need to choose to go forward in this discussion is the following would the machine know the same set of things that you do or would it know much more once a machine gets conscious wouldn t it quickly find out everything there is to know and then become capable of doing everything possible my answer is no i have reasons to believe that it isn t possible to know about everything even for a machine at any time in the future
i get a feeling sometimes that when consciousness is first created i or someone with curiosities similar to mine would go to this machine and start asking questions where did you come from or what was it like there and it would say i have no clue mate i m so blanked out i feel like a vegetable
i call this the aisenberg uncertainty principle
its very simple we can never know everything
to some this might be obvious others need some light to appreciate the darkness
every time we ask a question we unknowingly make a transition to a state of not knowing something and we do that quite frequently the process starts with an encounter with one or more unknowns followed by the act of knowing and ends in the generation and sometimes storage of knowledge if i had to give you the most universal observation possible it would be this everything that you ve ever encountered or will ever do in the future is either known to you or is unknown here s the idea in the form of an equation for later recollection
the inspiration for using epsilon for uncertainty or unknowns comes from my engineering background we use epsilon for all things nasty error in measurement noise in data uncertainty in models with every initiative we say okay we ve done our best lets see how it turns out the lets see part is epsilon i am obsessed with it and can go on and on about it but would rather suggest that you learn about it from nassem nicholas taleb you ll instantly know what i m talking about here it s sufficient to know that epsilon represents things that we don t know about
this however has hardly ever been a limitation in fact its always a good starting point for any initiative to accept that there would be unknowns and often unexpected turn of events this and similar guidelines from over the centuries have been made part of what is called the scientific approach to problem solving or science in short we ve known it forever but can seldom follow it we are pre disposed due to evolution to think irrationally in ways that fly in the face of science that s not a bad thing because it has kept us alive till now and no its not simply a behavior aspect that we can correct if we go to some kind of rehab its part of our biology to be irrational and in our environment to reward it yet its important to appreciate the scientific approach because now we have at our disposal tools that are capable of scientific thinking moreover these tools don t have the biological limitations that we do more on this in the following section intriguingly titled computation
from the previous section we see that tomorrow if we have artificial consciousness it would still need to adhere to the aisenberg principle at least in its nascent state the machines would also have to deal with things they don t know about and learn about as they go forward so we ve found some common ground with the machines uncertainty in problem solving more generally speaking problem solving itself and while we might share this with the machines in the future its what we share among all of us today every thing that we do can be defined as an attempt at solving some problem from as trivial as sipping coffee solving the problem of transferring nutrition from a cup to our body to building a giga factory that produces half a million cars in a year god what a mad man
problem solving is more fundamental to our existence than intelligence is if we have to shift from human intelligence to a more broad understanding of it then a functional definition of intelligence would be the ability to solve existing problems and to identify new ones to solve
how does problem solving link with the aisenberg principle
a problem is always something we encounter in the real world and the solutions that we come up with always emerge from what we already know as we try solutions we run into the unknowns and gain a better understanding of the world thereby increasing our knowledge till we are finally able to get a solution to work after every such cycle we have an expanded knowledge base
convince yourself that all forms of artificial intelligence that exists today is about solving some problem siri is an attempt at solving the problem of controlling your phone through voice input a driverless car is a solution to the problem of being transported from one point to another the attempts described in the previous section solve the problem of replicating the hardware of the human mind
would it be right to generalize the study of human intelligence into the study of problem solving lets keep this up for debate in the mean time the following objective doesn t seem any less valuable than replicating human intelligence
create a general purpose problem solving framework or agent or entity that is capable of inducing any change imaginable possible and desirable this last one is optional
we are lucky in this respect since we already have an abstract set of ideas for general purpose problem solving the scientific framework science gives us the highest quality of knowledge that appears in the above mentioned equation i have to say high quality knowledge because some people like to use the word knowledge also for the figments of imagination generated from religious beliefs it lets us identify what exactly to look for in the realm of epsilon from among the unknowns by allowing for hypotheses after experimentation every time a hypothesis is proven right or wrong our knowledge base increases for centuries now we ve been growing the knowledge part of the equation at a tremendous pace and science has a crucial role to play in that
this is not to say that science is the only way forward the method has its limitations in fact many of the leaps and advancements in our knowledge have come from random accidents and bizarre co incidences but sooner or later every idea needs to churn through the scientific screening process to qualify as knowledge
the natural line of inquiry at this stage should have been to develop systems that can optimize problem solving using the available technology of the day within the ethos of science we observe the problem at hand build sufficient understanding to arrive at a solution then indulge in trial and error to successfully solve the problem whether it was deliberate or not we ended up developing a paradigm in which all these steps can be delegated to the machines for good or for bad enter machine learning
a common story among societies in which swimming pools are a relatively new entry is parents telling their kids how they learnt to swim by jumping into a deep well and ensuring that they don t drown machine learning works more or less the same way reinforcement learning works exactly in the same outrageous way lets take a minute to analyze what your who dares wins dad just threw at you
problem being addressed ensure no drowning
path to finding a solution trial and error to experience the water s response to different body movements to ultimately identify the configuration in which he doesn t drown
expanded knowledge base at the end of the endeavor the ability to swim in calm waters
its interesting to note that the knowledge thus collected is not always shareable or easily communicable after coming out of the water your dad may not have been able to instruct the next daredevil in line about the steps to follow during his first visit to the well however thrown in the water again your dad would be able to regain his swimming ability by himself this observation will come in handy just in a short while
machine learning refers to the idea of throwing a machine into a well and expecting it to learn how to swim just like your dad did additionally it involves adjusting your understanding by taking into account how the machine is different from your dad most contemporary machines don t have hands and legs for example while your dad relies on inputs he gets from the five senses of the human body the machine can perceive only digital data that s why ml is so often about data handling or data science similarly while your dad can react with body movements the machine can only react by throwing out more digital data and that s about it
ml in its current form is about a machine constantly taking in data and giving out data till it eventually learns to give out exactly that data which is required to solve the problem at hand
in the process the machine learns the transformation it needs to apply to the incoming data to get the desired output that s knowledge but it may not always be able to communicate how it arrives at the data being thrown out most traditional ml algorithms end up with a mathematical function of the input set if you can extract that function then the machine has done a good job of communicating its knowledge the deep learning algorithm on the other hand is not able to communicate exactly how it works its knowledge is not easily shareable
and that s how we ve managed to outsource so many steps of problem solving to the machine it starts with a problem engages in vigorous trial and error builds an understanding of the process and ends up with a solution
needless to say that the current ml infrastructure is extremely primitive as compared to our mind s problem solving ability but the way it has captured the underlying process is nothing short of miraculous
whether we outsource all steps of problem solving to the machines or keep some parts to ourselves is a matter of design depending upon the time s technological ability check out ibm s cognitive computing initiative for an example of a hybrid machine human approach ultimately both the machine and the mind rely on a very fundamental property the perception of change in their environment and i would like to close this section with a short discussion about this property
it took me a lot of twisted reasoning to finally zero in on the word computation the mind works in amazing ways i knew since the beginning that i wanted computation as the one word attribute for this set of ideas but for a long time i couldn t justify to myself why i would do that hence you might find it irritating how i ve wandered along divergent lines of expression here bear with me while i try to make it fall into place help me with a better description by providing some feedback
intelligence is about problem solving problem solving is about inducing some kind of change inducing change is a form of computation lastly imagining a change is another form of computation distributing apples among kids equally or imagining how you would distribute apples among kids equally would require you to carry out the same process in your head i like to refer to that underlying process as a computation machines do that too a machine s ability to detect a change from to and vice versa is a computation and that forms the basis for its ability to do everything else to is the most fundamental change that a machine is able to bring into effect and the rest builds on top of that
any more abstract exploration would throw us off the overall objective of this article so i would urge the people who want to find out what is it about machines that make them capable of developing intelligence to look into the theory of computation its serene
its true we do if you want to disagree head over to quora there s an entire discussion about it
what is it about ai that spooks people out we ve established two main things about it till now one that we are getting closer and closer to developing the ability to solve harder and harder problems that should be a good thing two we might some day be able to synthesize consciousness artificially and that should give us more knowledge about our own selves what could possibly be worrisome about either of the two developments or what is so difficult to understand that might be scaring people
there are two ways in which humans think via induction and via deduction induction is when we ve seen something in the past similar to what is being witnessed and we re able to generalize and say oh right i know this artificial consciousness has no precedence whatsoever that we can relate it to we genuinely know absolutely nothing about it
deduction is the lesser used way of thinking in which we piece together cause and effect and fill blanks is sequences of logical reasoning with respect to ai people like nick bostrom have been doing so for quite some time and their deductions are disturbing i like deductions too so i would like to present some in the following passage but i would try to keep them as non disturbing as possible
before that just to be clear not everyone is concerned kurzwell s camp is suspiciously optimistic about the future of ai while referring to it as singularity at the same time andrew ng maintains that the kind of fears being raised are way too far fetched and we don t have anything to worry about in our lifetime maybe we have nothing to worry about even about our great grand children s lifetimes but that is not sufficient ground to dismiss an idea as tim urban pointed out people dismiss fears regarding ai as too far away in the future but no one has been able to find any logical counter argument to prove that these fears point to implausible scenarios finally ideas have merits not just in their plausibility but also in how much they can fire your imagination so why not explore
a long time ago we figured that moving things around is way too inconvenient and we need to do something about it initially a plank on a couple of logs was not the perfect looking solution but it worked in some cases to help us move things around as time passed it ended up evolving into technology that now moves us around faster than we can ever move on our own feet trains go like km hr today you go like
fast forward to the present times we re struggling with making machines behave like us computer vision systems are barely able to identify objects from images using the deep learning algorithm this doesn t bother us because the technology is nowhere as good as we are but it doesn t take long for a technology to evolve a computer might not be able to recognize the breadth of objects that we can but it can definitely process what it sees much much faster have a look at this and you would have a better chance of winning against a train than competing with this camera with respect to speed
so we have a proven track record of outperforming ourselves with our creations whatever it is that we mechanize we would end up leaving ourselves far behind eventually we don t understand non linear dynamical systems very well its now widely accepted that we screw up with macro economic decisions because an economy is a complex adaptive system and we re bad with understanding those we are already trying to make the machines understand our world and they will end up outperforming us they would eventually have a much better understanding of our social dynamics than we do in some literature its a blog post i can be that vague it has been suggested that our intelligence might someday compare with machine intelligence just like a mouse s intelligence compares with our intelligence today how empowering
so machines have been surpassing us in the past and they will keep surpassing us in the future it is the question of consciousness that makes things tricky
human beings have a consciousness and are biologically programmed to ensure their survival when machines develop consciousness would they share this goal of self preservation we don t know
what if self preservation is not a matter of being programmed into the machine but turns out to be an emergent property of a complex consciousness somewhere life began as self replicating molecules emerging out of a complex system of interacting chemicals somewhere human consciousness emerged out of a complex system of animal species competing for survival what if the need for survival emerges out of a complex system of artificially conscious beings interacting with each other
to self preserve or not to self preserve
first lets assume that machines have no desire for self preservation here despite consciousness machines develop an important distinction from humans and give up on a critical ability making choices out of self interest self interest guides our decision making more than logic or rationality does it guides our actions and thus our experience and thus the knowledge that we have no two individuals share the exact same knowledge because no two individuals have had the exact same experiences
not only does self interest ensure different knowledge sets for every individual it also limits the amount of knowledge that we are able to share or communicate with other people this might be because a lot of underlying motivations or axioms on top of which we build the rest of our knowledge reside in the section of the mind called our sub conscious and we don t have a particularly good access to that region in general here again there are two possibilities the less exciting possibility is that the nature of consciousness may be such that its subconscious region would be hidden even from the machine in this case the machines would face the same limitation as we do in communicating with other machines the other possibility is that the machine has access to its entire consciousness and thus is able to communicate its entire knowledge base with other machines everything known to one machine is known to every other machine as well in a way there would be no boundaries between the consciousness of two machines you might be surrounded by different kinds of devices performing very different functions the one that irons your clothes will not be driving you around as well but behind their physical incarnations there would be a single consolidated consciousness that has visibility of all events that are being witnessed by each of those machines there s going to be a single ethereal presence all around you in everything that you interact with i don t know about you but to my mind this brings forward just one word the matrix
ok bye
next
now lets look at the other possibility the one in which the machines develop the objective of survival if every conscious machine has the survival instinct and needs to compete with other machines then it may suit them to not share all information among each other sparing us from the matrix this development could further branch out into two different possibilities in the first possibility the machines would think of themselves as separate from humans we might exist in the same ecosystem but they will be them and we would be us it would be like ordinary human beings living among super heroes and mutants all going about their daily business we may not hold a special place in a machine s heart it is ideas like these that start to scare people we get a sense of being dispensable
there is a way out to prevent this from happening and that constitutes the second possibility there might be a way that tomorrow even when an artificial consciousness arises and scales up its intelligence to become super human instead of that consciousness being separate and disconnected from human consciousness it could develop as an extension of human consciousness the machines then won t be separate from us instead as our consciousness evolves and expands into the domain of machines their capabilities would simply be extensions of our own capabilities extended consciousness might be a consumer product or it might end up being a step in our evolutionary path making us what many people like to call transhumans
so which of the above possibilities are going to turn into reality we don t know the answers to such questions yet and its possible that we might not know these answers in advance before consciousness is realized this is the first glimpse of the singularity that ray kurzweil often talks about
it s important to understand what differentiates these ideas from the ones discussed in the previous sections as long as you have an objective that you choose to achieve the ideas and initiatives you take fall in the category of problem solving everything you do to achieve human like consciousness artificially falls in the category of consciousness but when artificial consciousness decides to have its own set of problems to solve in the same environment in which we exist we end up in an ecosystem we can t yet describe this ecosystem should be the focus of these set of ideas and discussions it is difficult to find a sense of purpose in these ideas other than dealing with this super intelligence these conversations need to be not just technical but also philosophical
in conclusion i believe despite the uncertainty accompanying the singularity that there is nothing to suggest that machines in this era would violate the aisenberg principle their knowledge base would grow at a rapid pace but the machines would have their own set of uncertainties and unknowns to deal with if only the machines found a way to wipe out all the unknowns they would become the gods of the universe or the multiverse i don t know obviously
so how do you become a god this segment is primarily for the sake of completeness with respect to the aisenberg principle we ve maintained so far that any form of intelligence that exists in the future would experience things from its environment that it does not know about that epsilon would always be non zero while we do have a scientific basis for the quantum counterpart of this idea heisenberg s uncertainty principle i don t have sufficient scientific theory behind the general principle i ve been using here the aisenberg principle is a belief that i hold and as scientists we are often tempted to question beliefs including our own so in the unlikely event of the principle being violated in a seemingly non existent future there might exist an entity for which epsilon becomes zero in other words the intelligence that is able to achieve zero epsilon would know everything i personally don t get attracted towards thinking about this idea because it swiftly gets very mundane but i invite others who might think otherwise to express themselves here to produce something interesting i m always game for something interesting
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
bigger update the content of this article is now available as a full length video course that walks you through every step of the code you can take the course for free and access everything else on lynda com free for days if you sign up with this link
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in portugu s ti ng vi t or italiano
have you noticed that facebook has developed an uncanny ability to recognize your friends in your photographs in the old days facebook used to make you to tag your friends in photos by clicking on them and typing in their name now as soon as you upload a photo facebook tags everyone for you like magic
this technology is called face recognition facebook s algorithms are able to recognize your friends faces after they have been tagged only a few times it s pretty amazing technology facebook can recognize faces with accuracy which is pretty much as good as humans can do
let s learn how modern face recognition works but just recognizing your friends would be too easy we can push this tech to the limit to solve a more challenging problem telling will ferrell famous actor apart from chad smith famous rock musician
so far in part and we ve used machine learning to solve isolated problems that have only one step estimating the price of a house generating new data based on existing data and telling if an image contains a certain object all of those problems can be solved by choosing one machine learning algorithm feeding in data and getting the result
but face recognition is really a series of several related problems
as a human your brain is wired to do all of this automatically and instantly in fact humans are too good at recognizing faces and end up seeing faces in everyday objects
computers are not capable of this kind of high level generalization at least not yet so we have to teach them how to do each step in this process separately
we need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step in other words we will chain together several machine learning algorithms
let s tackle this problem one step at a time for each step we ll learn about a different machine learning algorithm i m not going to explain every single algorithm completely to keep this from turning into a book but you ll learn the main ideas behind each one and you ll learn how you can build your own facial recognition system in python using openface and dlib
the first step in our pipeline is face detection obviously we need to locate the faces in a photograph before we can try to tell them apart
if you ve used any camera in the last years you ve probably seen face detection in action
face detection is a great feature for cameras when the camera can automatically pick out faces it can make sure that all the faces are in focus before it takes the picture but we ll use it for a different purpose finding the areas of the image we want to pass on to the next step in our pipeline
face detection went mainstream in the early s when paul viola and michael jones invented a way to detect faces that was fast enough to run on cheap cameras however much more reliable solutions exist now we re going to use a method invented in called histogram of oriented gradients or just hog for short
to find faces in an image we ll start by making our image black and white because we don t need color data to find faces
then we ll look at every single pixel in our image one at a time for every single pixel we want to look at the pixels that directly surrounding it
our goal is to figure out how dark the current pixel is compared to the pixels directly surrounding it then we want to draw an arrow showing in which direction the image is getting darker
if you repeat that process for every single pixel in the image you end up with every pixel being replaced by an arrow these arrows are called gradients and they show the flow from light to dark across the entire image
this might seem like a random thing to do but there s a really good reason for replacing the pixels with gradients if we analyze pixels directly really dark images and really light images of the same person will have totally different pixel values but by only considering the direction that brightness changes both really dark images and really bright images will end up with the same exact representation that makes the problem a lot easier to solve
but saving the gradient for every single pixel gives us way too much detail we end up missing the forest for the trees it would be better if we could just see the basic flow of lightness darkness at a higher level so we could see the basic pattern of the image
to do this we ll break up the image into small squares of x pixels each in each square we ll count up how many gradients point in each major direction how many point up point up right point right etc then we ll replace that square in the image with the arrow directions that were the strongest
the end result is we turn the original image into a very simple representation that captures the basic structure of a face in a simple way
to find faces in this hog image all we have to do is find the part of our image that looks the most similar to a known hog pattern that was extracted from a bunch of other training faces
using this technique we can now easily find faces in any image
if you want to try this step out yourself using python and dlib here s code showing how to generate and view hog representations of images
whew we isolated the faces in our image but now we have to deal with the problem that faces turned different directions look totally different to a computer
to account for this we will try to warp each picture so that the eyes and lips are always in the sample place in the image this will make it a lot easier for us to compare faces in the next steps
to do this we are going to use an algorithm called face landmark estimation there are lots of ways to do this but we are going to use the approach invented in by vahid kazemi and josephine sullivan
the basic idea is we will come up with specific points called landmarks that exist on every face the top of the chin the outside edge of each eye the inner edge of each eyebrow etc then we will train a machine learning algorithm to be able to find these specific points on any face
here s the result of locating the face landmarks on our test image
now that we know were the eyes and mouth are we ll simply rotate scale and shear the image so that the eyes and mouth are centered as best as possible we won t do any fancy d warps because that would introduce distortions into the image we are only going to use basic image transformations like rotation and scale that preserve parallel lines called affine transformations
now no matter how the face is turned we are able to center the eyes and mouth are in roughly the same position in the image this will make our next step a lot more accurate
if you want to try this step out yourself using python and dlib here s the code for finding face landmarks and here s the code for transforming the image using those landmarks
now we are to the meat of the problem actually telling faces apart this is where things get really interesting
the simplest approach to face recognition is to directly compare the unknown face we found in step with all the pictures we have of people that have already been tagged when we find a previously tagged face that looks very similar to our unknown face it must be the same person seems like a pretty good idea right
there s actually a huge problem with that approach a site like facebook with billions of users and a trillion photos can t possibly loop through every previous tagged face to compare it to every newly uploaded picture that would take way too long they need to be able to recognize faces in milliseconds not hours
what we need is a way to extract a few basic measurements from each face then we could measure our unknown face the same way and find the known face with the closest measurements for example we might measure the size of each ear the spacing between the eyes the length of the nose etc if you ve ever watched a bad crime show like csi you know what i am talking about
ok so which measurements should we collect from each face to build our known face database ear size nose length eye color something else
it turns out that the measurements that seem obvious to us humans like eye color don t really make sense to a computer looking at individual pixels in an image researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself deep learning does a better job than humans at figuring out which parts of a face are important to measure
the solution is to train a deep convolutional neural network just like we did in part but instead of training the network to recognize pictures objects like we did last time we are going to train it to generate measurements for each face
the training process works by looking at face images at a time
then the algorithm looks at the measurements it is currently generating for each of those three images it then tweaks the neural network slightly so that it makes sure the measurements it generates for and are slightly closer while making sure the measurements for and are slightly further apart
after repeating this step millions of times for millions of images of thousands of different people the neural network learns to reliably generate measurements for each person any ten different pictures of the same person should give roughly the same measurements
machine learning people call the measurements of each face an embedding the idea of reducing complicated raw data like a picture into a list of computer generated numbers comes up a lot in machine learning especially in language translation the exact approach for faces we are using was invented in by researchers at google but many similar approaches exist
this process of training a convolutional neural network to output face embeddings requires a lot of data and computer power even with an expensive nvidia telsa video card it takes about hours of continuous training to get good accuracy
but once the network has been trained it can generate measurements for any face even ones it has never seen before so this step only needs to be done once lucky for us the fine folks at openface already did this and they published several trained networks which we can directly use thanks brandon amos and team
so all we need to do ourselves is run our face images through their pre trained network to get the measurements for each face here s the measurements for our test image
so what parts of the face are these numbers measuring exactly it turns out that we have no idea it doesn t really matter to us all that we care is that the network generates nearly the same numbers when looking at two different pictures of the same person
if you want to try this step yourself openface provides a lua script that will generate embeddings all images in a folder and write them to a csv file you run it like this
this last step is actually the easiest step in the whole process all we have to do is find the person in our database of known people who has the closest measurements to our test image
you can do that by using any basic machine learning classification algorithm no fancy deep learning tricks are needed we ll use a simple linear svm classifier but lots of classification algorithms could work
all we need to do is train a classifier that can take in the measurements from a new test image and tells which known person is the closest match running this classifier takes milliseconds the result of the classifier is the name of the person
so let s try out our system first i trained a classifier with the embeddings of about pictures each of will ferrell chad smith and jimmy falon
then i ran the classifier on every frame of the famous youtube video of will ferrell and chad smith pretending to be each other on the jimmy fallon show
it works and look how well it works for faces in different poses even sideways faces
let s review the steps we followed
now that you know how this all works here s instructions from start to finish of how run this entire face recognition pipeline on your own computer
update you can still follow the steps below to use openface however i ve released a new python based face recognition library called face recognition that is much easier to install and use so i d recommend trying out face recognition first instead of continuing below
i even put together a pre configured virtual machine with face recognition opencv tensorflow and lots of other deep learning tools pre installed you can download and run it on your computer very easily give the virtual machine a shot if you don t want to install all these libraries yourself
original openface instructions
if you liked this article please consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
interested in computers and machine learning likes to write about it
update we have released a new report describing our proposal for algorithmic impact assessments in full detail the report describes how affected communities and stakeholders can use our framework to assess the use of ai and algorithmic decision making in public agencies and determine where or if their use is acceptable
in the coming months nyc mayor bill de blasio will announce a new task force on automated decision systems the first of its kind in the united states the task force will recommend how each city agency should be accountable for using algorithms and other advanced computing techniques to make important decisions as a first step toward this goal we urge the task force to consider a framework structured around algorithmic impact assessments aias
automated decision systems are here and are already being integrated across many core social institutions reshaping how our criminal justice system works via risk assessment algorithms and predictive policing systems optimizing energy use in critical infrastructure through ai driven resource allocation and changing our educational system through new teacher evaluation tools and student school matching algorithms and these are merely what journalists researchers and the public record expose to date no city in the us has explicitly mandated that its agencies disclose anything about the automated decision systems they have in place or are planning to use
while these systems are already influencing important decisions there is still no clear framework in the us to ensure that they are monitored and held accountable indeed even many simple systems operate as black boxes as they are outside the scope of meaningful scrutiny and accountability this is worrying if governments continue on this path they and the public they serve will increasingly lose touch with how decisions have been made thus rendering them unable to know or respond to bias errors or other problems the urgency of this concern is why ai now has called for an end to the use of black box systems in core public agencies black boxes must not prevent agencies from fulfilling their responsibility to protect basic democratic values such as fairness and due process and to guard against threats like illegal discrimination or deprivation of rights
with this in mind and drawing on several ongoing research efforts ai now is proposing an early stage framework centered on algorithmic impact assessments aias this broad approach complements similar domain specific proposals like andrew selbst s recent work on algorithmic impact statements in the context of predictive policing systems these frameworks in turn draw on the history and development of assessments in other areas such as environmental policy privacy law and data protection in the eu and build on growing and important research that scientific and policy experts have been developing on the topic of algorithmic accountability aias begin to shed light on these systems helping us to better understand their use and to determine where they are and aren t appropriate both before they are deployed and on a recurring basis when they are actively in use
aias strive to achieve four initial goals
a fundamental aspect of government accountability and due process is notice of how our rights are being affected and by which government agencies and actors when automated systems play a significant role in government decisions they should be disclosed
thus as a first step algorithmic impact assessments would require each agency to publicly list and describe all existing and proposed automated decision systems including their purpose reach and potential impacts on identifiable groups or individuals this requirement by itself would go a long way towards shedding light on which technologies are being deployed to serve the public and where accountability research should be focused similar provisions are already part of laws in the u s such as the privacy act of and have been proposed in emerging local ordinances such as one in santa clara county and another in oakland that are focused on privacy
of course in order to make disclosure meaningful automated decision making must be defined in ways that are both practical and appropriate an overly broad definition could burden agencies with disclosing systems that are not the main sources of concern if a public servant uses a word processor to type up her notes from a meeting where some key decisions were made and then checks them with the program s automated spell checker her agency should not have to perform an aia for that spell checker on the flipside an overly narrow definition could undermine efforts to include high profile systems like those deciding which students are admitted to specialized high schools or how housing opportunities are allocated
it is also essential that systems are defined in terms that are broader than just their software aias should cover human factors too along with any input and training data bias in automated decision systems can arise as much from the human choices on how to design or train the system as they can from human errors in judgment when interpreting or acting on the outputs evaluating a predictive policing system for instance is not just a matter of understanding the math behind its algorithm we must also understand how officers dispatchers and other decision makers take its outputs and implement them in both policy and everyday practices
to ensure that we draw an appropriate boundary around automated decision systems algorithmic impact assessments must set forth a reasonable and practical definition of automated decision making this process of defining and specifying such systems would help build agency capacity for the procurement and assessment of future systems as experience with aias would help guide requests for proposals budgeting and other key milestones
crucially agencies would not be working alone to create these definitions in order for aias to be effective agencies must publish their definition as part of a public notice and comment process whereby individuals communities researchers and policymakers could respond and if necessary challenge the definition s scope this would allow push back when agencies omit essential systems that raise public concerns
consider the example of an education agency a reasonable agency s definition should include an automated decision system such as the educational value added assessment system used by many jurisdictions for automated teacher evaluations we might expect that the text of that agency s definition would include something like the systems tools or statistical models used to measure or evaluate an individual teacher s performance or effectiveness in the classroom in a criminal justice agency similar wording might yield a definition that includes systems tools or statistical models used to measure or evaluate an individual criminal defendant s risk of reoffending
a definition that focuses on individual profiling has a precedent in the eu s general data protection regulation gdpr automated profiling is defined as any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person in particular to analyse or predict aspects concerning that natural person s performance at work economic situation health personal preferences interests reliability behaviour location or movements
the gdpr language may be a good starting point but will require some shaping to match the appropriate contexts and in other contexts it may not be sufficient some predictive policing tools for example don t necessarily constitute profiling individuals and instead focus on locations using statistics to try to understand and predict crime trends with the potential for disparate impact a definition might then have to account for any systems tools or algorithms that attempt to predict crime trends and recommend the allocation of policing resources in non individualized terms in general any definition should be sure to cover systems that might have a disparate impact on vulnerable communities and to pay careful attention to how broad terms like automated processing are specified in practice
after internal agency processes work to publicly disclose existing or proposed systems algorithmic impact assessments should provide a comprehensive plan for giving external researchers meaningful access to examine specific systems and gain a fuller account of their workings while certain individuals and communities may wish to examine the systems themselves it would be unreasonable to expect that everyone has the time knowledge and resources for such testing and auditing automated decision systems can be incredibly complex and issues like bias and systematic errors may not be easily determined through the review of systems on an individual case by case basis a plan to grant meaningful access would allow individuals and communities to call upon the trusted external experts best suited to examine and monitor a system and to assess whether there are issues that might harm the public interest
to do this well it s important to recognize that the appropriate type and level of access may vary from agency to agency from system to system and from community to community the risks and harms at issue in different systems may demand different types of research across different disciplines while the right to an explanation concerning a specific automated decision could prove useful in some situations as it is suggested in the gdpr framework many systems may require a group level or community wide analysis for example an explanation for a single stop and frisk incident would not reveal the greater discriminatory pattern that the policy created in nyc where over of those stopped were black or latino men
other systems may only require analysis based on inputs and outputs without needing access to the underlying source code we believe that the best way for agencies to develop appropriate research access programs initially would be to work with affected communities and interdisciplinary researchers through the notice and comment process importantly given changing technologies the developing research field around accountability and the shifting social and political contexts within which systems are deployed access to a system will almost certainly need to be ongoing and take the form of monitoring over time
ongoing monitoring and research access would also allow agencies and researchers to work together to develop their approaches to testing the research around algorithmic accountability is young we do not yet know what future tools and techniques might best keep systems accountable external researchers from a wide variety of disciplines will need the flexibility to adapt to new methods of accountability as new technologies drive new forms of automating decisions
to effectuate external research access public agencies will also need to commit to accountability in both their internal technology development plans as well as vendor and procurement relationships for example meaningful access to automated decision systems will not be practical or feasible if essential information about the system can be shielded from review by blanket claims of trade secrecy agency aias commit each agency to ensuring meaningful review of these systems therefore agencies may need to require potential vendors to waive restrictions on information necessary for external review for example at minimum vendors should be contractually required by agencies to waive any proprietary or trade secrecy interest in information related to accountability such as those surrounding testing validation and or verification of system performance and disparate impact
of course there is also a real danger that relying on external auditing will become an unfunded mandate on researchers to check automated decision systems however there are models that legislation could adopt to address this an aia framework could fund an independent government wide oversight body like an inspector general s office to support the research and access or funding could be set aside for the compensation of external auditors fortunately there are many options that jurisdictions could consider for their own needs and a growing community of computer scientists journalists and social scientists have already proven there is an appetite for research into public automated systems
access for external researchers is a crucial component of algorithmic accountability but in parallel we need to increase the internal capacity of public agencies to better understand and explicate potential impacts before systems are implemented agencies must be experts on their own automated decision systems if they are to ensure the public trust that s why agencies algorithmic impact assessments must include an evaluation of how a system might impact the public and show how they plan to address any issues should they arise
this is an opportunity for agencies to develop expertise when commissioning and purchasing automated decision systems and for vendors to foster the public trust in their systems agencies will be better able to assess the risks and benefits associated with different types of systems and work with vendors to conduct and share relevant testing and research on their automated decision system including but not limited to testing for any potential biases that could adversely impact an individual or group interest and any other validation or verification testing conducted as noted above if some vendors raise trade secrecy or confidentiality concerns those can be addressed in the aia but responsibility for accountability ultimately falls upon the public agency
aias would also benefit vendors that prioritize fairness accountability and transparency in their offerings companies that are best equipped to help agencies and researchers study their systems would have a competitive advantage over others cooperation would also help improve public trust especially at a time when skepticism in the societal benefits of tech companies is on the rise these new incentives encourage a race to the top of the accountability spectrum among vendors
increasing agency expertise through aias will also help promote transparency and accountability in public records requests today when agencies receive open records requests for information about algorithmic systems there is often a mismatch between how the outside requestor thinks agencies use and classify these technologies and the reality as a result requests may often take a scattershot approach cramming overly broad technical terms into numerous requests in the hopes that one or more hit the mark this can make it difficult for records officers responding in good faith to understand the request let alone provide the answers the public needs
even open records experts who are willing to reasonably narrow their requests may be unable to do so because of the lack of any roadmap showing which systems a given agency is planning procuring or deploying for example in a project out of the university of maryland faculty and students working in a media law class filed numerous general public records requests for information regarding criminal risk assessment usage in all fifty states the responses they received varied significantly making it difficult to aggregate data and compare usage across jurisdictions it also revealed a lack of general knowledge about the systems among the agencies leading to situations where the students had to explain what criminal justice algorithms were to the public servants in charge of providing the records on their use
accountability processes such as the aia would help this mismatch on both sides of the equation researchers journalists and concerned members of the public could use the algorithmic impact assessments to reasonably target their requests to systems that were enumerated and described saving public records staff significant time and resources agency staff would also gain a better handle on their own systems and records and could then help requestors understand which documents and public records are potentially available this alignment would increase efficiency lower the agency burden of processing requests and increase public confidence
agencies could also use the aia as an opportunity to lay out any other procedures that will help secure public trust in such systems if appropriate the agency might want to identify how individuals can appeal decisions involving automated decision systems to make clear what appeals processes might cover a given system s decision or to share its mitigation strategy should the system behave in an unexpected and harmful way the benefits to public agencies of self assessment go beyond algorithmic accountability it encourages agencies to better manage their own technical systems and become leaders in the responsible integration of increasingly complex computational systems in governance
the aia process provides a much needed basis for evaluating and improving agency systems but without oversight aias could become simply a checkbox for agencies to mark off and forget that s why the algorithmic impact assessment process should also provide a path for the public to pursue cases where agencies have failed to comply with the algorithmic impact assessment requirement or where serious harms are occurring for example if an agency fails to disclose systems that reasonably fall within the scope of those making automated decisions or if it allows vendors to make overboard trade secret claims and thus blocks meaningful system access the public should have the chance to raise concerns with an agency oversight body or directly in a court of law if the agency refused to rectify these problems after the public comment period
as the nyc task force embarks on its study we hope the algorithmic impact assessment framework can serve as a productive foundation in defining meaningful algorithmic accountability the task force will be a great opportunity for the public and city agencies to come together to make new york the fairest big city in america that s why we hope the mayor calls on city agencies to help the task force understand the automated decisions that shape new yorkers lives
we will be publishing further research on this model in the coming months and welcome any and all feedback to develop it and as more jurisdictions take the same first steps new york city has we hope aias will give other communities a useful starting place from which to better understand the systems impacting them and to design and deploy their own approaches to meaningful algorithmic oversight and accountability
thank you to chris bavitz hannah bloch wehba ryan calo danielle citron cassie deskus rachel goodman frank pasquale rashida richardson andrew selbst vincent southerland and michael veale for their helpful comments on the aia framework and this post
europe has already been developing approaches under various long standing directives and conventions and the more recent general data protection regulation gdpr while the massachusetts legislature has taken up similar questions but with a bill focused specifically in the criminal justice context
see generally citron danielle keats technological due process wash ul rev edwards lilian and michael veale slave to the algorithm why a right to an explanation is probably not the remedy you are looking for duke l amp tech rev brauneis robert and ellen p goodman algorithmic transparency for the smart city citron danielle keats and frank pasquale the scored society due process for automated predictions wash l rev selbst andrew d and julia powles meaningful information and the right to explanation international data privacy law no diakopoulos nicholas algorithmic accountability the investigation of black boxes tow center for digital journalism barocas solon and andrew d selbst big data s disparate impact cal l rev crawford kate and jason schultz big data and due process toward a framework to redress predictive privacy harms bcl rev
some have argued that the gdpr s actual definition which says that people have the right not to be subject to decisions based on decisions made solely by automated processing introduces a loophole for systems that have any degree of human intervention recently released guidelines on gdpr have attempted to adjust for this by requiring that human intervention be meaningful rather than a token gesture and requiring that data controllers discuss human involvement in their data protection impact assessments
https gdpr info eu art gdpr
the original draft of int relied on a transparency approach directed towards individuals allowing individuals to audit decisions made using their own personal information though there may be benefit to an individual having that access it is insufficient to uncovering larger systemic issues see for example ananny m amp crawford k seeing without knowing limitations of the transparency ideal and its application to algorithmic accountability new media amp society
there might be privacy or security concerns related to making community or group level data available to researchers working out protocols for appropriate disclosures and access controls for researchers will be important for the stakeholders in this process
in line with our past recommendations we need a definition of external researchers that includes people from beyond computer science and engineering it should effectively include at minimum university researchers from a broad array of disciplines civil society organizations who can represent the interests of relevant communities and journalists this and other parts of our framework will be treated in our future work
see for example the conference on fairness accountability and transparency fat
we see this process as analogous the us process for managing the potential environmental impacts made by federal agencies under the national environmental policy act federal agencies must conduct a brief environmental assessment of a proposed action or if necessary create a longer environmental impact statement which the public can challenge before the action takes place a similar process should take place before an agency deploys a new high impact automated decision system ideally agencies would welcome and facilitate this process by identifying stakeholders ahead of time and conducting consultations on critical questions and concerns then after incorporating these concerns in a public notice any unresolved concerns could be raised during the comment process
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
researching the social implications of artificial intelligence now to ensure a more equitable future
deduction given the rule and the cause deduce the effect
induction given a cause and an effect induce a rule
abduction given a rule and an effect abduce a cause
taxonomy
what parameters structure hidden concepts
what from supervised unsupervised reinforcement
what for prediction diagnostics summarization
how passive active online offline
outputs classification regression
details generative discriminative
occom s razor everything else being equal choose the less complex hypothesis
the ultimate goal of machine learning is to have data models that can learn and improve overtime
evaluation metrics
learn from data to make predictions
classification and regression
classification is about deciding which categories new instances belong to then when we see new objects we can use their features to guess which class they belong to
in regression we want to make a prediction on continuous data
in classification we want to see how often a model correctly or incorrectly identifies a new example whereas in regression we might be more interested to see how far off the model s prediction is true from true value
classification accuracy precision recall and f score
regression mean absolute error and mean square error
short comings of accuracy
causes of error
bias due to a model being unable to represent the complexity of the underlying data
variance due to a model being overly sensitive to the limited data it has been trained on
bias occurs when a model has enough data but is not complex enough to capture the underlying relationships as a result the model consistently and systematically misrepresents the data leading to low accuracy in prediction this is known as underfitting to overcome error from bias we need more complex model
variance is a measure of how much the predictions vary for any given test sample high sensitivity to the training set is also known as overfitting occurs when the model is too complex
we can typically reduce the variability of a model s predictions and increase precision by training on more data if more data is unavailable we can also control variance by limiting our model s complexity
data types
curse of dimensionality
as the number of features or dimensions grows the amount of data we need to generalize accurately grows exponentially
learning curves
bias when the training and testing errors converge and are quite high this usually means the model is biased
variance w hen there is a large gap between the training and testing error this generally means the model suffers from high variance
alright that s it for now thank you for spending your time cheers
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
machine learning and blockchain bengaluru india
an intuitive way to understand the relation between the agent and its environment is with the following example
environment you are in state you have possible actions agent i ll take action environment you received a reinforcement of units you are in state you have possible actions
the agent s job is to find a policy mapping states to actions that maximizes some long run measure of reinforcement we assume the environment is stationary
important ideas in reinforcement learning that came up
alright that s it for now thank you for spending your time cheers
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
machine learning and blockchain bengaluru india
this post covers the second and final day of the deep learning summit that took place in london on september th th you can find the first post here videos are also being posted on youtube
after a welcome from alison lowndes of nvdia the day started with the startup session
first up were wally trenholm founder amp ceo and jason cassidy md amp chief science officer of sightline innovation talking about the commercialisation of deep learning they started going after military customers then looked for other markets due to long military order process year to order they first took what had been developed in image analysis on geo scale satellite uav and applied it to agriculture then to serve even more customers they went from geo scale to macro scale images addressing industrial problems automated manufacturing quality control next they will go further down and apply their image analysis to nano scale genomic there is a mlaas machine learning as a service term for which they hold the copyright platform which will be released next month with a server on site to collect and preprocess the data and also provide reporting and dashboards while algorithm training and prediction will be done on their cloud in case you are looking clarify is hiring
next up was paul murphy ceo of clarify on deep learning amp speech adaptation the next frontier with some funny cartoonish slides clarify started in london and now texas based provides an api that analyses audio and video making it searchable the main issue with speech is adaptation as also discussed by s bastien brati res in the last session of the first summit day there are different adaptation problems like speaker adaptation ex accents speaker may not be native while most of the training data is native and male noise and tenuation moving away from the microphone the bleeding edge in speech recognition research is
then came appu shaji head of r amp d at eyeem talking about deep learning for real photography eyeem is a social network for photography one of the goals appu is to improve content discovery helping photographers being found and selling more photos he showed eyevision which is currently in early access the engine assesses aesthetic quality of the photo and also tags them with k concepts using data coming from both community and expertly curated tagging they are using cnns with word embeddings based on these research papers paper paper paper
john overington director of bioinformatics at stratified medical followed with artificial intelligence in drug discovery john said that currently drug discovery is extremely expensive and unpredictable r amp d expenses for a single approved drug range from billion to billion source he brought his experience on drug discovery to stratified medical which is developing their own drug pipeline the goal is to use ai to filter down potential molecules accelerating discovery and reducing costs they are building a knowledge graph using data from structured sources molecule databases vocabularies and unstructured data papers patents etc the latter being extracted with nlp techniques they will also leverage new public datasets such as uk k the genome sequencing data of k people which will help uncover rare variants contributing to diseases they are making progress they achieved key milestones in a multimillion partnered alzheimer s program
the last talk of the startup session was given by marius cobzarenco co founder amp cto of re infer on building conversational interfaces with deep nets marisu said they are building business bots that collect data from different systems slack crm wiki etc and are able to answer natural queries currently it is hard to understand intent and context there is active research on embeddings done for example by geoff hinton on deep thoughts at google they are using cnns to find embeddings they found this dnns to be faster to train compared to rnns and at the same time gives good results they also use dl for named entity recognition you still need to extract entities to translate the intent into actions
the second part of the morning was on deep learning applications
david plans ceo and davide morelli cto of biobeats talked about machine intelligence for the essential self their initial work was on neural networks in creativity releasing an app called pulse that generates music based on the heartbeat with the pulse app they collected a large cardiovascular dataset enhanced by information coming from sensor data accelerometer gps gyro etc now they pivoted and use this information to train models for people wellness david who also gave a terrific talk during the summit dinner the night before said we are constantly under stress as a result we live in sympathetic mode fight or flight with our body acting as if we were in a jungle facing a lion in the long run it damages our health and may result in premature death but with interventions we can be brought back to living in the much saner parasympathetic mode feed and rest couple this with the fact that of company healthcare spending is on preventable chronic diseases they are bringing their system inside organisations collaborating with bupa axa and samsung to predict employee stress and fatigue levels and take action before it is too late they also have a couple of public apps in beta testing
in the last part of the speech davide talked about their technology where there are several challenges like understanding if the stress is good eg you re happy or bad there are some indicators for example under bad stress the heartbeat becomes more regular plus heartbeat information can be correlated with activity ex you are not moving and the heartbeat suddenly becomes regular and info coming from social networks to label datasets on top of that they need to manage large datasets each user generates mb day without killing batteries and exhausting user data plans their solution is to extract features locally send them to the server where models are trained then send back the trained model and make predictions on the device the api sdk will be released by end of the year they concluded saying that the most important open challenges are ethical on bringing emotional intelligence to the algorithms so that interventions are beneficial for the user receiving them and don t cause additional stress
i then attended the parallel session on investing in ai it started with a panel made of vcs nathan benaich of playfair capital john henderson of white star capital simon king of octopus investments together with alex dalyac co founder amp ceo of tractable and moderated by sally davies of financial times most of the discussion has been on how to evaluate an ai startup here are some aspects being considered
they agreed that the acquisition of deepmind by google is a very important signal for europe before us companies tended to buy only us startups this opens new exit possibilities for european startups making them more attractive to vcs
after a very good lunch break the afternoon started with alex matei mhealth manager and ekaterina volkova volkmar researcher of bupa on deep learning for digital health bupa is an international healthcare group whose activity span from hospitals to company health insurance they showed an interesting series of proof of concept
i really appreciated their approach using available software api for fast prototype development they also showed some good practices like defining at the start of each project the evaluation criteria for deciding which software api to use example criteria what is the software api potential to scale how does the costs grow in case of large deployments
rodolfo rosini cto of weave ai came after the presentation was not very informative they seem to be in stealth mode their idea is to use contextual information to provide improved search he also talked about aggregating corporate information and making it easily searchable something similar to what re infer was talking about in the morning
joerg bornschein global scholar at cifar followed with a talk on combining directed amp undirected generative models joerg talk was about unsupervised learning where the progress has not been as impressive as in supervised learning and there are yet less real world application nevertheless it might help us to understand how the brain works and it will enable new applications where machines generate content joerg presented his work on training bidirectional helmholtz machines paper helmholtz machines hms are made of a generative model coupled with an auxiliary model which performs approximate inference joerg presented a new way to train the hms where probabilities of both models are interpreted as approximate inference distributions and the goal is to minimise the difference between the distributions he showed some examples of the algorithms in action where they reconstruct digits and faces with missing parts
the last talk of the summit was given by marie francine moens professor at ku leuven on learning representations for language understanding experiences from the muse project muse which stands for machine understanding for interactive storytelling is working on algorithms that translate text into virtual worlds applications include rendering children s stories and providing patient guidelines ex foreigners in a hospital as d virtual worlds the algorithms play a double role
the main difficulties come from having very few annotated training datasets for which they are researching into using other data sources like language models to improve results there is also a lack of world knowledge ex practice with a spear gt the spear is held in the hand so they are working on multimodal deep learning using both images and phrases to acquire more knowledge
that concluded the deep learning summit london the organisation by the re work team nikita pip sophie was great the summit had a positive mix of industry and research talk and it was a terrific opportunity to network and get to know lots of interesting people in the deep learning field coming up are the san francisco summit and then europe again highly recommended
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
ceo and chief data scientist at optimist ai bringing innovation to sales through big data the future is bright
python is one of the most popular programming languages the reason in its universality because it is a multi tool with the ability to sharpen for a variety of needs today i publish a compilation with a description of useful for the data scientist and expert on ai tools
machine learning neural networks big data are an increasingly growing trend which means that more and more specialists are needed the syntax of python is mathematically accurate so that it is understood not only by programmers but also by all who are connected with the technical sciences that s why so many new tools are being created in this language
but enough to describe the merits of python let s get down to our collection at last
shogun is qualitatively documented among the shortcomings can be called the relative complexity of working with the api it is distributed free of charge
the four basic principles underlying the keras philosophy are user friendliness modularity extensibility and compatibility with python among the shortcomings can be called a relatively slow speed of work compared to other libraries
the above tools are almost ideal for scientists programmers and anyone who is involved with machine learning and large data and of course it s worth remembering that these tools are sharpened by python
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
it entrepreneur web developer seo expert it adviser a founder of www smartspate com you can reach me out at alexmaison me
with artificial intelligence proving to be the next big thing current tech giants seem to be leaving nothing to chance when it comes to aligning themselves with what appears to be the looming future of the technology space for instance intel has been on an ai acquisition spree in recent times having made various purchases including movidius mobileeye and nervana what s more the company recently announced the purchase of vertex ai a seattle based startup that is involved in the building of a platform agnostic ai model suite according to a note posted on intel s website vertex ai will become the latest addition to the company s ai products group whereby it is expected to provide support to a wide array of hardware it is also anticipated to incorporate plaidml which is the chipmaker s multi language acceleration platform intended to help developers in deploying ai models on windows macos and linux devices particularly with its ngraph machine learning backend in the acquisition announcement intel said that vertex ai s seven person team would join the movidius team specifically in the chipmaker s artificial intelligence products group thanks to this acquisition intel has gained not only an experienced team but also ip to boost flexible deep learning at the edge additional terms and details pertaining to the entire deal were not disclosed vertex ai was founded back in by both choong ng and jeremy bruestle with the intention of building a framework that eliminated the existing gap between hardware and ai powered software the company lured seed money from various investors including toronto a canada based creative destruction lab and curious capital just to mention a few ng stated on the eve of vertex ai s launch in that current gpus and cpus are efficient and powerful enough for numerous intelligent applications however he added that the benefits of such systems do not go beyond that point in fact ng said that the lack of developer friendly and portable tools keeps most organizations from fully benefiting from the power of deep learning technology according to ng a year ago his company figured out a way that it could solve the portability and compatibility issues simultaneously for all platforms through a new software technique this approach calls for rethinking how the startup implements its algorithms and even though it has been an impediment to engineers ng stated the payoff justifies the struggle for intel the acquisition of vertex ai marks another step for the company as far as trying to capture the billion ai market is concerned its acquisition of altera delivered field programmable gate array into its vast product lineup whereas the purchase of nervana and movidius improved its real time processing portfolio importantly the former s neural network processor which is anticipated to start production in late can reportedly provide a maximum of times the ai training performance associated with competing graphics cards intel s executive vp navin shenoy said at the chipmaker s recent data centric innovation summit that after years its ai acquisitions present the largest opportunity for the company in fact he added that the company currently holds of the ai market source venturebeat
read the full article
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
algorithm x lab is a leading media and events platform dedicated to covering the latest artificial intelligence news amp insights
artificial intelligence ai is the convenient future it is one of the most promising and transformative opportunities of our time we are closer to the near future where virtual assistants bots and software agents will act more and more like people
some the biggest advances in ai are being developed inside tech giants such as google deep mind and ibm watson but there are still a lot of great opportunities for young startups to explore
related the near future of ai the road to super intelligent apps and machines
more than private companies working to advance artificial intelligence technologies have been acquired in the last years by corporate giants competing in the space including google amazon apple ibm yahoo facebook intel and more recently salesforce according to cb insights
ai will play a huge role in the near future and some of these startups are already developing apps that could help shape the future of ai there are still plenty of opportunities to exploit
and while technology giants are fighting over ai dominance these startups have made a lot of progress
x ai is an artificial intelligence driven personal assistant who schedules meetings for you
legal robot helps with understanding complex legal language using ai without the cost associated with it
the grid uses ai to build and customize your website for you billing itself as your personal ai web developer
metamind wants to make deep learning a set of techniques that don t require domain experts to program knowledge into algorithms accessible to everyone
sense is a b b predictive intelligence engine for marketing and sales it accelerates sales by finding buyers at every stage of the funnel
enlitic uses deep learning and image analysis to help doctors make diagnoses and spot abnormalities in medical images
persado is a cognitive content platform for marketers persado s products and technology generates language that inspires action and increases roi
quid is a platform that searches analyzes and visualizes the world s collective intelligence to help answer strategic questions
radiumone builds intelligent software that automates media buying making big data actionable for marketers and connects them to their next customer
gridspace has created an application based on technology that automatically saves and indexes meeting conversations
weave ai building an alternative to google now that can mine tweets for context and bring up relevant data in other apps on your phone
wit ai is an api that makes it easy for developers to create applications or devices that you can talk to
mobvoi is a chinese artificial intelligence ai company specializing in mobile voice technology
crowdflower is focused on making data useful by helping data teams collect clean and label their data at scale
mindmeld enables you to add intelligent natural language voice search to any content driven mobile app or website
mintigo helps marketing leaders to discover target and engage buyers faster with predictive marketing
sense ly is an avatar based emotively driven clinical platform virtual nurse that helps clinicians better manage their chronic care patients
botanic io designs and builds products which are capable of understanding and responding to human speech
enlitic is a deep learning healthcare company ushering in a new era of data driven medicine
scaled inference is enabling a new generation of intelligent software built by the masses and powered by an open shared platform
appier is a technology company that makes it easy for businesses to use artificial intelligence to grow and succeed in a cross screen era
harvest ai identifies and stops data breaches from targeted attacks insider threat amp stolen credentials in near real time security nerds that love design
banjo is building the world s first disaster prediction engine the company s dream is to make terrorism impossible
idibon s cloud based natural language processing services enable organizations to efficiently structure and organize their language data
statustoday analyses behavior in the context of humans and their intended actions to protect you and your company
wise io provides machine learning models that enable companies to optimize the customer experience
kasisto augments mobile financial applications by enabling intelligent conversations using the perfect mix of speech text and touch interfaces
the author is the founding editor at alltopstartups tools resources and ideas for launching and growing a startup
he is also the curator at postanly a weekly newsletter that delivers the most insightful long form posts from top publishers here is what subscribers received last week
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
writer thinker creator at thinkinginmodels co curator at postanly com columnist at inc magazine featured at business insider forbes entrepreneur etc
most of the time we do have a common problem to increase the accuracy in a model for a given data set it is hard because when it comes to implementation we try to do all things using a single model which is not optimal for some scenarios for example let s assume that there is a categorical feature called gender and some other features when we try to train the whole data set at once this categorical feature might have a huge impact on the variance of other variables which can results an unstable model because model cannot converge men s behavior and women s behavior together using a single approach
so to address this kind of a problem sometimes it is better to treat these categories separately and check for the accuracy divide the data set based on gender and remove the gender feature from both data sets apply different models for both men s and women s data separately maybe they might good in different models if men s data has more linear relationship then a linear model will quite fit for the scenario if women s data does not show a linear relationship then decision tree type algorithm might good for that particular case even may be the same model with different hyper parameters could make a difference
finally we have to do predictions when we have to do the predictions we have to manually check for the feature that we used to separate the data set and navigate each data point to relevant model and get the predictions
sometimes there can be disadvantage when there is a class imbalance problem if we have more men s data rather than women s data then there will be a problem in training a model for women s data so it is better to have fair amount of data for both models and should be sufficiently balanced
maybe we might have taken a wrong feature to separate the data set which does not have a strong impact on the output in that case we just increase the complexity of our implementation
so test it do it only if it is required
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
software engineer at sysco labs computer science amp engineering graduand at university of moratuwa
artificial intelligence will never have what is not downloaded into it robot or some other form i just read an article that stated an ai was becoming a citizen just like i heard a while back ago two ai s made up their own language to communicate rubish or maybe its wishful thinking that man can create and be a creator of the artificial intelligence and make it think by itself
this isn t possible though not truely not realistically
just more scifi for the imagination which is a feeding frenzy eyesore
theres a lot of misinformation out there just look at orsen wells radio version of war of the world how many supposedly committed suicide thinking it was real
we humans have a knack for the dramatic the eeriness of scary things happening and ruling over us or killing us some hope it does become reality
there lies the delima
software engineer
at the end of all eyes were on the year s accomplishments as well as forecasting technology trends of and beyond one particular field that has frequently been in the spotlight during the last year is deep learning an increasingly popular branch of machine learning which looks to continue to advance further and infiltrate into an increasing number of industries and sectors here are a list of deep learning libraries and frameworks that will gain momentum in
theano is a python library for defining and evaluating mathematical expressions with numerical arrays it makes it easy to write deep learning algorithms in python on the top of the theano many more libraries are built
keras is a minimalist highly modular neural network library in the spirit of torch written in python that uses theano under the hood for optimized tensor manipulation on gpu and cpu
pylearn is a library that wraps a lot of models and training algorithms such as stochastic gradient descent that are commonly used in deep learning its functional libraries are built on top of theano
lasagne is a lightweight library to build and train neural networks in theano it is governed by simplicity transparency modularity pragmatism focus and restraint principles
blocks a framework that helps you build neural network models on top of theano
caffe is a deep learning framework made with expression speed and modularity in mind it is developed by the berkeley vision and learning center bvlc and by community contributors google s deepdream is based on caffe framework this framework is a bsd licensed c library with python interface
nolearn contains a number of wrappers and abstractions around existing neural network libraries most notably lasagne along with a few machine learning utility modules
gensim is deep learning toolkit implemented in python programming language intended for handling large text collections using efficient algorithms
chainer bridge the gap between algorithms and implementations of deep learning its powerful flexible and intuitive and is considered as the flexible framework for deep learning
deepnet is a gpu based python implementation of deep learning algorithms like feed forward neural nets restricted boltzmann machines deep belief nets autoencoders deep boltzmann machines and convolutional neural nets
hebel is a library for deep learning with neural networks in python using gpu acceleration with cuda through pycuda it implements the most important types of neural network models and offers a variety of different activation functions and training methods such as momentum nesterov momentum dropout and early stopping
cxxnet is fast concise distributed deep learning framework based on mshadow it is a lightweight and easy extensible c cuda neural network toolkit with friendly python matlab interface for training and prediction
deeppy is a pythonic deep learning framework built on top of numpy
deeplearning is deep learning library developed with c and python
neon is nervana s python based deep learning framework
convnet convolutional neural net is a type of deep learning classification algorithms that can learn useful features from raw data by themselves and is performed by tuning its weighs
deeplearntoolbox is a matlab octave toolbox for deep learning and includes deep belief nets stacked autoencoders convolutional neural nets
cuda convnet is a fast c cuda implementation of convolutional or more generally feed forward neural networks it can model arbitrary layer connectivity and network depth any directed acyclic graph of layers will do training is done using the backpropagation algorithm
matconvnet is a matlab toolbox implementing convolutional neural networks cnns for computer vision applications it is simple efficient and can run and learn state of the art cnns
eblearn is an open source c library of machine learning by new york university s machine learning lab led by yann lecun in particular implementations of convolutional neural networks with energy based models along with a gui demos and tutorials
singa is designed to be general to implement the distributed training algorithms of existing systems it is supported by apache software foundation
nvidia digits is a new system for developing training and visualizing deep neural networks it puts the power of deep learning into an intuitive browser based interface so that data scientists and researchers can quickly design the best dnn for their data using real time network behavior visualization
intel deep learning framework provides a unified framework for intel platforms accelerating deep convolutional neural networks
n dimensional arrays for java nd j is scientific computing libraries for the jvm they are meant to be used in production environments which means routines are designed to run fast with minimum ram requirements
deeplearning j is the first commercial grade open source distributed deep learning library written for java and scala it is designed to be used in business environments rather than as a research tool
encog is an advanced machine learning framework which supports support vector machines artificial neural networks genetic programming bayesian networks hidden markov models genetic programming and genetic algorithms are supported
convnet js is a javascript library for training deep learning models mainly neural networks entirely in a browser no software requirements no compilers no installations no gpus no sweat
torch is a scientific computing framework with wide support for machine learning algorithms it is easy to use and efficient fast scripting language luajit and an underlying c cuda implementation torch is based on lua programming language
mocha is a deep learning framework for julia inspired by the c framework caffe efficient implementations of general stochastic gradient solvers and common layers in mocha could be used to train deep shallow convolutional neural networks with optional unsupervised pre training via stacked auto encoders its best feature include modular architecture high level interface portability with speed compatibility and many more
lush lisp universal shell is an object oriented programming language designed for researchers experimenters and engineers interested in large scale numerical and graphic applications it comes with rich set of deep learning libraries as a part of machine learning libraries
dnngraph is a deep neural network model generation dsl in haskell
accord net is a net machine learning framework combined with audio and image processing libraries completely written in c it is a complete framework for building production grade computer vision computer audition signal processing and statistics applications
darch package can be used for generating neural networks with many layers deep architectures training methods includes a pre training with the contrastive divergence method and a fine tuning with common known training algorithms like backpropagation or conjugate gradient
deepnet implements some deep learning architectures and neural network algorithms including bp rbm dbn deep autoencoder and so on
upcoming deep learning events in
the best way to predict the future is to create it
so i just started with the course at http course fast ai called practical deep learning for coders the basic infrastructure that you need is a gpu enabled pc so that you can train your models on the images quickly the author has described how to do it in aws but the problem with aws gpu instances are that is still in some sort of preview and we need to contact amazon support for unlocking their p instances
microsoft azure on the other hand already has gpu enabled vms which came out of preview on st of december you can see the promo page here its now out of preview and anyone can access it without going through the hassle of contacting support you can see the pricing here the nc machines that we are gonna use costs per hour
if you are new to azure i hope the screenshots will help you login to https ms portal azure com with your microsoft live account the click on the sign to add a vm
search for ubuntu server lts as above
make sure you choose the vm disk type as hdd instead of ssd as otherwise it will not show you the nc option also the location has to be east us
by default it shows recommended vms click on all and scroll down to nc
you should see the above message once it is successful
once it is ready click on connect and you will be able to see the ip
once you ssh into the machine start running the following commands from your home folder i have made a gist as seen below please run the commands one by one as in the blog
run step from this gist you might see an error like the one below
so we have to re run the last lines from the install gpu azure script so run step from the gist
no we are almost ready to start with out jupyter notebook so please execute step from your local in your local system so this will tunnel traffic from your localhost to the vm port replace the ip with your own ip
now run step form the gist and get all the resources you need
now we open the notebook and navigate lesson and start executing each of the commands
you should get this error we need cv please run step from the gist and you should be good
everything should be fine and dandy now happy deep learning
everyone hates captchas those annoying images that contain text you have to type in before you can access a website captchas were designed to prevent computers from automatically filling out forms by verifying that you are a real person but with the rise of deep learning and computer vision they can now often be defeated easily
i ve been reading the excellent book deep learning for computer vision with python by adrian rosebrock in the book adrian walks through how he bypassed the captcha on the e zpass new york website using machine learning
adrian didn t have access to the source code of the application generating the captcha image to break the system he had to download hundreds of example images and manually solve them to train his system
but what if we want to break an open source captcha system where we do have access to the source code
i went to the wordpress org plugin registry and searched for captcha the top result is called really simple captcha and has over million active installations
and best of all it comes with source since we ll have the source code that generates the captchas this should be pretty easy to break to make things a little more challenging let s give ourself a time limit can we fully break this captcha system in less than minutes let s try it
important note this is in no way a criticism of the really simple captcha plugin or its author the plugin author himself says that it s not secure anymore and recommends that you use something else this is just meant as a fun and quick technical challenge but if you are one of the remaining million users maybe you should switch to something else
to form a plan of attack let s see what kinds of images really simple captcha generates on the demo site we see this
ok so the captcha images seem to be four letters let s verify that in the php source code
yep it generates letter captchas using a random mix of four different fonts and we can see that it never uses o or i in the codes to avoid user confusion that leaves us with a total of possible letters and numbers that we need to recognize no problem
time elapsed so far minutes
before we go any further let s mention the tools that we ll use to solve this problem
python
python is a fun programming language with great libraries for machine learning and computer vision
opencv
opencv is a popular framework for computer vision and image processing we ll use opencv to process the captcha images it has a python api so we can use it directly from python
keras
keras is a deep learning framework written in python it makes it easy to define train and use deep neural networks with minimal coding
tensorflow
tensorflow is google s library for machine learning we ll be coding in keras but keras doesn t actually implement the neural network logic itself instead it uses google s tensorflow library behind the scenes to do the heavy lifting
ok back to the challenge
to train any machine learning system we need training data to break a captcha system we want training data that looks like this
since we have the source code to the wordpress plug in we can modify it to save out captcha images along with the expected answer for each image
after a couple of minutes of hacking on the code and adding a simple for loop i had a folder with training data png files with the correct answer for each as the filename
this is the only part where i won t give you working example code we re doing this for education and i don t want you to actually go out and spam real wordpress sites however i will give you the images i generated at the end so that you can replicate my results
time elapsed so far minutes
now that we have our training data we could use it directly to train a neural network
with enough training data this approach might even work but we can make the problem a lot simpler to solve the simpler the problem the less training data and the less computational power we ll need to solve it we ve only got minutes after all
luckily the captcha images are always made up of only four letters if we can somehow split the image apart so that that each letter is a separate image then we only have to train the neural network to recognize a single letter at a time
i don t have time to go through training images and manually split them up into separate images in photoshop that would take days and i ve only got minutes left and we can t just split the images into four equal size chunks because the captcha randomly places the letters in different horizontal locations to prevent that
luckily we can still automate this in image processing we often need to detect blobs of pixels that have the same color the boundaries around those continuous pixels blobs are called contours opencv has a built in findcontours function that we can use to detect these continuous regions
so we ll start with a raw captcha image
and then we ll convert the image into pure black and white this is called t hresholding so that it will be easy to find the continuous regions
next we ll use opencv s findcontours function to detect the separate parts of the image that contain continuous blobs of pixels of the same color
then it s just a simple matter of saving each region out as a separate image file and since we know each image should contain four letters from left to right we can use that knowledge to label the letters as we save them as long as we save them out in that order we should be saving each image letter with the proper letter name
but wait i see a problem sometimes the captchas have overlapping letters like this
that means that we ll end up extracting regions that mash together two letters as one region
if we don t handle this problem we ll end up creating bad training data we need to fix this so that we don t accidentally teach the machine to recognize those two squashed together letters as one letter
a simple hack here is to say that if a single contour area is a lot wider than it is tall that means we probably have two letters squished together in that case we can just split the conjoined letter in half down the middle and treat it as two separate letters
now that we have a way to extract individual letters let s run it across all the captcha images we have the goal is to collect different variations of each letter we can save each letter in it s own folder to keep things organized
here s a picture of what my w folder looked like after i extracted all the letters
time elapsed so far minutes
since we only need to recognize images of single letters and numbers we don t need a very complex neural network architecture recognizing letters is a much easier problem than recognizing complex images like pictures like cats and dogs
we ll use a simple convolutional neural network architecture with two convolutional layers and two fully connected layers
if you want to know more about how convolutional neural networks work and why they are ideal for image recognition check out adrian s book or my previous article
defining this neural network architecture only takes a few lines of code using keras
now we can train it
after passes over the training data set we hit nearly accuracy at this point we should be able to automatically bypass this captcha whenever we want we did it
time elapsed minutes whew
now that we have a trained neural network using it to break a real captcha is pretty simple
here s how our model looks decoding real captchas
or from the command line
if you want to try this yourself you can grab the code here it includes the sample images and all the code for each step in this article check out the included readme md file for instructions on how to run it
but if you want to learn what every line of the code does i highly recommend grabbing a copy of deep learning for computer vision with python it goes into a lot more detail and has tons of detailed examples it s the only book i ve seen so far that covers both how things work and how to actually use them in the real world to solve difficult problems check it out
if you liked this article consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
bigger update the content of this article is now available as a full length video course that walks you through every step of the code you can take the course for free and access everything else on lynda com free for days if you sign up with this link
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or italiano
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
artificial intelligence ai was once considered as a theory that could never be applicable in real life within a few decades the theory turned into a concept and now every sector has an ai based mechanism whether it s an automatic car or apple s siri technology this technology has its application in every segment ai has now become an integral part of our daily life
artificial intelligence brings a technology that will make machines intelligent these machines would be able to reason and make decisions just like humans do they will be able to perceive hear and recognize the data and thereafter will give solutions for a specific problem
read also the guide to crypto banking
strong vs weak ai
there are few tasks which have only a specific requirement such machines running a facial recognition or a surgery performed by a robot or a chat running on a server all these come under weak ai as their area is towards to limitations the application has only one defined activity and thus intelligence will respond specifically
now humans have the capability to build a stronger ai platform that will be able to multi task this is called strong ai if this happens in near future then the machines in no time shall out do the humans in every given task
applications of ai
artificial intelligence can be implemented in every sector whether it s healthcare it finance amp banking or managing our daily routine when humans perform a given task it faces human error but with the help of ai our chances of reducing the error and achieving the accuracy are high these machines can overcome the human limitations and work in the areas of mining or be exploring deep sea and oceans
talking about our daily routine it s either the siri from apple or a gps from our smartphones we rely on ai to a great extent while clicking a picture our faces are read by the machines and get a tag on social media talking about the finance sectors a lot of fintech organizations depend on ai managing big data finding patterns and performing data analysis is all machine dependent
fraud detection and implementing anti money laundering regulations is another area where ai finds its application the machines are capable of performing analysis based on regular inputs a lot of healthcare surgeries are robotic thus artificial intelligence is moving from being a technology to becoming a necessity
innovation crypto bank with artificial intelligence
airfio is the future of cyrpto banking which integrates neural networks with blockchain technology https airfio com
t oday we are going to confront two different pieces of hardware that are often used for deep learning tasks the first is a gtx gpu a gaming device which is worth the dollar due to its high performance the second is a tesla p gpu a high end device devised for datacenters which provide high performance computing for deep learning
for over a year now i have dedicated most of my academic life to research in deep learning working as a pre doctoral researcher in the evannai group of computer science department of universidad carlos iii de madrid i started working with convolutional neural networks soon after google released tensorflow in late since then i started exploring the use of convolutional neural networks cnns in order to automatically extract features from raw data which can be used to succesfully carry out supervised learning or in other words training predictive models
also since early one of the research fields i have spent most time working in was human activity recognition i e developing systems that could recognize the activity performed by a user e g running walking or even smoking based on data provided by sensors such as those already present in smartphones or smartwatches
early in i found a paper by ordo ez and roggen where they applied deep learning for achieving human activity recognition in particular they used cnns along with lstm long short term memory cells which are a specific implementation of a recurrent network that turns out to be useful to capture temporal patterns such as those present in human activities
later that year i found myself spending a lot of time working with this kind of things tensorflow convolutional networks lstm cells in fact i started to search for the best architectures for a given problem this involves significant amounts of trial and error and therefore a lot of time for training and evaluating networks
by that time i needed to find a way to be able to iterate quickly over different architectures of these deep neural networks it is commonly acknowledged that gpus are way faster than cpus in performing these kind of tasks mostly because they comprise a larger number of cores and faster memory however our budget for acquiring hardware was quite limited so my research group eventually acquired one computer featuring nvidia geforce gtx followed few months later by another computer with the exact same specs
nvidia geforce is not really deep learning dedicated hardware however if you look out there you will see that many people actually use them for this purpose why because they are cheap for the performance they offer specially when compared to other nvidia solutions such as the tesla family
i have been working with these nvidia devices for over a year recently the staff from azken muga s l official nvidia provider in spain let me participate in a test drive program to evaluate the performance of tesla p devices
in this post i will try to summarize the main conclusions obtained from this test drive
in this post i will compare three different hardware setups when running different deep learning tasks
the latter have been included only for the sake of comparing gpu vs cpu when working on deep learning tasks
it is remarkable that for the first two systems our tests will be performed using only the gpu yet other components may be used as well for example data may be moved from main memory to gpu memory the gpus most remarkable specs are
it can be seen how tesla p has times more cuda cores slighly higher single precision flops and twice the amount of memory also hbm memory is significantly faster than gddr x however all these advantages can be easily eclipsed when looking at the price prices in spain including vat
for the software stack we have used the following components
in order to compare the three different hardware configurations we will use two benchmarks i have tried these benchmarks to accurately mimic my daily research tasks these benchmarks are the following
in order to obtain robust results each experiment has been run times and finally metrics are averaged for each epoch
now let s take a look at the results
it is worth recalling that these numbers refer to the average time for each training epoch
it can be seen how gpu computing is significantly faster than cpu computing about x x in both benchmarks this is an improvement of almost two orders of magnitude or to put it in different words the time required by the gpu to complete a training epoch is only slightly over compared with the cpu
regarding the comparison between the two gpus tesla outperforms geforce in the latter benchmark however there is only a x speedup or equivalently the training time is reduced in a the difference is not noticeable in the mnist benchmark probably due to the fact of epochs being so fast
finally let s take a look at the average operating temperatures and consumption of these devices during the second benchmark
we can see how energy consumption is quite similar but temperature is significantly higher in the geforce devices at this point i must say that both configurations are not comparable since the geforce gpus are installed in an atx computer tower located in an office and do not have any special cooling system besides the heatsinks and fans located in the devices and the tower
in this post we have compared two different gpus by running a couple of deep learning benchmarks these devices were geforce gtx gpus devised for gaming and tesla p gpus specifically designed for high performance computing in a datacenter
after looking at the results is the p worth the dollar given that its cost is about times the cost of the geforce it could be argued that the expense is not worthy
however a disclaimer should be added at this point tesla p seems to have a better construction and may last longer given an intensive usage personally i don t think our gtx will last long given they are running heavy processes almost x
tesla p has an additional advantage the amount of gpu memory is doubled compared to the geforce gtx this would enable us to either work with larger networks or with larger batches the former case could make a difference maybe a certain problem cannot be solved given the memory constraint imposed by the geforce device as for the latter case larger batches could lead to better convergence of the gradient descent process enabling us to train a successful model in a smaller number of epochs even if the cost per epoch is only slightly better than in the geforce gpu
it could be interesting to try the volta architecture recently announced by nvidia used along with cuda toolkit and cudnn nvidia promises up to a x speedup compared to the pascal architecture given the inclusion of tensor cores specifically designed for deep learning computating the tesla v would become the successor of the tesla p and it would be great to extend this benchmark to consider this new device
i sincerely acknowledge azken muga s l for letting us test the performance of nvidia tesla p gpus as part of their test drive program
acknowledgements are also aimed at evannai group of computer science department of universidad carlos iii de madrid for acquiring the computers with nvidia geforce gtx with which i have been working for almost a year
ios amp swift the most comprehensive course on machine learning for ios development master building smart apps ios
take this course
take this course
take this course
note if the coupon doesn t work for you please let us know and check our website for other courses we are affiliated to udemy
you can expect the latest and the greatest courses to be available for free here is the one place where you can find these coupons for free
artificial intelligence and blockchain are two of the most hyped technology topics all over the blogosphere as our teams at deutsche telekom are dealing with the interlink of data management and artificial intelligence we constantly think about how adjacent technologies like iot or even blockchain relate to our areas of expertise
what we have recently observed is that artificial intelligence has truly arrived at the board level agendas our confidence is high that the topic of blockchain has certainly reached a similar hype level in almost all industries at least from what we observe in deutsche telekom we can clearly see that this is definitely the case
today we would like to invite you to join our thinking about how telecommunication companies such as deutsche telekom can benefit from synergies between artificial intelligence amp blockchain thereby we will first shortly summarize the key ideas behind blockchain for experts feel free to skip that as a matter of completion we reference to one of our earlier articles in which we excessively explained the key ideas behind artificial intelligence in a second step we will mention how ai can benefit from blockchain as well as the other way around more precisely when talking about ai we focus specifically on machine learning and data availability sharing
blockchain a distributed ledger technology
a blockchain is a chronological list of elements called blocks these blocks are bound to each other each block contains a hash of the previous block a timestamp and content information about the underlying matter what benefits does blockchain bring let us say a group of people wanted to record transactions between each other when using a blockchain approach each peer would receive a copy of the blockchain which is extended every time a new transaction happens if one participant adds a block to the chain other users immediately verify it thereby a single participant can hardly corrupt a blockchain because the peers would detect it
sometimes people tend to use the terms blockchain interchangeably with distributed ledger technology dlt however blockchain is only one special type of the dlt concept without getting too deep into the different approaches of dlt it is worth to mention differentiating properties such as whether being public or private the used consensus algorithms e g proof of work proof of stake or whether being mineable or not wecan highly recommend an article published by the world bank which gives a solid introduction into the details of dlt and blockchain
deutsche telekom actively drives blockchain forward
the common benefit in all dlt approaches is that they disintermediate centralized administrators brokers because the peer group itself and not an intermediary ensures the validity of transactions thereby dlt has the potential to disrupt significant parts of value chains in many industries such as banking and possibly it will become a commodity technology in the near future
since deutsche telekom innovation laboratories t labs has been exploring the possibilities of dlt and actively drives the topic forward with t labs deutsche telekom is researching and developing concepts with dlt focusing on how ledger technology works by installing and experimenting on numerous ledger systems such as bitcoin ethereum and iota additionally t labs is formally joining a few foundations to push the technology forward such as agreeing to become a steward of the sovrin foundation https sovrin org
synergies of artificial intelligence specifically machine learning amp distributed ledger technology
as mentioned earlier the key for artificially intelligent machines enabled by machine learning is the availability of and the efficient access to a wide range of high quality and reliable data at the same time decision makers that rely on the inference of machine learning models need to eventually trust and believe in the proclaimed values and directives for both aspects data acquisition as well as reliable machine learning models dlt has the potential to add significant value
in fact dlt has the potential to tear down data silos if dlt manages data access and ownership in the back one could effectively solve a problem with machine learning this is the case because it would allow easier access to a higher volume and variety of data finally this would eventually lead to better and more accurate model decisions so if the wide introduction of dlt leads to an opening of silos and a clear and effective way to charge data access companies like banks insurances but also telcos like deutsche telekom might be able to extend their internal scoring models with external data this opens up the opportunity to lead to earlier identification of fraudulent or risky customers many other use cases are imaginable that benefit from the commoditization of data brokerage which is enabled and secured by dlt
how data brokerage platforms may benefit from dlt
especially for the data acquisition aspect deutsche telekom currently develops new platforms and business models one prominent external example is the so called data intelligence hub dih that t systems has recently launched as of today in its first development stage the platform does not yet embody dlt however the use case and benefit of it should be straightforward as dih is a market place for the exchange of data dlt would control so called smart contracts that steer and record any data and model exchange between parties of the dih in this context the ability of dlt to prevent identity theft and thereby ensure that trading parties can trust each other is an additional benefit dlt would bring to the table
as data from different sources are shared and consolidated via a platform such as the data intelligence hub involved parties may apply machine learning techniques to train models that can itself be traded on the platform as well here again dlt may mitigate these trades via smart contracts between the involved parties on the one hand furthermore on the other hand dlt can ensure transparency on what factors specifically influence the properties of a trained model this would enable the ability to comprehend why a model infers certain values and decisions in this case one could think of a blockchain as a kind of logchain
dlt as security leaver
to sum up dlt can help to enable track understand and explain reliable decisions made by ai specifically machine learning models additionally in terms of security aspects dlt has the potential to prevent machine learning models from getting skewed by fraudulent parties that forcefully add unbalanced data in order to influence a certain behavior of machines since such influence would be much easier to detect by other involved parties no single entity could risk the humiliation it becomes apparent that dlt has the potential to optimize data trading as well as transparency on ownership of data and models in the long term dlt may ensure validity and trustworthiness of models and their inferred decisions
the other way around
now that we have shared our thoughts on how blockchain may fuel the establishment of data sharing and machine learning training distribution and application i want to mention shortly that machine learning can help the dlt movement to achievement efficiency gains too to give a very basic example everyone has heard about the mining process of bitcoins and that it takes more and more effort to mine these crypto currencies in fact mining is in general an increasingly energy consuming process that is inherent in a lot dlt applications artificially intelligent machines have the potential to allocate resources to the mining process in a smarter way so that the overall energy consumption is lower i want to recommend the paper of marwala amp xing in which one can find an extensive list of how ai technologies can facilitate more secure and efficient dlt based solutions
and for more synergies between ai and blockchain i highly recommend these two articles
https www forbes com sites bernardmarr artificial intelligence and blockchain major benefits of combining these two mega trends ddb b
https medium com francesco ai the convergence of ai and blockchain whats the deal c e accc
as always please understand this blog post as an invitation to openly discuss thoughts on topics that are currently of high importance for me personally and the industry we work in we look forward to engage in a discussion with you either personally or here on linkedin
written by susan wegner with help from john calian
susan wegner leads the chief data office of deutsche telekom and is based in berlin
john calian leads the deutsche telekom innovation labs t labs in berlin and is also the lead on blockchain driven strategy dt wide
some experts amp scientists entrepreneurs from a variety of disciplines from more than nations all work together at t labs http bit ly tlabs
more than colleagues are participating in deutsche telekom s world cup betting pool and a very special better is participating at telekom innovation laboratories t labs an ai programmed in house that is trying to pick the winners of all the world cup matches without any emotion based solely on data from previous world cup tournaments since but the exit of the german team from the tournament has predicted the ai as little as most of us
quite the contrary the ai has picked germany to reach the final but with this prognosis the ai system was certainly not alone but let s have a look on the t labs oracle besides the german result who can beat the ai in the betting pool we re really proud of our ai after the group phase it s close to the top of the rankings explain ronald fromm and elmar arunov who both work in the artificial intelligence innovation area at t labs in the t labs pool group the ai is currently only three points behind the top not bad for a group with participants in total just to give an example the ai predicted germany s last minute victory over sweden on the nose it also predicted several ties correctly including spain versus morocco although results without a victor are the most difficult to prognosticate
t labs established artificial intelligence as an innovation area around a year ago the team focuses mainly on the use of ai methods such as machine learning in network relevant use cases the idea to use the ai for the world cup arose from a student project says elmar arunov maik p chter one of our cooperative students designed and trained the model with our support all the world cup data since was fed in which only took a couple of hours the ai did not get any additional information however such as results from national leagues or current injuries the goal of the project was simply to see the best way to train ai based models optimally with a minimum of input data
the bottom line the ai is predicting the results as good and as reliably as a regular soccer expert it will be interesting to see where it ends up in the end says elmar arunov but it has great faith in the brazilian team if the t labs oracle is to be believed brazil will win this year s final match of the world cup incidentally around percent of other neural networks that have made predictions also picked brazil to win the title
t labs is now constructing a new model for the knockout matches this will enable them to determine whether the ai has learned from the results of the group round possibly changing its prediction in that regard watching the ai develop might be just as exciting as the play on the field
some experts amp scientists entrepreneurs from a variety of disciplines from more than nations all work together at t labs http bit ly tlabs
hey tim i think using machine learning to solve a real world problem would be a really nice idea
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
generative models allow a computer to create data like photos movies or music by itself
a little over a year ago alec radford building on the work of ian goodfellow published a paper that changed how everyone thought about building generative models with machine learning the new system is called deep convolutional generative adversarial networks or dcgans for short
dcgans are able to hallucinate original photo realistic pictures by using a clever combination of two deep neural networks that compete with each other all of these pictures of bedrooms were dreamt up by a dcgan
ai researchers care about generative models because they seem to be a stepping stone towards building ai systems that can consume raw data from the world and automatically build understanding from it
but let s use generative models to do something a bit more silly make artwork for bit video games
so why exactly are ai researchers building complex systems to generate slightly wonky looking pictures of bedrooms
the idea is that if you can generate pictures of something you must have an understanding of it
look at this picture
you instantly know this is a picture of a dog a furry thing with four legs and a tail but to a computer the picture is just a grid of numbers representing the color of each pixel the computer has no understanding that the picture represents a concept
but now imagine that we showed a computer thousands of pictures of dogs and after seeing those pictures the computer was able to generate new pictures of dogs on its own including different dog breeds and pictures from different angles maybe we could even ask it for certain types of pictures like a side view of a beagle
if the computer was able to do this and the pictures it produced had the right number of legs tails and ears it would prove that the computer knows what parts go into making up a dog even though no one told it explicitly so in a sense a good generative model is proof of basic understanding at least on a toddler level
that s why researchers are so excited about building generative models they seem to be a way to train computers to understand concepts without being explicitly taught the meaning of those concepts that s a big step over current systems that can only learn from training data that has been painstakingly pre labeled by humans
but if all this research results in programs that generate pictures of dogs how many years until we get the first computer generated dog a day calendar as a side effect
and if you can build a program that understands dogs why not a program that understands anything else what about a program that could generate an unlimited number of stock photos of people shaking hands i m sure someone would pay for that
ok maybe a program that generates bad stock photos wouldn t be that interesting but given the rate of progress in generative models over just the past year who knows where we ll be in or years what happens if someone invents a system to generate entire movies or music or video games
if you look forward years and squint you can already imagine a world where entertainment could be machine generated
the video game industry is the first area of entertainment to start seriously experimenting with using ai to generate raw content aside from the obvious venn diagram overlap between computer gaming and machine learning engineers there s a huge cost incentive to invest in video game development automation given the million budgets of modern aaa video games
we are still in the earliest days of machine learning based generative models and their practical uses are currently pretty narrow but they are a lot of fun to play around with let s see what we can do with one
to build a dcgan we create two deep neural networks then we make them fight against each other endlessly attempting to out do one another in the process they both become stronger
let s pretend that the first deep neural network is a brand new police officer who is being trained to spot counterfeit money it s job is to look at a picture and tell us if the picture contains real money
since we are looking for objects in pictures we can use a standard convolutional neural network for this job if you aren t familiar with convnets you can read my earlier post but the basic idea is that the neural network that takes in an image processes it through several layers that recognize increasingly complex features in the image and then it outputs a single value in this case whether or not the image contains a picture of real money
this first neural network is called the discriminator
now let s pretend the second neural network is a brand new counterfeiter who is just learning how to create fake money for this second neural network we ll reverse the layers in a normal convnet so that everything runs backwards so instead of taking in a picture and outputting a value it takes in a list of values and outputs a picture
this second neural network is called the generator
so now we have a police officer the discriminator looking for fake money and a counterfeiter the generator that s printing fake money let s make them battle
in the first round the generator will create pathetic forgeries that barely resemble money at all because it knows absolutely nothing about what money is supposed to look like
but right now the discriminator is equally terrible at it s job of recognizing money so it won t know the difference
at this point we step in and tell the discriminator that this dollar bill is actually fake then we show it a real dollar bill and ask it how it looks different from the fake one the discriminator looks for a new detail to help it separate the real one from the fake one
for example the discriminator might notice that real money has a picture of a person on it and the fake money doesn t using this knowledge the discriminator learns how to tell the fake from the real one it gets a tiny bit better at its job
now we start round we tell the generator that it s money images are suddenly getting rejected as fake so it needs to step up it s game we also tell it that the discriminator is now looking for faces so the best way to confuse the discriminator is to put a face on the bill
and the fake bills are being accepted as valid again so now the discriminator has to look again at the real dollar and find a new way to tell it apart from the fake one
this back and forth game between the generator and the discriminator continues thousands of times until both networks are experts eventually the generator is producing near perfect counterfeits and the discriminator has turned into a master detective looking for the slightest mistakes
at the point when both networks are sufficiently trained so that humans are impressed by the fake images we can use the fake images for whatever purpose we want
so now that we know how dcgans work let s see if we can use one to generate new artwork for s style video games
let s build a dcgan that tries to produce screenshots of imaginary video games for the nintendo entertainment system or nes based on screenshots of real games
the idea is that if we can generate convincing screenshots of imaginary video games we could copy and paste bits of art from those screenshots and use it in our own retro style video game since the generated video games never existed it wouldn t even be stealing maybe more on this later
video game art in those days was very simple since the nes had such a small amount of memory the games used way less memory than this article takes up programmers had to use lots of tricks to fit the game art into memory to maximize the limited space games used tile based graphics where each screen in the game is made up of just a few usually x pixel repeated graphical tiles
for example the starting screen of the legend of zelda is made up of only unique tiles
here are the tiles for entire the legend of zelda game map
our goal is to create a similar tile sheet for our game because of that we don t really care if the game screenshots we generate look completely realistic instead we re just looking for the shapes and patterns that we can use as x tiles in our game things like stones water bridges etc then we can use those tiles to build our own bit style video game levels
to train our system we need lots of data luckily there are over games for the nes that we can pull from
i used wget to download all the nes game screenshots on the video game museum website sorry for scraping your site after a few minutes of downloading i had a little over screenshots of hundreds of nes games
right now dcgans only work on pretty small images pixels square or so but the entire screen resolution of the nes was only pixels by pixels so that s not a problem to make things simple i cropped each nes screenshot to pixels square
there are several open source implementations of dcgans on github that you can try out i used taehoon kim s tensorflow implementation since dcgans are unsupervised all you have to do is put the data in a folder tweak the basic parameters start it training and then wait to see what results you get
here s what a sample of the original training data looks like
now training begins at first the output from the generator is pure noise but it slowly start to take shape as the generator learns to do a better job
after several more training rounds the images start to resemble nightmare ish versions of classic nintendo games
as training continues further we start to see the bricks and blocks we are hoping to find you can also see screen elements like life bars and even some text
this is where things get complicated how do we know the computer is creating brand new art and not just regurgitating art directly from the training images in two of these images you can clearly see the menu bar from super mario bros and the header bar and bricks from the original super mario bros
regurgitating training data is definitely something that can happen by using a large training data set and not training too long we can try to reduce the chance that this happens but it s a thorny issue and research on it continues
since i m just going for aesthetics i tweaked the model until it produced art that looked original to me but i can t prove that the new art is totally original except by searching the training data for similar art and verifying that there isn t any
with a few hours of training the generated images contained x tiles that looked nice to me i was looking for some variations on a basic stone block brick patterns water patterns bushes and some general spooky looking background atmosphere tiles
next i need to pre process the generated images to the make sure they only used the colors that are available on the nes
then i ll open up the color images in the tiled map editor from there i can easily grab the x tiles that match the aesthetic i want
then inside of tiled map editor i ll arrange those x tiles into a simple level layout reminiscent of the nes game castlevania
i think that looks pretty good keep in mind i didn t touch a single pixel with an image editor every tile came straight out of the dcgan model
next let s throw in the main character and some enemies from castlevania so we can see what this level would look like in action
to get the full effect let s see what the level would look like inside the game with the menu elements added
i think that looks like the nes games that i remember i m not claiming it s the best nes art ever created but it s certainly not the worst
i get really excited about generative models like this the idea of one day cranking out endless artwork with computers is fascinating to me but when i talk to other people about this stuff sometimes the response is is that it that s so basic
there s certainly a lot of hype around generative models right now gans are already being called the future of ai despite being notoriously hard to train and limited to generating tiny images in fact the very best models can currently only generate postage stamp sized pictures of mutant dogs
but a couple of years ago we couldn t do anything close to that we were pretty excited by generated pictures that looked like this
and the technology is improving every single day here s a random paper that came out this week that uses gans to age the faces of people
if things keep improving at this pace it won t be too long before generative models are a mainstream tool helping us create it s a great time to start experimenting
if you want to learn more in depth about generative models and dcgans here are some recommended resources
this article is part of my machine learning is fun series you can check out the earlier parts here part part part part part and part
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
this article is part of an on going series on nlp part part you can also read a reader translated version of this article in
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
computers are great at working with structured data like spreadsheets and database tables but us humans usually communicate in words not in tables that s unfortunate for computers
a lot of information in the world is unstructured raw text in english or another human language how can we get a computer to understand unstructured text and extract data from it
natural language processing or nlp is the sub field of ai that is focused on enabling computers to understand and process human languages let s check out how nlp works and learn how to write programs that can extract information out of raw text using python
note if you don t care how nlp works and just want to cut and paste some code skip way down to the section called coding the nlp pipeline in python
as long as computers have been around programmers have been trying to write programs that understand languages like english the reason is pretty obvious humans have been writing things down for thousands of years and it would be really helpful if a computer could read and understand all that data
computers can t yet truly understand english in the way that humans do but they can already do a lot in certain limited areas what you can do with nlp already seems like magic you might be able to save a lot of time by applying nlp techniques to your own projects
and even better the latest advances in nlp are easily accessible through open source python libraries like spacy textacy and neuralcoref what you can do with just a few lines of python is amazing
the process of reading and understanding english is very complex and that s not even considering that english doesn t follow logical and consistent rules for example what does this news headline mean
are the regulators questioning a business owner about burning coal illegally or are the regulators literally cooking the business owner as you can see parsing english with a computer is going to be complicated
doing anything complicated in machine learning usually means building a pipeline the idea is to break up your problem into very small pieces and then use machine learning to solve each smaller piece separately then by chaining together several machine learning models that feed into each other you can do very complicated things
and that s exactly the strategy we are going to use for nlp we ll break down the process of understanding english into small chunks and see how each one works
let s look at a piece of text from wikipedia
this paragraph contains several useful facts it would be great if a computer could read this text and understand that london is a city london is located in england london was settled by romans and so on but to get there we have to first teach our computer the most basic concepts of written language and then move up from there
the first step in the pipeline is to break the text apart into separate sentences that gives us this
we can assume that each sentence in english is a separate thought or idea it will be a lot easier to write a program to understand a single sentence than to understand a whole paragraph
coding a sentence segmentation model can be as simple as splitting apart sentences whenever you see a punctuation mark but modern nlp pipelines often use more complex techniques that work even when a document isn t formatted cleanly
now that we ve split our document into sentences we can process them one at a time let s start with the first sentence from our document
the next step in our pipeline is to break this sentence into separate words or tokens this is called tokenization this is the result
tokenization is easy to do in english we ll just split apart words whenever there s a space between them and we ll also treat punctuation marks as separate tokens since punctuation also has meaning
next we ll look at each token and try to guess its part of speech whether it is a noun a verb an adjective and so on knowing the role of each word in the sentence will help us start to figure out what the sentence is talking about
we can do this by feeding each word and some extra words around it for context into a pre trained part of speech classification model
the part of speech model was originally trained by feeding it millions of english sentences with each word s part of speech already tagged and having it learn to replicate that behavior
keep in mind that the model is completely based on statistics it doesn t actually understand what the words mean in the same way that humans do it just knows how to guess a part of speech based on similar sentences and words it has seen before
after processing the whole sentence we ll have a result like this
with this information we can already start to glean some very basic meaning for example we can see that the nouns in the sentence include london and capital so the sentence is probably talking about london
in english and most languages words appear in different forms look at these two sentences
i had a pony
i had two ponies
both sentences talk about the noun pony but they are using different inflections when working with text in a computer it is helpful to know the base form of each word so that you know that both sentences are talking about the same concept otherwise the strings pony and ponies look like two totally different words to a computer
in nlp we call finding this process lemmatization figuring out the most basic form or lemma of each word in the sentence
the same thing applies to verbs we can also lemmatize verbs by finding their root unconjugated form so i had two ponies becomes i have two pony
lemmatization is typically done by having a look up table of the lemma forms of words based on their part of speech and possibly having some custom rules to handle words that you ve never seen before
here s what our sentence looks like after lemmatization adds in the root form of our verb
the only change we made was turning is into be
next we want to consider the importance of a each word in the sentence english has a lot of filler words that appear very frequently like and the and a when doing statistics on text these words introduce a lot of noise since they appear way more frequently than other words some nlp pipelines will flag them as stop words that is words that you might want to filter out before doing any statistical analysis
here s how our sentence looks with the stop words grayed out
stop words are usually identified by just by checking a hardcoded list of known stop words but there s no standard list of stop words that is appropriate for all applications the list of words to ignore can vary depending on your application
for example if you are building a rock band search engine you want to make sure you don t ignore the word the because not only does the word the appear in a lot of band names there s a famous s rock band called the the
the next step is to figure out how all the words in our sentence relate to each other this is called dependency parsing
the goal is to build a tree that assigns a single parent word to each word in the sentence the root of the tree will be the main verb in the sentence here s what the beginning of the parse tree will look like for our sentence
but we can go one step further in addition to identifying the parent word of each word we can also predict the type of relationship that exists between those two words
this parse tree shows us that the subject of the sentence is the noun london and it has a be relationship with capital we finally know something useful london is a capital and if we followed the complete parse tree for the sentence beyond what is shown we would even found out that london is the capital of the united kingdom
just like how we predicted parts of speech earlier using a machine learning model dependency parsing also works by feeding words into a machine learning model and outputting a result but parsing word dependencies is particularly complex task and would require an entire article to explain in any detail if you are curious how it works a great place to start reading is matthew honnibal s excellent article parsing english in lines of python
but despite a note from the author in saying that this approach is now standard it s actually out of date and not even used by the author anymore in google released a new dependency parser called parsey mcparseface which outperformed previous benchmarks using a new deep learning approach which quickly spread throughout the industry then a year later they released an even newer model called parseysaurus which improved things further in other words parsing techniques are still an active area of research and constantly changing and improving
it s also important to remember that many english sentences are ambiguous and just really hard to parse in those cases the model will make a guess based on what parsed version of the sentence seems most likely but it s not perfect and sometimes the model will be embarrassingly wrong but over time our nlp models will continue to get better at parsing text in a sensible way
want to try out dependency parsing on your own sentence there s a great interactive demo from the spacy team here
so far we ve treated every word in our sentence as a separate entity but sometimes it makes more sense to group together the words that represent a single idea or thing we can use the information from the dependency parse tree to automatically group together words that are all talking about the same thing
for example instead of this
we can group the noun phrases to generate this
whether or not we do this step depends on our end goal but it s often a quick and easy way to simplify the sentence if we don t need extra detail about which words are adjectives and instead care more about extracting complete ideas
now that we ve done all that hard work we can finally move beyond grade school grammar and start actually extracting ideas
in our sentence we have the following nouns
some of these nouns present real things in the world for example london england and united kingdom represent physical places on a map it would be nice to be able to detect that with that information we could automatically extract a list of real world places mentioned in a document using nlp
the goal of named entity recognition or ner is to detect and label these nouns with the real world concepts that they represent here s what our sentence looks like after running each token through our ner tagging model
but ner systems aren t just doing a simple dictionary lookup instead they are using the context of how a word appears in the sentence and a statistical model to guess which type of noun a word represents a good ner system can tell the difference between brooklyn decker the person and the place brooklyn using context clues
here are just some of the kinds of objects that a typical ner system can tag
ner has tons of uses since it makes it so easy to grab structured data out of text it s one of the easiest ways to quickly get value out of an nlp pipeline
want to try out named entity recognition yourself there s another great interactive demo from spacy here
at this point we already have a useful representation of our sentence we know the parts of speech for each word how the words relate to each other and which words are talking about named entities
however we still have one big problem english is full of pronouns words like he she and it these are shortcuts that we use instead of writing out names over and over in each sentence humans can keep track of what these words represent based on context but our nlp model doesn t know what pronouns mean because it only examines one sentence at a time
let s look at the third sentence in our document
if we parse this with our nlp pipeline we ll know that it was founded by romans but it s a lot more useful to know that london was founded by romans
as a human reading this sentence you can easily figure out that it means london the goal of coreference resolution is to figure out this same mapping by tracking pronouns across sentences we want to figure out all the words that are referring to the same entity
here s the result of running coreference resolution on our document for the word london
with coreference information combined with the parse tree and named entity information we should be able to extract a lot of information out of this document
coreference resolution is one of the most difficult steps in our pipeline to implement it s even more difficult than sentence parsing recent advances in deep learning have resulted in new approaches that are more accurate but it isn t perfect yet if you want to learn more about how it works start here
want to play with co reference resolution check out this great co reference resolution demo from hugging face
here s an overview of our complete nlp pipeline
whew that s a lot of steps
note before we continue it s worth mentioning that these are the steps in a typical nlp pipeline but you will skip steps or re order steps depending on what you want to do and how your nlp library is implemented for example some libraries like spacy do sentence segmentation much later in the pipeline using the results of the dependency parse
so how do we code this pipeline thanks to amazing python libraries like spacy it s already done the steps are all coded and ready for you to use
first assuming you have python installed already you can install spacy like this
then the code to run an nlp pipeline on a piece of text looks like this
if you run that you ll get a list of named entities and entity types detected in our document
you can look up what each of those entity codes means here
notice that it makes a mistake on londinium and thinks it is the name of a person instead of a place this is probably because there was nothing in the training data set similar to that and it made a best guess named entity detection often requires a little bit of model fine tuning if you are parsing text that has unique or specialized terms like this
let s take the idea of detecting entities and twist it around to build a data scrubber let s say you are trying to comply with the new gdpr privacy regulations and you ve discovered that you have thousands of documents with personally identifiable information in them like people s names you ve been given the task of removing any and all names from your documents
going through thousands of documents and trying to redact all the names by hand could take years but with nlp it s a breeze here s a simple scrubber that removes all the names it detects
and if you run that you ll see that it works as expected
what you can do with spacy right out of the box is pretty amazing but you can also use the parsed output from spacy as the input to more complex data extraction algorithms there s a python library called textacy that implements several common data extraction algorithms on top of spacy it s a great starting point
one of the algorithms it implements is called semi structured statement extraction we can use it to search the parse tree for simple statements where the subject is london and the verb is a form of be that should help us find facts about london
here s how that looks in code
and here s what it prints
maybe that s not too impressive but if you run that same code on the entire london wikipedia article text instead of just three sentences you ll get this more impressive result
now things are getting interesting that s a pretty impressive amount of information we ve collected automatically
for extra credit try installing the neuralcoref library and adding coreference resolution to your pipeline that will get you a few more facts since it will catch sentences that talk about it instead of mentioning london directly
by looking through the spacy docs and textacy docs you ll see lots of examples of the ways you can work with parsed text what we ve seen so far is just a tiny sample
here s another practical example imagine that you were building a website that let s the user view information for every city in the world using the information we extracted in the last example
if you had a search feature on the website it might be nice to autocomplete common search queries like google does
but to do this we need a list of possible completions to suggest to the user we can use nlp to quickly generate this data
here s one way to extract frequently mentioned noun chunks from a document
if you run that on the london wikipedia article you ll get output like this
this is just a tiny taste of what you can do with nlp in future posts we ll talk about other applications of nlp like text classification and how systems like amazon alexa parse questions
but until then install spacy and start playing around or if you aren t a python user and end up using a different nlp library the ideas should all work roughly the same way
this article is part of an on going series on nlp you can continue on to part
if you liked this article consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
a summary from reading the post by jason brownlee post on machinelearningmastery com here s the original link https machinelearningmastery com improve deep learning performance
the gains often get smaller the further down the list for example a new framing of your problem or more data is often going to give you more payoff than tuning the parameters of your best performing algorithm not always but in general
in fact you can often get good performance from combining the predictions from multiple good enough models rather than from multiple highly tuned and fragile models
let s begin by removing black box algorithms from core public agencies
today we released our second annual research report on the state of artificial intelligence since last year s report we ve seen early stage ai technologies continue to filter into many everyday systems from scanning faces at airport security to recommending to hire someone to granting someone bail to denying someone a loan this report was developed for our annual ai now experts workshop which included invited researchers across relevant domains and it reflects a range of views that were discussed at the event
while ai holds significant promise we re seeing significant challenges in the rapid push to integrate these systems into high stakes domains in criminal justice a team at propublica and multiple academics since have investigated how an algorithm used by courts and law enforcement to predict recidivism in criminal defendants may be introducing significant bias against african americans in a healthcare setting a study at the university of pittsburgh medical center observed that an ai system used to triage pneumonia patients was missing a major risk factor for severe complications in the education field teachers in texas successfully sued their school district for evaluating them based on a black box algorithm which was exposed to be deeply flawed
this handful of examples is just the start there s much more we do not yet know part of the challenge is that the industry currently lacks standardized methods for testing and auditing ai systems to ensure they are safe and not amplifying bias yet early stage ai systems are being introduced simultaneously across multiple areas including healthcare finance law education and the workplace these systems are increasingly being used to predict everything from our taste in music to our likelihood of experiencing mental illness to our fitness for a job or a loan
the problem here is not the willful misuse of ai it s that ai and related technologies are being used without processes or standards to ensure safety or fairness or without a deeper consideration of their complex social interactions when a new drug is released into the marketplace it must first undergo rigorous scientific trials and testing and continued monitoring of its medium and long term effects care and caution is paramount in this domain because if things go wrong many people experience significant harm the same is true for ai systems in high stakes domains
as part of our report we are offering ten recommendations for the ai industry researchers and policy makers we ve listed these recommendations below along with some additional context for each these recommendations aren t the solution they are a starting place for much needed further work while the deployment of ai products is moving quickly research into bias and fairness are in their early stages and there is much to be done if we re going to ensure that ai systems are deployed and managed responsibly that will require a joint effort for our part we are committed to further research on these issues and sharing that with the wider community we think it s urgently needed finally if you re interested in pursuing a postdoctoral fellowship centered on the social implications of ai we hope you ll consider joining us in this effort
core public agencies such as those responsible for criminal justice healthcare welfare and education e g high stakes domains should no longer use black box ai and algorithmic systems this includes the unreviewed or unvalidated use of pre trained models ai systems licensed from third party vendors and algorithmic processes created in house the use of such systems by public agencies raises serious due process concerns and at a minimum such systems should be available for public auditing testing and review and subject to accountability standards
this would represent a significant shift our recommendation reflects the major decisions that ai and related systems are already influencing and the multiple studies providing evidence of bias in the last twelve months as detailed in our report others are also moving in this direction from the ruling in favor of teachers in texas to the current process underway in new york city this month where the city council is considering a bill to ensure transparency and testing of algorithmic decision making systems
before releasing an ai system companies should run rigorous pre release trials to ensure that they will not amplify biases and errors due to any issues with the training data algorithms or other elements of system design as this is a rapidly changing field the methods and assumptions by which such testing is conducted along with the results should be openly documented and publicly available with clear versioning to accommodate updates and new findings
we believe that those who develop and profit from these systems should be responsible for leading testing and assurance including pre release trials we recognize that the field is a long way from standardized methods which is why we recommend that these methods and assumptions are open for scrutiny and discussion this openness will be crucial if the ai field is to develop robust testing standards over time we also recognize that testing in a lab even with standardized methods may not catch all errors and blind spots which leads us to recommendation
after releasing an ai system companies should continue to monitor its use across different contexts and communities the methods and outcomes of monitoring should be defined through open academically rigorous processes and should be accountable to the public particularly in high stakes decision making contexts the views and experiences of traditionally marginalized communities should be prioritized
ensuring that ai and algorithmic systems are safe is extraordinarily complex and needs to be an ongoing process through the life cycle of a given system it s not a compliance checkbox that can be completed and forgotten monitoring across dynamic use cases and contexts is needed to ensure ai systems don t introduce errors and bias as cultural assumptions and domains shift and change it is also important to note that many ai models and systems are general purpose where products might use plug and play add ons like emotion detection or facial recognition capabilities this means that those offering general purpose ai models could also consider the option of licensing for approved uses where potential downsides and risks have been considered
more research and policy making is needed on the use of ai systems in workplace management and monitoring including hiring and hr this research will complement the existing focus on worker replacement via automation specific attention should be given to the potential impact on labor rights and practices and should focus especially on the potential for behavioral manipulation and the unintended reinforcement of bias in hiring and promotion
the debate around ai and labor usually focuses on the displacement of human workers which is a very serious concern however we think it s just as important to track how ai and algorithmic systems are used within today s workplaces for everything from behavioural nudging to surveillance to rating performance for example a company called hirevue recently deployed an ai based video interviewing service which analyzes a job applicant s speech body language and tone to determine whether the applicant matches the model of top performers at a given company given the potential of these systems to reduce diversity and entrench existing biases more work is needed to fully understand how ai is being integrated into management hiring scheduling and the structures and practices of everyday workplaces
develop standards to track the provenance development and use of training datasets throughout their life cycle this is necessary to better understand and monitor issues of bias and representational skews in addition to developing better records for how a training dataset was created and maintained social scientists and measurement researchers within the ai bias research field should continue to examine existing training datasets and work to understand potential blind spots and biases that may already be at work
ai relies on large scale data in order to detect patterns and make predictions this data reflects human history and inevitably reflects biases and prejudices from the training dataset machine learning techniques excel at picking up such statistical patterns often omitting diverse outliers in an attempt to generalize the common cases this is why it is important that research into bias not take data at face value and that such research begin by understanding where data used to train ai systems came from tracking how such data is used across systems and validating the methods and assumptions that shape a given dataset over time by understanding this we can better understand errors and bias reflected in data and develop ways of recognizing and possibly mitigating them during data creation and collection
expand ai bias research and mitigation strategies beyond a narrowly technical approach bias issues are long term and structural and contending with them necessitates deep interdisciplinary research technical approaches that look for a one time fix for fairness risk oversimplifying the complexity of social systems within each domain such as education healthcare or criminal justice legacies of bias and movements toward equality have their own histories and practices legacies of bias cannot be solved without drawing on domain expertise addressing fairness meaningfully will require interdisciplinary collaboration and methods of listening across different disciplines
the recent increase in work on ai and algorithmic bias is an excellent sign but we caution against taking a purely technical approach otherwise there is a risk that systems are merely optimized without knowing what to optimize for computer scientists can learn more about underlying structural inequalities that shape data and the contextual integration of ai systems by collaborating with domain experts in fields like law medicine sociology anthropology and communication
strong standards for auditing and understanding the use of ai systems in the wild are urgently needed creating such standards will require the perspectives of diverse disciplines and coalitions the process by which such standards are developed should be publicly accountable academically rigorous and subject to periodic review and revision
currently there are no established methods for measuring and assessing the impacts of ai systems as they are used in specific social contexts this is a significant problem given the determinations that early stage ai systems are already influencing across multiple high stakes domains developing such standards and methods should be an urgent priority for the ai field
companies universities conferences and other stakeholders in the ai field should release data on the participation of women minorities and other marginalized groups within ai research and development many now recognize that the current lack of diversity in ai is a serious issue yet there is insufficiently granular data on the scope of the problem which is needed to measure progress beyond this we need a deeper assessment of workplace cultures in the technology industry which requires going beyond simply hiring more women and minorities toward building more genuinely inclusive workplaces
the assumptions and perspectives of those who create ai systems will necessarily shape them ai developers are often male white and with similar backgrounds in terms of education and training we have already seen evidence that this causes problems from voice recognition systems that don t hear women to ai assistants that fail to give information on women s health however beyond general tech industry diversity statistics there are few efforts to quantify and better understand the issue of diversity in the ai field specifically if ai is to be safe fair and widely relevant efforts need to be made not only to track diversity and inclusion but also to ensure that the culture in which ai is being designed and developed is welcoming to women minorities and other marginalized groups
the ai industry should hire experts from disciplines beyond computer science and engineering and ensure they have decision making power as ai moves into diverse social and institutional domains influencing increasingly high stakes decisions efforts must be made to integrate social scientists legal scholars and others with domain expertise that can guide the creation and integration of ai into long standing systems with established practices and norms
just as we wouldn t expect a lawyer to optimize a deep neural network we shouldn t expect technical ai researchers and engineers to be experts in criminal justice or any of the other social domains where technical systems are being integrated we need domain experts to be at the table to help lead decision making and ensure ai systems don t naively misunderstand the complex processes histories and contexts in areas like law health and education
ethical codes meant to steer the ai field should be accompanied by strong oversight and accountability mechanisms more work is needed on how to substantively connect high level ethical principles and guidelines for best practices to everyday development processes promotion and product release cycles
several computing industry groups are developing ethical codes to help ensure the development of safe and fair ai detailed further in our report however these codes are voluntary and generally high level asking ai developers to prioritize the common good but how should the common good be determined and by whom in addition to questions of representation such codes will need to be connected to clear systems of accountability while also remaining conscious of the incentive structures and power asymmetries at work in the ai industry
researching the social implications of artificial intelligence now to ensure a more equitable future
on june the forum for future medical technology and artificial intelligence conference hosted by bio valley was held in shanghai the goal of the conference was to share and discuss the development and application of artificial intelligence in the medical field
the panel of speakers at the conference included prof jianwei zhang director of the institute of the multi modal technology systems and professor at the university of hamburg in germany mr ray zhang founder and ceo of airdoc mr fabao zhang chairman of shanghai metz pharmaceutical technology co mr xubo hu the managing partner at qiming venture partners
since the discovery of x ray in x ray has been widely used to examine the human body to assist in the diagnosis of diseases laying the basis for radiological and medical imaging medical imaging has now become the most common diagnostic diagnostic tool
over the past few decades medical imaging technology in china has developed rapidly however imaging specialists have been in short supply and mainly concentrated in large hospitals of large cities many small and medium size cities do not have adequate imaging diagnostics resources patients in smaller cities have found it necessary to travel to big cities in order to seek proper medical treatment
airdoc aims to solve the problem of inadequate medical imaging resources by leveraging scalable technology artificial intelligence airdoc equips many smaller community level health care institutions with ai medical image recognition capability previously only available at the best hospitals
in the years since the conception of artificial intelligence lack of computing power and immature algorithms impeded its development in the advent of deep learning brought significant revival to artificial intelligence in the emergence of alexnet brought about a turning point in ai at the large scale visual recognition challenge ilsvrc alexnet bested the previous year s top error by percentage points ever since artificial intelligence in the field of image recognition has constantly been making and breaking records
in recent years articles appearing in nature jama science and other authoritative medical journals have begun writing about using artificial intelligence to solve medical problems for example artificial intelligence identifies skin cancer appeared on the cover of nature science magazine reported on computers predicting heart attack at higher accuracy rate than that of human doctors etc meanwhile major chinese hospitals have also begun to seriously study clinical applications of artificial intelligence
ray zhang asserts that artificial intelligence has virtually limitless possibilities in the medical field a few examples besides medical imaging include virtual nurse assistant health management medical risk analysis drug extraction auxiliary diagnosis and medical research but medical artificial intelligence is still in its infancy but its role in medical imaging recognition is well on its way
in medical image recognition the development of artificial intelligence requires massive numbers of medical images to generate algorithm models data volume and data quality are critical high data volume increases the model s inclusion rate while accurate data and annotations ensure high accuracy of the model s training and test sets
ray zhang dalei contends that within the next years artificial intelligence will play a critical role in the medical field artificial intelligence will be the core driving force behind the next revolution in medicine ai can thoroughly analyze and aggregate medical knowledge to help provide higher quality clinical advice
with its comprehensive inter disciplinary integration ai is set to facilitate the evolution of economic patterns by transforming across commercial financial and medical industries
airdoc is a deep learning based algorithm services company providing ai medical solutions
here i introduce the concept of automated learning learning by induction and other learning methods
this article is part of series of articles about the fundamental theories behind machine learning
in order to create systems that are able to learn autonomously we have to understand what learning is learning is in essence the ability of turning experience into expertise or knowledge for example a baby at some point may not know how to detect the voice of family members but as he interacts with them and hears each one of their voices accompanied by their face it slowly learns to detect the voice of each family member and after a few months it becomes an expert at identifying the voices of each family member in the context of the baby example what do we call the input it receives and what would be the output the input that the babies brain receives we call the training data which represents experience and the output would be some expertise what then is the expertise that the baby acquired in this case the expertise that the baby acquired is the ability to identify the voice of each family member
as we are seeking a formal mathematical understanding of this concept we need to ask ourselves the following questions what is the training data our learning system will need how can learning be automated how can we evaluate the success or failure of such a system
let us consider an example of learning by analyzing two fictional monkeys called a and b respectively who are both taking an online course on algebra a and b learn in very different ways monkey a and b are both shown equations similar to the ones below
they are not given any explanations on how to solve the equations and have never taken maths classes before they are given hour to find a strategy that they must use to solve equations in a test they will receive after that hour has passed
monkey a decides to memorize all equations monkey b analyzes the equations and tries to find patterns in the equations when given a test with equations they have never seen before which of the monkeys is most likely to solve them correctly obviously it s monkey b
what strategies did the monkeys use to learn why would monkey b perform better than a well monkey a used a technique called learning by memorization while monkey b used inductive reasoning also called inductive inference inductive reasoning is the cognitive process of making observations discerning a pattern in order to make generalizations a hallmark of a successful learning system is the ability to progress from a few examples to broader generalizations
great so we know inductive reasoning is a hallmark of a successful learning system but will it be consistent in providing us with the right conclusions
let us seek out this answer by means of a example of inductive reasoning i have a bag i put my hands in the bag and take out a banana i put my hands in the bag again and out comes another banana i put my hands in the bag once again and out comes another banana my bag only has bananas did you notice that this matches our earlier definition of inductive reasoning observe discern patterns and make generalizations is it reasonable to conclude that everything in the bag is a banana just because we have observed bananas came out of it would it be reasonable to conclude that every bag will also have bananas you answer could sway either way but if we are to create good learning systems we must prove formally that it will succeed to consistently draw true conclusions unfortunately it is clear that inductive reasoning will fail to be consistent and thus return false conclusions
let us go back to the monkey maths dilemma where monkey b used inductive reasoning to solve equations it is clear that it s learning method is superior to monkey a s method but as we have concluded above it will not be consistent at always returning true conclusions therefore we have two options either scrape the entire inductive reasoning method or add some modification to it in order to enhance its learning capability we could effectively allow monkey b to perform better on the test by giving monkey b some prior knowledge about terms variables expressions equations and patterns it should ignore as well as patterns it should pay attention to the incorporation of prior knowledge that biases monkey b s learning process is called inductive bias monkey b will now be bias to detecting certain patterns in the equations while ignoring others it turns out that the incorporation of prior knowledge is one of key concepts to understand in order to build a successful learning system and we will dig deeper into these concepts in later articles
machine learning is often used to solve the following classes of problems
when we have tasks that are extremely complicated to code by hand for example detecting hand written digits detecting faces in pictures and natural language processing it is far too difficult to create a well defined step by step solution to these kinds of problems
when we want programs that adapt to changes or environments for example recommendation engines that adapts to users preferences speech recognition systems that adapt to variations in a users voice and programs that adapt to variations in hand writing
supervised learning is a method of learning in which a teacher helps train the learner by providing the correct labels for the data this data is called training data or a training data set for example let s say we have a set of bananas b b b b b the teacher would then provide the correct labels for each element of the banana set labels ripe not ripe ripe ripe this labeling process is akin to giving our monkey prior knowledge in order for it to successfully accomplish the task it was given to learn
formally this training data will usually be some n dimensional vector which will be input to a learning system that uses inference to label unseen data the teacher thus guides the learner in it s learning task
these types of learning methods are split into classification and regression problems and later on we will get into the specifics of these kinds of problems
unsupervised learning is slightly different to the previous method as the learner is not provided with the correct labels nor a teacher to guide it examples of this type of learning is common in humans humans do not need labels to learn do you know of a baby that was given labels to learn to identify it s mother face or voice these learning systems are split into clustering and association problems
reinforcement and semi supervised learning are techniques that are used in various learning systems and will be discussed in future articles
machine learning shares common roots to statistics information theory game theory and optimization calculus it is a sub field of computer science since our objective here is to program machines that will learn it is also a branch of artificial intelligence however note that machine learning s goal is not create an automated imitation of intelligent behavior as seen in humans but rather use the capabilities of computers to compliment human intelligence in contrast with humans computers can analyze billions of terabytes of data that we can never dream of they can also run very complex calculations an order of magnitude faster then our biological brains it is only common sense to use these capabilities to enhance our society and our own intelligence
in the next article we will be introduced to the statistical learning model and other concepts which will be the foundation to fully understand these automated learning systems
if you enjoyed reading this make sure to follow and as well share it with friends family oh and every monkey you know cheers
software developer open source enthusiast security nerd techie member of gdgluanda
when dennis r mortensen hired his founding team members at x ai he pitched them by illustrating his vision of a world where everyone has a personal assistant to schedule their meetings recognizing the complexity of the challenge he concluded by saying we may die trying
it s a great setting to hire qualified people dennis says recounting the late days of we re working on something that is clearly very hard to the extent that we might not make it but it s not impossible that s the sweet spot he says when a calling finds you that is incredibly challenging yet still attainable even if only at your fingertips it s right in the middle he continues it s not a weekend hackathon but it s not space travel either it s that area right in between where you find the best people
x ai has since grown to team members who dennis refers to as propeller heads who are working day in and day out to bring amy and andrew ingram whom many of you know to life
from his initial meetings with his seed investors including ia ventures lerer hippeau ventures and softbank capital to our first conversation in early dennis has been adamant in demonstrating his long term perspective for x ai countless solutions currently exist to schedule meetings actual assistants virtual assistants apps plug ins and websites the list goes on and each has a different price point
x ai has taken a different approach to developing amy they refer to her and her brother as invisible software she can never be an app plugin or website amy has to exist in dialogue you would never go up to your assistant at the front of your office and say show me your features what can you do for me it would be completely unacceptable dennis affirms
the goal is for amy to feel and communicate like a human and she does if you ve ever had an interaction with her you ll find yourself asking how her day is and thanking her more than individuals have even asked her on a date x ai has an ai interaction designer who focuses specifically on developing these humanistic conversational skills
when you communicate with amy you should forget that she is a machine because it doesn t matter you can be confident that when you tell her something she understands and will do what you requested the mission has required two years of deep learning testing and iteration the first was spent primarily gathering data and developing the tools that would enable the team to start building amy according to dennis they are building the tools to build the machine while building the machine
in the darkest hours of our first year there was no meeting data that we could acquire and model on top of nothing zero he says we started out by setting up one meeting then another then and so on until we went through millions of emails that we annotated with great pain so we can create models on top of them
despite acquiring foundational knowledge the last two years the challenge is significantly more complex than the message that appears in our inboxes take the response sure jessica how about next tuesday thursday around sent at p m on sunday night countless questions arise for amy or andrew on the other side of this exchange is jessica referring to this upcoming tuesday and thursday or the following does wednesday count is she referring to exactly or perhaps or will this be a morning meeting or an evening meeting will you be commuting from a prior meeting if so from where the most significant question then is how do they proceed
little things turn into massive complexities on our end dennis asserts the more we learn the more ambiguity we see in everything that humans do the less complexity you put on the user side the more you have to put on the creator
the mentality appears intense but scheduling meetings is a vital part of our personal and professional lives say you re meeting with an investor to close your funding round and amy makes a mistake there is simply no room for error it is precisely because of this that x ai has made your calendar their sole focus despite requests from customers asking for more capabilities such as arranging deliveries or scheduling travel
we just want to perfect amy we want her to be so good that even if you can hire a human to perform this task you won t need or want to dennis says the goal is for amy to grow up to be an adult who can handle everything on her own without human intervention x ai is on track to achieve that as the team prepares to release their first paid product this autumn we are working on a clearly defined list as we speak dennis confirms we know exactly what we need to work on to make amy into a superhuman when it comes to setting up meetings
similar to self driving cars flawless artificial intelligence isn t going to be ready overnight the progress will be based on deliberate experimentation slow growth and most importantly resilient pioneers it s not reasonable to think that an ai agent is going to arrive at an oracle level dennis says
the more likely scenario according to dennis will be a team of vertical ai agents meaning that we ll have individual artificial intelligence agents who each work on a single task for us such as scheduling our meetings booking travel or ordering our groceries for example if you re traveling to los angeles your ai travel agent will arrange your flights hotel and transportation amy or andrew will then communicate with him or her to determine the best place to schedule your meetings based on your arrival time distance to the hotel and trip duration your input will not be required
our lack of participation raises what dennis believes is the common misconception that ai will lead to doomsday scenarios with little human interaction and mass unemployment
we all read the same blogs asserting that creating ai is like summoning the devil i just don t believe that no one has ever come up to you and congratulated you on scheduling a meeting it s a task we are given when we don t have anyone else to do it there is no creativity required i can t play out a scenario where we end up worse
dennis believes that ai will free us to do the things that we excel at and are passionate about like brainstorming ideas creating art or leading our teams artificial intelligence is an agent for change enabling us to catalyze on our creative pursuits he says it will never replace human ingenuity
to follow along with amy and learn about the future of ai subscribe to x ai s blog where you can learn about topics like how to think about ai agents in the future and sign up for the waitlist here
originally published at www voices com
voices is a community for entrepreneurs to grow their businesses and design their lives
we take our rights for granted we figure they are a regular part of life we also assume we will continue to have these rights and privileges forever
but what if we only have these rights because we were born at the right time in the right place what if these rights and privileges only exist because they make us more valuable to the state said another way we get them because they make us better workers
if this is true does it mean in time things will change what if our economies stop functioning the way they do could these motivations disappear if collected taxes reduce or governments run out of cash will they stop protecting us
even the most fundamental right the right to vote comes from the idea that we are valuable to our countries in exchange for working we have the right to have our voices heard
robots and ai are poised to take over the world by doing most of the work will we be valued for our ability to work when a computer can do it better if this were to happen we would stop being valuable to the economy if we aren t of value our opinions will stop mattering as well
in canada we have what we call free health care though we all pay for it the main reason our governments use our tax dollars to pay for this service is that it helps us work better in turn working better is of value to the corporations that pay taxes to the government so it works out
if we get sick the health care system repairs us so we can return to work when companies no longer need us they won t want governments to pay for our healthcare the same reasoning would go for education and public transit
today we can already see this happening in ways homeless people tend not to contribute to the economy so they slip through the cracks in a sense they become invisible
in practice without an address it is difficult to vote even worse it is hard to get a job or an id as people become useless they fall away from societal support
proximity also relates to our consciousness of people as we see people less we have fewer thoughts about them and their importance to us decreases seeing people as useful is unfair but is often how our social connections work
on a grand scale as more jobs get replaced by robots and ai more humans will be forgotten people in general will become less valuable as they will provide less value
is there an easy way out of this situation will there be a future for regular people who don t create ai and robots
some companies will try to slow down this transition due to its cost but at some point it will become impossible to avoid letting the robots take over
in the future owning a robot or ai may be the only way to make money
even worse the people with all the money now will also have all the robots and ai with this the gap between the rich and poor will grow even more extreme
this future sounds scary but is there something we can do to avoid it what can we do to prepare
we need a better democracy also we need a political system where people matter more than money and efficiency we need to figure out better ways to reward people for the value they create
the world needs more amazing people and amazing people will save the world click the link below to receive my free ebook about ways to be amazing and a checklist how amazing are you
free ebook and checklist
originally published at abraintrust com
trying to save the world and be more amazing get my free ebook and checklist at http abraintrust com
by aditya
adityatheeditor outlook com
adityawrites outlook com
the fear of machines taking over has been debated for centuries through the medium of the fictional and facts genre there is hardly a bridge between the two in the terminator franchise we see how machines or robots will be sentient enough to perceive their makers as a threat
as time and technology have progressed the endeavor is not only to produce machines that can do work times faster than humans but they are trying to add features like problem solving decision making curiosity and deviating from the path as well it is about putting emotion in an otherwise empty hollow metallic creature or simply called as artificial intelligence
for such situations there will always be two schools of thought one which feels that excessive use of machines shrinks our otherwise organised brain which functions faster than any ai the other school of thought will argue that by letting the ai do the menial work we can use our natural cpu for other work where the ai might be conflicted
a neutral observer would simply point out that machines were created for the benefit of humans it is an aid from the wheel printing press to the telephone the telegram mobile phone and computers fax machines etc just as it inherent for humans to improve as one grows up but we are not flawless so our creation will suffer from the same
there has been a sudden rush to yearn for a machine less world but those who advocate such ideas for them machines include only mobile phones and computers but this is obviously a misconception on their part if we were to exclude all machinery from our existence that would have to include the pen the paper essentially every stationary item our shoes clothing shelter but then even nomads had some sense of technology when they indigenously made swords and arrows from whatever they could collect in the end everything we use is technology and we should not be myopic about the same the digital analogue rivalry is just the tip of the misconception if we feel that paper files are creating a mess then just digital uploading is not enough if we cannot organise on our tables that infliction will carry to the computer as well
the saying that humans are social animals is contradictory we cannot be in a community yet display animal or uncivilized behaviour at the same time one does not have to fear technology as they were meant to do aid us and engage in menial work if it is artificial it cannot be intelligence as we see two contradictory terms come together everything digital has been borrowed from the analogue people still wear a wristwatch despite the time being displayed on the phone so this fear will extinguish quickly the commuter does not make up data it only computes it stores it these debates just let our emotions and nostalgia about certain simple year s fly high even when unnecessary
democratization of artificial intelligence microsoft s promise to take the ai and machine learning from the ivory towers and make it accessible for all is starting to take shape quite effectively let s face it resource constraints around ai ml is a real problem most companies with real world ai use cases just don t have enough runway to build their own artificial intelligence offerings and microsoft cognitive services provide a sophisticated yet easy to use abstraction which fills this gap microsoft has also announced ai as an mvp category http aka ms aimvp for those creating intelligent apps bots voice txt spch and ai algorithms
being a microsoft mvp for data platforms i have had the front row seat to see how cognitive services a collection of powerful apis and toolkits unfold to fulfill the promise of ai democratization among top ai and machine learning related capabilities discussed at build i d consider
as top contenders with video index service as a close runner up
custom vision service
computer vision service has been part of cognitive services since the inception however this has been significantly enhanced by introducing active learning and custom models in the current update the api now offers the capability to upload your own image datasets to create custom vision models which becomes part of a feedback loop and helps to improve the underlying classification accuracy
https customvision ai
custom decision service
custom decision service provides a contextual decision making api that sharpens with experience essentially providing an abstraction over cognitive services reinforcement learning capabilities which helps adapts the content in the application think personalized interfaces a b testing content recommendations to respond in real time
custom decision service
multiworld testing decision service
azure batch ai training
batch ai training enables ai and machine learning developers to start training their customized deep neural networks using any framework yes not just cntk tensorflow and caffe
video index service
a ubiquitous use case for entertainment advertisement and media verticals like cognitive services image api video index service works on moving pictures to identify faces voices and emotions from captions to targeted advertisement to discovering relevant or irrelevant contents to avoid the service offers audio transcription video indexer face tracking and identification speaker indexing visual text recognition voice activity detection scene detection keyframe extraction sentiment analysis translation visual content moderation keywords extraction and annotation
https vi microsoft com
food classification with custom vision service
the cognitive services are classified into categories including vision speech language knowledge and search these broader categories offer further specific sub apis in the vision group we see an amazing collection of powerful computer vision apis around content moderation intelligent video processing video indexing face amp emotion api as well as the long awaited and newly minted custom vision service which allows users to upload their own images to create models
in speech custom speech service helps recognize variety of speaking styles works with background noise and customized vocabulary bing speech api speaker recognition api and translator services are provided the live demo of powerpoint translator service is definitely one of the build highlights
language understanding intelligent service luis is one of the marquee offerings in cognitive services which contains an entire suite of nlu nlp capabilities teaching applications to understand entities utterances and genera commands from user input other language services include bing spell check api which detect and correct spelling mistakes web language model api which helps building knowledge graphs using predictive language models text analytics api to perform topic modeling and do sentiment analysis as well as translator text api to perform automatic text translation the linguistic analysis api is a new addition which parses and provide context around language concepts
in the knowledge spectrum the recommendations api to help predict and recommend items knowledge exploration service to enable interactive search experiences over structured data via natural language inputs entity linking intelligence service for ner disambiguation academic knowledge api academic content in the microsoft academic graph search qna maker api and the newly minted custom decision service which provides a contextual decision making api with reinforcement learning features search apis include autosuggest news web image video and customized searches
some of the labs projects discussed during build includes project prague for gesture based controls nanjing project for isochrones calculations travel time project johannesburg for route logistics project cuzco for event associated with wikipedia entries project abu dhabi for distance matrix and project wollongong for location insights
i have very little reason to doubt satya nadella s claim that software bots will be as big as mobile apps there is already evidence of blurring lines as most applications use ai and machine learning as inherent part of their offering microsoft bot framework has also been upgraded this open source bot builder sdks helps build dialogs and integrates with cognitive services to see hear interpret and interact in more human ways
i have thoroughly enjoyed working with the bot framework and it provides variety of features including building the skype bots bing building bots for teams in office and skype for business bots the cognitive capabilities include features like bot smarts language understanding and qna maker the framework also offers tools like emulator which features debugging for mac windows and linux a channel inspector to show how the messages may look like on multiple channels and message types adaptive cards for conversation cards as well as payments request api and analytics on the bot usage
the next generation of ai chatbots amp cognitive services
microsoft continues ai push with expanded bot framework new cognitive services
hci classifies the ability of the computers to understand what a person wants as one of the key problems figuring out the pieces of information relevant to the intention is the key microsoft luis our language understanding intelligent service now enables building language models intents entities to understand actions entities and utterances luis is not specific to the bot framework but can be used as a general offering
azure batch ai training is now offered for training customized deep neural networks on azure the preview allows and this is the kicker here to train models using any framework including microsoft cognitive toolkit tensorflow and caffe at scale across clustered gpus
acknowledgements
images courtesy of microsoft corporation and adnan hashmi
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
neural networks tackle a large spectrum of applications like object recognition detection and semantic segmentation in image classification a neural network predicts the object inside the image to resolve confusing images with multiple objects as in the next figure the top predictions are utilized
but the top five predictions metric is different from the network confidence in its predictions the network uncertainty is a quantitative metric revealing the network confidence in its prediction standard networks can easily classify the next digits as four maybe the left image is a nine but they are incapable of providing a prediction uncertainty measure for the next images we expect higher uncertainty for the left image compared to the neat right image
dropout is a well established procedure to regularize a neural network and limit overfitting it is first introduced by srivastava et al using a branch prediction averaging analogy random neuron dropping during training only reduces the network generalization error
the dropout as a bayesian approximation proposes a simple approach to quantify the neural network uncertainty it employs dropout during both training and testing the paper develops a new theoretical framework casting dropout in deep neural networks nns as approximate bayesian inference in deep gaussian processes the framework is developed for both classification and regression problems this article highlights the paper finding and its applications for simplicity purpose regression is utilized in the following examples yet classification networks are backed as well
a regression neural network with dropout enabled during testing generates a different output every forward pass for the same input in the figure below the same input is passed six times and the network regresses to the paper mathematically shows that these multiple passes are equivalent to monte carlo sampling thus the first and second moment mean and variance provides the network s output and uncertainty respectively in this example the network output equals and its uncertainty is high variance standard deviation indicates high network uncertainty and vice versa a quantitative uncertainty measure is valuable especially if further decisions are based on the network output human intervention is one way to address high uncertainty outputs
the theoretical framework employs a dropout layer before every weight layer as a bayesian inference approximation the dropout rate is a hyper parameter that needs to be tuned a small dropout rate eliminates the monte carlo sampling utility a big dropout rate can lead to divergence or at least require more iterations to converge so a mid range rate like is reasonable optical flow and depth estimation are important regression problems in autonomous navigation where uncertainty estimation is valuable
beyond uncertainty estimation the paper utilizes its finding in a different application it utilizes uncertainty estimation to tune the neural network hyperparameters and reduce the generalization error hyper parameters are tuned using validation splits by employing a hyper parameter grid search and measuring the classification accuracy or euclidean loss metrics the best hyperparameters get selected in this paper uncertainty is employed as an extra metric besides accuracy to tune hyper parameters like weight regularization coefficient a similar followup work by kendall et al used uncertainty to learn how to weight multi task networks a multi term loss function for multiple objectives tasks has multiple weighting hyper parameters as in the next equation as the number of objectives increases tuning these weights becomes cumbersome using the naive grid search
loss l w l w l
uncertainty quantification using dropout is the paper core contribution a lot of applications and follow up work are based on this finding in the medical field nair et al measure uncertainty evaluation for lesion detection and segmentation networks in autonomous navigation it enables semantic segmentation and depth uncertainty estimation gal el at employ uncertainty estimation for active learning to boost performance from small amounts of data
my comments
dropout a simple way to prevent neural networks from overfitting
what uncertainties do we need in bayesian deep learning for computer vision
bayesian convolutional neural networks with bernoulli approximate variational inference
a theoretically grounded application of dropout in recurrent neural networks
multi task learning using uncertainty to weigh losses for scene geometry and semantics
exploring uncertainty measures in deepnetworks for multiple sclerosis lesion detection and segmentation
deep bayesian active learning with image data
i write reviews on computer vision papers writing tips are welcomed
on june the forum for future medical technology and artificial intelligence conference hosted by bio valley was held in shanghai the goal of the conference was to share and discuss the development and application of artificial intelligence in the medical field
the panel of speakers at the conference included prof jianwei zhang director of the institute of the multi modal technology systems and professor at the university of hamburg in germany mr ray zhang founder and ceo of airdoc mr fabao zhang chairman of shanghai metz pharmaceutical technology co mr xubo hu the managing partner at qiming venture partners
since the discovery of x ray in x ray has been widely used to examine the human body to assist in the diagnosis of diseases laying the basis for radiological and medical imaging medical imaging has now become the most common diagnostic diagnostic tool
over the past few decades medical imaging technology in china has developed rapidly however imaging specialists have been in short supply and mainly concentrated in large hospitals of large cities many small and medium size cities do not have adequate imaging diagnostics resources patients in smaller cities have found it necessary to travel to big cities in order to seek proper medical treatment
airdoc aims to solve the problem of inadequate medical imaging resources by leveraging scalable technology artificial intelligence airdoc equips many smaller community level health care institutions with ai medical image recognition capability previously only available at the best hospitals
in the years since the conception of artificial intelligence lack of computing power and immature algorithms impeded its development in the advent of deep learning brought significant revival to artificial intelligence in the emergence of alexnet brought about a turning point in ai at the large scale visual recognition challenge ilsvrc alexnet bested the previous year s top error by percentage points ever since artificial intelligence in the field of image recognition has constantly been making and breaking records
in recent years articles appearing in nature jama science and other authoritative medical journals have begun writing about using artificial intelligence to solve medical problems for example artificial intelligence identifies skin cancer appeared on the cover of nature science magazine reported on computers predicting heart attack at higher accuracy rate than that of human doctors etc meanwhile major chinese hospitals have also begun to seriously study clinical applications of artificial intelligence
ray zhang asserts that artificial intelligence has virtually limitless possibilities in the medical field a few examples besides medical imaging include virtual nurse assistant health management medical risk analysis drug extraction auxiliary diagnosis and medical research but medical artificial intelligence is still in its infancy but its role in medical imaging recognition is well on its way
in medical image recognition the development of artificial intelligence requires massive numbers of medical images to generate algorithm models data volume and data quality are critical high data volume increases the model s inclusion rate while accurate data and annotations ensure high accuracy of the model s training and test sets
ray zhang dalei contends that within the next years artificial intelligence will play a critical role in the medical field artificial intelligence will be the core driving force behind the next revolution in medicine ai can thoroughly analyze and aggregate medical knowledge to help provide higher quality clinical advice
with its comprehensive inter disciplinary integration ai is set to facilitate the evolution of economic patterns by transforming across commercial financial and medical industries
airdoc is a deep learning based algorithm services company providing ai medical solutions
china has the world s largest population of the blind and visually impaired data shows that china has about million patients with myopia million glaucoma patients million cataract patients and million fundus neovascular disease patients ametropia glaucoma and cataracts and other blinding diseases gradually show a growing trend among younger people to better promote eye health china s national health and family planning commision issued the thirteenth five year plan for national eye health to
artificial intelligence and deep learning has advanced to the point where machines can simulate the human thought process this advancement has subsequently led to the rapid development of artificial intelligence in medical image recognition which is now used to identify and diagnose eye diseases
on august wenzhou medical university eye hospital zhejiang province eye hospital and the leader in medical ai airdoc announced a joint vision research and development center at the signing ceremony the two sides announced that they will commit to the developments and advancements in the field of intelligent optometry applications
in attendance at the signing ceremony were wenzhou medical university eye optic hospital dean qu jia airdoc founder and ceo ray zhang airdoc chief medical officer yuzhong chen airdoc vp of marketing richard zhang among dozens of others
the two sides will jointly establish a ai powered intelligent eye vision center to research and develop intelligent eye disease imaging and intelligent eye examination systems leveraging ophthalmic data and ai applications from both parties
previously airdoc had worked with the wenzhou medical university eye hospital to develop a children s vision change prediction model airdoc successfully analyzed the results of optometry results relative to age trends for example years are the most critical age with regards to vision changes airdoc s algorithm can predict future vision changes based on current age and vision results
for this cooperation wenzhou medical university eye hospital president qu jia said professional work should be left to the professionals as the hospital looks to develop medical applications of artificial intelligence it makes sense to take a cooperative approach
according to qu s view hospitals need to leverage the right players in advanced technology this avoids the situation of professional work being done by non professionals leading ultimately to less than desirable results the eye optometry hospital is a professional in the field of medicine and airdoc is a professional in the field of artificial intelligence which is the basis of cooperation between our two sides
qu admits that there is still a long way to go for artificial intelligence in clinical application but proven potential show good prospects for the development of new technologies we should make full use of existing resources to actively explore and research
airdoc founder and chief executive officer ray zhang dalei the two sides will leverage their respective expertise to jointly promote the organic combination of artificial intelligence technology and ophthalmic clinicians to optimize the doctor patient relationship
eye vision artificial intelligence applications
the first collaborative project is a smart cataract surgery platform
in china about million people each year undergo cataract surgery airdoc builds on china s cataract knowledge base based on massive clinical data and develops specific solutions based on different eyes to assist physician in making surgical decisions
the second project is a keratoconus intelligent assisted diagnosis research conducted by wenzhou medical university eye hospital and airdoc is based on massive clinical data to develop an intelligent auxiliary diagnostic model this diagnostic model is expected to help with rapid screening of the various stages of keratoconus cases
intelligent ophthalmic diagnosis is the third area of collaboration today the ophthalmic hospitals are overcrowded with long lines for patients resulting in poor patient experience as well as overwhelmed doctors the plan is to leverage artificial intelligence to solve this problem artificial intelligence can quickly help refer patients to the appropriate type of doctor so as to enhance the efficiency of doctors saving patients wait time
the last collaborative project is juvenile myopia intelligent progression prediction
china s juvenile myopia rate ranks first in the country hampered by the amount of data and methods accurate myopia progression prediction is difficult
airdoc built an ai model by using massive data from the eye hospital of wenzhou medical university the model is used to predict myopia progression in year olds spanning from their current to years of age
speaking of data mining wenzhou medical university eye hospital information management director wang xiaoxing said most of the detection and data processing equipment have been well structured the multi device data has already been integrated into the information management system with the dicom agreement we will be able to transmit airdoc s ai information through the hospital system of course it has the benefit of building on over years of the hospital s information technology platform
zhang dalei said of the business model at this stage the entire industry is absolutely overheating and we certainly hope to make it big but airdoc is not simply just about business we hope to help the hospital in scientific research clinical treatment efficiency to solve the problem of scarce domestic medical resources
integrating ai into medicine is a long term endeavor so businesses must be patient now many artificial intelligence companies have surfaced in the field of cancer and the ophthalmic market is also growing as long as we can create a real product that can create value the business aspects need not worry about business opportunities
airdoc has made great progress in ai the fields of ophthalmology dermatology cardiovascular neurology and so on with airdoc involved in research in these diseases its business model product promotion profit model will bring us some insight into the field of artificial intelligence
airdoc is a deep learning based algorithm services company providing ai medical solutions
another ces passed by and we saw a bunch of new smart cars with self driving capabilities what all of them had in common was how they were trying to be the center of your digital experience
byton for example wants to track many aspects of your health and show it on the large screen on the dashboard for you to see they are also trying to be a hub for your music and entertainment some of the car manufacturers are also insisting on developing their own personal assistants in the car
but there s a large problem with that building a new platform is difficult specially for a car manufacturer apple google and microsoft and more recently amazon have managed to create their own platforms with varying levels of openness and compatibility with each other apple insists on iphone owners using their appstore for all of their app needs google does the same thing on android with play store building a personal assistant might be getting easier and easier with advances in machine learning and human language processing but one main problem remains
all of this is resulting in a fragmentation in the industry and that makes it very difficult for developers to develop and maintain their applications for those platforms
netflix is not going to develop an app for byton then another one for mercedes then another one for tesla and then another one for any other car manufacturer that thinks it s a clever idea to build their own platform even if they do a partnership and decide to make an app for a couple of these car manfucaturers do you think they would put the time in mainataining these apps and giving them regular updates car manufacturers already suffer from not getting regular updates and the consumers are used to monthly app updates on their smartphones if the car industry doesn t realize soon that they need a unified approach to this instead of fragmenting the industry we re all going to end up with really bad user experiences in our shared cars
remember when instagram didn t make an official app for blackberry and asked them to remove any third party instagram apps on the platform because they were violating their terms of use that s how it s going to feel driving one of these future self driving cars it s going to feel like we re using blackberries
apple and google have taken attempts to streamline the experience with android auto and carplay but they seem to not be getting much traction as car manufacturers are realizing that there s a huge potential to make money from the infotainment systems in their cars when they are self driving they would have the user s attention and that presents the opportunity to show them ads or have them subscribe to their services
but here s the problem if the infotainment system in my car is going to suck and not have all of my favourite apps i m just going to start bringing my ipad to the car and mounting it to the dashboard
so unless all these car startups actually want all of their customers to mount an ipad over their complicated dashboard entertainment hub health monitoring attention seeking displays in their cars they better get their acts together and start integrating with systems that already exist ios android windows and macos
cars will never be the center of our digital world because we are not always en route but when we are they need to integrate with what we are already doing and carrying with ourselves i want to get in my car and continue what i was watching on my iphone but now on the bigger display on the dashboard and when that happens my phone simply turns into the remote for the screens the passenger wants to get in and continue browsing instagram on their android but now on the larger display each passenger gets their own share of the display if we decide to watch something together then it would be in the middle
so please stop trying to be the next smart device in my life and start embracing being a peripheral to your customer s already existing digital world
signed everyone who s excited about self driving cars
ui ux motion designer www alborz design
by charlotte kng
even before its official app launch in september pet s design and use case of artificial intelligence ai and machine learning has proven its worth and recently clinched a place as one of the top apac machine learning solution providers of as judged by cio advisor its novel idea of incorporating artificial intelligence into a digital companion chatbot and tertiary option recommender took the world by storm and leading innovation magazine cio advisor sure isn t going to let that slide without highlighting that to its rich profile of tech savvy readers
cio advisor is an established publication that prides itself best in identifying leading industry insiders and experts not forgetting unique solutions and services that are foreseen to transform apac businesses and enhance the legacy system with its wide network and extensive research in recognizing game changing individuals and projects within the innovation and tech space a slot on cio advisor s top listings has never been known as an easy feat cio advisor often covers prominent industry experts including the likes of nick wilkinson ceo of binary tree ryan wu ceo of qihan as well as vikash varma ceo of argyle data with pet soon to join the hall of fame when the top apac machine learning solution providers get coverage in its september issue
the full article will feature mr wilson wang pet s founder and ceo alongside other esteemed rankers on the list as they discuss how their machine learning solutions are set to revolutionize and disrupt the world with their core stemming from a very niche and novel arm of technology the blockchain pet is not only conquering the machine learning aspect of things it will push boundaries and change the educational game by introducing a whole new level of security transparency and decentralization in the storage and analysis of academic related data creating a more inclusive space for all learners alike
token sale
pet s private token sale kicked off earlier last month and will run until the end of august early bird incentives for the public pre sale will be through bonus tokens computed as follows
bonus tokens from september to september
bonus tokens from september to september
bonus tokens from september to september
bonus tokens from september to september
the official token generation event will be on the st october reach out to pet s management team at support opetfoundation com for further information about their private sale
about pet
pet is a singapore based company focusing on the development of an ai companion chatbot that is capable of learning high school curriculum and revision assistance it also offers a digital companion tuition service to assist in students revision efforts as well as recommend suitable tertiary institutions and courses of study globally via collected user data stored on its unique blockchain solution facilitating a seamless tertiary college application and admission validation pet also empowers an accountable way of education related philanthropy
www opetfoundation com
about cio advisor
cio advisor has culminated as the leading print platform offering a fresh aspect in understanding the latest innovations and technologies in the apac region following a peer to peer learning approach cio advisor spearheads in highlighting industry s latest trends and technologies and brings forth the ideas and values of industry leaders to assist insurance experts to established corporations alike
https www cioadvisorapac com
bringing ai and blockchain technologies into education pet is revolutionizing students lives helping them to reach their full potential
a blockchain project to enable seamless tertiary amp college application and admission
like a musical maestro who seems to possess an inexplicable air of magic artificial intelligence is often attributed with a magical quality beyond human comprehension
while this misattribution may be acceptable in the world of music it is dangerous in the context of ai in a democracy where fundamental decisions must be made by its citizenry without a familiarity with ai and how it works how can a democratic population make informed decisions further how can such a population protect itself from exploitation by ill intentioned corporations and other entities
let s start by clearing up confusion ai is not magic it is applied calculus which applied destructively can be dangerous in a trillion dollar flash crash led by auto trading bots an implementation of autonomous ai caused a point drop in the dow jones in minutes in an even more insidious manner ai assisted decisions can lead to outcomes that contravene our basic societal values like microsoft s ai tay which became wildly racist within days of going online ai can reinforce existing biases as it did in idaho where the aclu is currently fighting for the rights of idahoans who without justification had their medicaid assistance cut by
despite its potential negative consequences however ai has boundless positive potential some people s limited encounters with ai in the media with its sci fi wizard of oz false feeling of power may underestimate ai s possibilities the same computer that ostentatiously beat the world s best jeopardy players in the day cracks medical mysteries at night curing and diagnosing diseases left and right asimo a humanoid robot powered by ai will revolutionize search and rescue missions uber google maps and even commercial airline flights use variations on ai tesla bmw ford gm and many others have released autonomous car programs which brings me to my final point
there is a classic and difficult question in ai imagine a tesla model x is approaching an intersection it s foggy and the car s sensors can t see a crowd of people until it is too late the car decides in a fraction of a second should it drive into the crowd killing bystanders or swerve into a pole killing the car s occupants without an informed populace making democratic decisions car companies will decide the answer
despite the complications we can t ignore this problem
it is estimated that autonomous ai cars could save lives per year there is a balance that can only be evaluated when we understand the underpinnings of how ai works and what it can and cannot accomplish elon musk understands the great possibilities ai presents but he also warns that we must regulate it before it s too late on the other side of the ocean the uk parliament has discussed many of the issues around ai but has decided to wait before taking decisive action
an educated stance on ai is necessary for making good decisions as citizens in a democratic society ai is here and it is making decisions about what you see in the world whether you are eligible for a bank loan and how you move through the world ai is saving lives in massachusetts general hospital saving lives at the wheel and flying thousands of travelers through the air every day yet the number of people who can properly describe its consequences behavior or internal functioning is but a handful an educated citizenry is vital for survival as a free people
let s begin to really focus on educating the american people about ai
the subversionist is a publication by fund that features stories of people who are in protest of something they care deeply about what are you rallying against
here s how the rest of us can do meaningful things with artificial intelligence or machine learning since all of the current ai experts are already working for google and facebook
first and foremost i m going to argue that you don t necessarily need a phd to be an ai expert
in order to get a phd you need to have completed a doctoral thesis which is a lengthy research project usually mixed with additional education done with close supervision by another academic this is in general a good thing we want research we want knowledge we want people to get phds
in the world of machine learning and artificial intelligence phd work often centers around developing new algorithms to accomplish more and more computationally complex things perhaps if we can boost the accuracy of a face detection algorithm from to we ll have accomplished something worthwhile
in the world of practical ai such intense research on algorithms and new methods of computation take a long time to become useful because they are often not optimized for business nor should they be
today right now at this moment there are a plethora of apis and machine learning tools that can deliver a tremendous amount of value all you need to do is follow a set of best practices that doesn t require years of research to pursue
this is something entrepreneurs developers and founders do really well we don t have time to do something for the sake of doing something we have to solve a real world problem machine learning is great for doing that but only if your problem is well defined and isn t just predict the stock market
always start small and work your way up from there for example maybe you want to tag people in photos your customers are uploading to your platform or flag user submitted news articles ahem reddit as opinionated or biased
both of these use cases can be pretty easily accomplished today with off the shelf apis and tools that don t require any machine learning engineering knowledge whatsoever
if you re training a face recognition system to recognize your customers or trying to classify news articles just make sure your training data meets some simple criteria
don t worry about the algorithm or accuracy as much as you worry about deployment and scalability machine learning should run like any other software in your stack it should be fault tolerant lightweight and owned managed by you not outsourced to someone else
you might get some false positives or false negatives you might have some variation in performance and you might see errors the best implementations of machine learning are not so because of accuracy but because of how they handle these exceptions when apple photos gets someone s face wrong it lets you change it and thereby trains itself on that change to be better
you can and should do this to
here are some of my favorite diy out of the box no data science required tools
machine box runs on premises lets you train with minimal or no data at all start with pre trained models tune the models on the fly or build your own very simple api full disclosure this is my company so i hope you pick this one
google vision api runs in the public cloud has some training capabilities extremely accurate image recognition medium to simple api
azure vision api also runs in the public cloud some training capabilities massive pre trained celebrity recognition database simple api
aws rekognition public cloud endpoint good with face detection api is not as easy as azure but still pretty easy
practice practice practice this is your data your use cases your niche your market you need to experiment there s no grand machine learning model that will solve all the world s problems the best models are the smaller finely tuned models that run just on your dataset
spend some time cleaning your data make sure it is a really good subset of the data you plan on having your machine learning model make predictions on later and for god s sake don t expect it to be perfect the first time around
the more iterations you go through the more models you train the more you experience the more likely you are to see success face recognition not doing what you want try altering the training images or using freeze frames from your own data assuming its video thats where face recognition usually gets tricky accuracy only on detecting biased news articles find more articles or deploy your model and crowdsource the answer from your users
you can do this phd mba msc ba bs ged or not
co founder machine box exited machine learning superfan business development agile product owner author father amateur programmer
let s get started
the most common problem we face while starting with data science or machine learning is from where to start even i got stuck with the same question but with time i learned about it its algorithm and about how it works but it was very slow that s the point i was very slow i spent a lot of time understanding it and then was pushed back since my basics were not clear so here i m with a tutorial that can lead you to from a beginner to a pro in machine learning i will be updating you guys with a blog and a tutorial on github every week
things we will be covering in the tutorial series
the codes of all these will be available at github
business applications machine learning can be used in business analysis work as well in spam email detection stock prediction natural language processing has proved to be very efficient in the field of machine learning
there is endless use of machine learning it s heavily upon the coder how he she implements it before we get started with machine learning it is also important to know the basics of python so i just made a tutorial which is enough to get you guys started with data science
python basics
there are certain simple things which we should remember before starting with python
let us see a hello world program in python
step open your terminal and type python in case you don t have python follow this link to install it on your system windows linux mac
step if you have python installed in your system then type python on your terminal and press enter
wait but we haven t included any header file so are we wrong
well no as discussed earlier there is no need to include any header files initially isn t that simple
this just notebook gives a brief explanation of python basics
link to the code python basics
pandas
pandas is one of the most efficient libraries for data science in python it makes handling of dataset very easy for the developer the problem developers face without pandas is that it requires manually handling each and every part of the dataset like columns rows its size etc but pandas has proved to be one of the most efficient libraries in the field of data science it automates the loading of data into memory very quickly basically used for data manipulation and analysis a quick overview of pandas is shown in below notebook to know about jupyter have a look on the below notebook
numpy
numpy is a library adding support for large multi dimensional arrays and matrices along with a large collection of high level mathematical functions to operate on these arrays
so this was all about chapter of go ml tutorial link to the codes link
thanks for your time we hope that you liked our first part of go ml tutorials follow me on github for further updates on this course
linkedin
data scientist and researcher
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
generative models allow a computer to create data like photos movies or music by itself
a little over a year ago alec radford building on the work of ian goodfellow published a paper that changed how everyone thought about building generative models with machine learning the new system is called deep convolutional generative adversarial networks or dcgans for short
dcgans are able to hallucinate original photo realistic pictures by using a clever combination of two deep neural networks that compete with each other all of these pictures of bedrooms were dreamt up by a dcgan
ai researchers care about generative models because they seem to be a stepping stone towards building ai systems that can consume raw data from the world and automatically build understanding from it
but let s use generative models to do something a bit more silly make artwork for bit video games
so why exactly are ai researchers building complex systems to generate slightly wonky looking pictures of bedrooms
the idea is that if you can generate pictures of something you must have an understanding of it
look at this picture
you instantly know this is a picture of a dog a furry thing with four legs and a tail but to a computer the picture is just a grid of numbers representing the color of each pixel the computer has no understanding that the picture represents a concept
but now imagine that we showed a computer thousands of pictures of dogs and after seeing those pictures the computer was able to generate new pictures of dogs on its own including different dog breeds and pictures from different angles maybe we could even ask it for certain types of pictures like a side view of a beagle
if the computer was able to do this and the pictures it produced had the right number of legs tails and ears it would prove that the computer knows what parts go into making up a dog even though no one told it explicitly so in a sense a good generative model is proof of basic understanding at least on a toddler level
that s why researchers are so excited about building generative models they seem to be a way to train computers to understand concepts without being explicitly taught the meaning of those concepts that s a big step over current systems that can only learn from training data that has been painstakingly pre labeled by humans
but if all this research results in programs that generate pictures of dogs how many years until we get the first computer generated dog a day calendar as a side effect
and if you can build a program that understands dogs why not a program that understands anything else what about a program that could generate an unlimited number of stock photos of people shaking hands i m sure someone would pay for that
ok maybe a program that generates bad stock photos wouldn t be that interesting but given the rate of progress in generative models over just the past year who knows where we ll be in or years what happens if someone invents a system to generate entire movies or music or video games
if you look forward years and squint you can already imagine a world where entertainment could be machine generated
the video game industry is the first area of entertainment to start seriously experimenting with using ai to generate raw content aside from the obvious venn diagram overlap between computer gaming and machine learning engineers there s a huge cost incentive to invest in video game development automation given the million budgets of modern aaa video games
we are still in the earliest days of machine learning based generative models and their practical uses are currently pretty narrow but they are a lot of fun to play around with let s see what we can do with one
to build a dcgan we create two deep neural networks then we make them fight against each other endlessly attempting to out do one another in the process they both become stronger
let s pretend that the first deep neural network is a brand new police officer who is being trained to spot counterfeit money it s job is to look at a picture and tell us if the picture contains real money
since we are looking for objects in pictures we can use a standard convolutional neural network for this job if you aren t familiar with convnets you can read my earlier post but the basic idea is that the neural network that takes in an image processes it through several layers that recognize increasingly complex features in the image and then it outputs a single value in this case whether or not the image contains a picture of real money
this first neural network is called the discriminator
now let s pretend the second neural network is a brand new counterfeiter who is just learning how to create fake money for this second neural network we ll reverse the layers in a normal convnet so that everything runs backwards so instead of taking in a picture and outputting a value it takes in a list of values and outputs a picture
this second neural network is called the generator
so now we have a police officer the discriminator looking for fake money and a counterfeiter the generator that s printing fake money let s make them battle
in the first round the generator will create pathetic forgeries that barely resemble money at all because it knows absolutely nothing about what money is supposed to look like
but right now the discriminator is equally terrible at it s job of recognizing money so it won t know the difference
at this point we step in and tell the discriminator that this dollar bill is actually fake then we show it a real dollar bill and ask it how it looks different from the fake one the discriminator looks for a new detail to help it separate the real one from the fake one
for example the discriminator might notice that real money has a picture of a person on it and the fake money doesn t using this knowledge the discriminator learns how to tell the fake from the real one it gets a tiny bit better at its job
now we start round we tell the generator that it s money images are suddenly getting rejected as fake so it needs to step up it s game we also tell it that the discriminator is now looking for faces so the best way to confuse the discriminator is to put a face on the bill
and the fake bills are being accepted as valid again so now the discriminator has to look again at the real dollar and find a new way to tell it apart from the fake one
this back and forth game between the generator and the discriminator continues thousands of times until both networks are experts eventually the generator is producing near perfect counterfeits and the discriminator has turned into a master detective looking for the slightest mistakes
at the point when both networks are sufficiently trained so that humans are impressed by the fake images we can use the fake images for whatever purpose we want
so now that we know how dcgans work let s see if we can use one to generate new artwork for s style video games
let s build a dcgan that tries to produce screenshots of imaginary video games for the nintendo entertainment system or nes based on screenshots of real games
the idea is that if we can generate convincing screenshots of imaginary video games we could copy and paste bits of art from those screenshots and use it in our own retro style video game since the generated video games never existed it wouldn t even be stealing maybe more on this later
video game art in those days was very simple since the nes had such a small amount of memory the games used way less memory than this article takes up programmers had to use lots of tricks to fit the game art into memory to maximize the limited space games used tile based graphics where each screen in the game is made up of just a few usually x pixel repeated graphical tiles
for example the starting screen of the legend of zelda is made up of only unique tiles
here are the tiles for entire the legend of zelda game map
our goal is to create a similar tile sheet for our game because of that we don t really care if the game screenshots we generate look completely realistic instead we re just looking for the shapes and patterns that we can use as x tiles in our game things like stones water bridges etc then we can use those tiles to build our own bit style video game levels
to train our system we need lots of data luckily there are over games for the nes that we can pull from
i used wget to download all the nes game screenshots on the video game museum website sorry for scraping your site after a few minutes of downloading i had a little over screenshots of hundreds of nes games
right now dcgans only work on pretty small images pixels square or so but the entire screen resolution of the nes was only pixels by pixels so that s not a problem to make things simple i cropped each nes screenshot to pixels square
there are several open source implementations of dcgans on github that you can try out i used taehoon kim s tensorflow implementation since dcgans are unsupervised all you have to do is put the data in a folder tweak the basic parameters start it training and then wait to see what results you get
here s what a sample of the original training data looks like
now training begins at first the output from the generator is pure noise but it slowly start to take shape as the generator learns to do a better job
after several more training rounds the images start to resemble nightmare ish versions of classic nintendo games
as training continues further we start to see the bricks and blocks we are hoping to find you can also see screen elements like life bars and even some text
this is where things get complicated how do we know the computer is creating brand new art and not just regurgitating art directly from the training images in two of these images you can clearly see the menu bar from super mario bros and the header bar and bricks from the original super mario bros
regurgitating training data is definitely something that can happen by using a large training data set and not training too long we can try to reduce the chance that this happens but it s a thorny issue and research on it continues
since i m just going for aesthetics i tweaked the model until it produced art that looked original to me but i can t prove that the new art is totally original except by searching the training data for similar art and verifying that there isn t any
with a few hours of training the generated images contained x tiles that looked nice to me i was looking for some variations on a basic stone block brick patterns water patterns bushes and some general spooky looking background atmosphere tiles
next i need to pre process the generated images to the make sure they only used the colors that are available on the nes
then i ll open up the color images in the tiled map editor from there i can easily grab the x tiles that match the aesthetic i want
then inside of tiled map editor i ll arrange those x tiles into a simple level layout reminiscent of the nes game castlevania
i think that looks pretty good keep in mind i didn t touch a single pixel with an image editor every tile came straight out of the dcgan model
next let s throw in the main character and some enemies from castlevania so we can see what this level would look like in action
to get the full effect let s see what the level would look like inside the game with the menu elements added
i think that looks like the nes games that i remember i m not claiming it s the best nes art ever created but it s certainly not the worst
i get really excited about generative models like this the idea of one day cranking out endless artwork with computers is fascinating to me but when i talk to other people about this stuff sometimes the response is is that it that s so basic
there s certainly a lot of hype around generative models right now gans are already being called the future of ai despite being notoriously hard to train and limited to generating tiny images in fact the very best models can currently only generate postage stamp sized pictures of mutant dogs
but a couple of years ago we couldn t do anything close to that we were pretty excited by generated pictures that looked like this
and the technology is improving every single day here s a random paper that came out this week that uses gans to age the faces of people
if things keep improving at this pace it won t be too long before generative models are a mainstream tool helping us create it s a great time to start experimenting
if you want to learn more in depth about generative models and dcgans here are some recommended resources
this article is part of my machine learning is fun series you can check out the earlier parts here part part part part part and part
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in italiano espa ol fran ais t rk e portugu s ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
in part we said that machine learning is using generic algorithms to tell you something interesting about your data without writing any code specific to the problem you are solving if you haven t already read part read it now
this time we are going to see one of these generic algorithms do something really cool create video game levels that look like they were made by humans we ll build a neural network feed it existing super mario levels and watch new ones pop out
just like part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
back in part we created a simple algorithm that estimated the value of a house based on its attributes given data about a house like this
we ended up with this simple estimation function
in other words we estimated the value of the house by multiplying each of its attributes by a weight then we just added those numbers up to get the house s value
instead of using code let s represent that same function as a simple diagram
however this algorithm only works for simple problems where the result has a linear relationship with the input what if the truth behind house prices isn t so simple for example maybe the neighborhood matters a lot for big houses and small houses but doesn t matter at all for medium sized houses how could we capture that kind of complicated detail in our model
to be more clever we could run this algorithm multiple times with different of weights that each capture different edge cases
now we have four different price estimates let s combine those four price estimates into one final estimate we ll run them through the same algorithm again but using another set of weights
our new super answer combines the estimates from our four different attempts to solve the problem because of this it can model more cases than we could capture in one simple model
let s combine our four attempts to guess into one big diagram
this is a neural network each node knows how to take in a set of inputs apply weights to them and calculate an output value by chaining together lots of these nodes we can model complex functions
there s a lot that i m skipping over to keep this brief including feature scaling and the activation function but the most important part is that these basic ideas click
it s just like lego we can t model much with one single lego block but we can model anything if we have enough basic lego blocks to stick together
the neural network we ve seen always returns the same answer when you give it the same inputs it has no memory in programming terms it s a stateless algorithm
in many cases like estimating the price of house that s exactly what you want but the one thing this kind of model can t do is respond to patterns in data over time
imagine i handed you a keyboard and asked you to write a story but before you start my job is to guess the very first letter that you will type what letter should i guess
i can use my knowledge of english to increase my odds of guessing the right letter for example you will probably type a letter that is common at the beginning of words if i looked at stories you wrote in the past i could narrow it down further based on the words you usually use at the beginning of your stories once i had all that data i could use it to build a neural network to model how likely it is that you would start with any given letter
our model might look like this
but let s make the problem harder let s say i need to guess the next letter you are going to type at any point in your story this is a much more interesting problem
let s use the first few words of ernest hemingway s the sun also rises as an example
what letter is going to come next
you probably guessed n the word is probably going to be boxing we know this based on the letters we ve already seen in the sentence and our knowledge of common words in english also the word middleweight gives us an extra clue that we are talking about boxing
in other words it s easy to guess the next letter if we take into account the sequence of letters that came right before it and combine that with our knowledge of the rules of english
to solve this problem with a neural network we need to add state to our model each time we ask our neural network for an answer we also save a set of our intermediate calculations and re use them the next time as part of our input that way our model will adjust its predictions based on the input that it has seen recently
keeping track of state in our model makes it possible to not just predict the most likely first letter in the story but to predict the most likely next letter given all previous letters
this is the basic idea of a recurrent neural network we are updating the network each time we use it this allows it to update its predictions based on what it saw most recently it can even model patterns over time as long as we give it enough of a memory
predicting the next letter in a story might seem pretty useless what s the point
one cool use might be auto predict for a mobile phone keyboard
but what if we took this idea to the extreme what if we asked the model to predict the next most likely character over and over forever we d be asking it to write a complete story for us
we saw how we could guess the next letter in hemingway s sentence let s try generating a whole story in the style of hemingway
to do this we are going to use the recurrent neural network implementation that andrej karpathy wrote andrej is a deep learning researcher at stanford and he wrote an excellent introduction to generating text with rnns you can view all the code for the model on github
we ll create our model from the complete text of the sun also rises characters using unique letters including punctuation uppercase lowercase etc this data set is actually really small compared to typical real world applications to generate a really good model of hemingway s style it would be much better to have at several times as much sample text but this is good enough to play around with as an example
as we just start to train the rnn it s not very good at predicting letters here s what it generates after a loops of training
you can see that it has figured out that sometimes words have spaces between them but that s about it
after about iterations things are looking more promising
the model has started to identify the patterns in basic sentence structure it s adding periods at the ends of sentences and even quoting dialog a few words are recognizable but there s also still a lot of nonsense
but after several thousand more training iterations it looks pretty good
at this point the algorithm has captured the basic pattern of hemingway s short direct dialog a few sentences even sort of make sense
compare that with some real text from the book
even by only looking for patterns one character at a time our algorithm has reproduced plausible looking prose with proper formatting that is kind of amazing
we don t have to generate text completely from scratch either we can seed the algorithm by supplying the first few letters and just let it find the next few letters
for fun let s make a fake book cover for our imaginary book by generating a new author name and a new title using the seed text of er he and the s
not bad
but the really mind blowing part is that this algorithm can figure out patterns in any sequence of data it can easily generate real looking recipes or fake obama speeches but why limit ourselves human language we can apply this same idea to any kind of sequential data that has a pattern
in nintendo released super mario maker for the wii u gaming system
this game lets you draw out your own super mario brothers levels on the gamepad and then upload them to the internet so you friends can play through them you can include all the classic power ups and enemies from the original mario games in your levels it s like a virtual lego set for people who grew up playing super mario brothers
can we use the same model that generated fake hemingway text to generate fake super mario brothers levels
first we need a data set for training our model let s take all the outdoor levels from the original super mario brothers game released in
this game has levels and about of them have the same outdoor style so we ll stick to those
to get the designs for each level i took an original copy of the game and wrote a program to pull the level designs out of the game s memory super mario bros is a year old game and there are lots of resources online that help you figure out how the levels were stored in the game s memory extracting level data from an old video game is a fun programming exercise that you should try sometime
here s the first level from the game which you probably remember if you ever played it
if we look closely we can see the level is made of a simple grid of objects
we could just as easily represent this grid as a sequence of characters with one character representing each object
we ve replaced each object in the level with a letter
and so on using a different letter for each different kind of object in the level
i ended up with text files that looked like this
looking at the text file you can see that mario levels don t really have much of a pattern if you read them line by line
the patterns in a level really emerge when you think of the level as a series of columns
so in order for the algorithm to find the patterns in our data we need to feed the data in column by column figuring out the most effective representation of your input data called feature selection is one of the keys of using machine learning algorithms well
to train the model i needed to rotate my text files by degrees this made sure the characters were fed into the model in an order where a pattern would more easily show up
just like we saw when creating the model of hemingway s prose a model improves as we train it
after a little training our model is generating junk
it sort of has an idea that s and s should show up a lot but that s about it it hasn t figured out the pattern yet
after several thousand iterations it s starting to look like something
the model has almost figured out that each line should be the same length it has even started to figure out some of the logic of mario the pipes in mario are always two blocks wide and at least two blocks high so the p s in the data should appear in x clusters that s pretty cool
with a lot more training the model gets to the point where it generates perfectly valid data
let s sample an entire level s worth of data from our model and rotate it back horizontal
this data looks great there are several awesome things to notice
finally let s take this level and recreate it in super mario maker
play it yourself
if you have super mario maker you can play this level by bookmarking it online or by looking it up using level code ac f c
the recurrent neural network algorithm we used to train our model is the same kind of algorithm used by real world companies to solve hard problems like speech detection and language translation what makes our model a toy instead of cutting edge is that our model is generated from very little data there just aren t enough levels in the original super mario brothers game to provide enough data for a really good model
if we could get access to the hundreds of thousands of user created super mario maker levels that nintendo has we could make an amazing model but we can t because nintendo won t let us have them big companies don t give away their data for free
as machine learning becomes more important in more industries the difference between a good program and a bad program will be how much data you have to train your models that s why companies like google and facebook need your data so badly
for example google recently open sourced tensorflow its software toolkit for building large scale machine learning applications it was a pretty big deal that google gave away such important capable technology for free this is the same stuff that powers google translate
but without google s massive trove of data in every language you can t create a competitor to google translate data is what gives google its edge think about that the next time you open up your google maps location history or facebook location history and notice that it stores every place you ve ever been
in machine learning there s never a single way to solve a problem you have limitless options when deciding how to pre process your data and which algorithms to use often combining multiple approaches will give you better results than any single approach
readers have sent me links to other interesting approaches to generating super mario levels
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
k atica roy is a gender economist ceo and founder of pipeline pipeline is a saas platform engineered with artificial intelligence to stop unconscious bias in the workplace and increase financial performance with more than two decades of experience in technology healthcare and financial services roy has a rare combination of expertise and passion for gender equity people analytics and sales operations she pours her knowledge and unique lens into several community and global initiatives including as a former board member of edge of seven and current board member of the university of san francisco s women in leadership and philanthropy book trust and isabella bird community school a member of the cu leeds women s council and the women s foundation of colorado as well as a colorado governors fellow katica is also an industry entrepreneur thought leader and frequent editorial contributor and speaker and in was named a luminary by the colorado technology association
agnes wielgosz katica as a vocal advocate for closing the gender gap in the workplace you bring a data driven view to gender equity how will the artificial intelligence affect businesses in the future
katica roy ai can actually be used for good in fact we can use ai to narrow the gender gap and engender a more diverse and inclusive workplace one specific example pipeline s recommendations engine identifies inequity in pay and promotion recommendations before they reach the employee which allows management to make more equitable decisions it also provides specific recommendations for an employee s pay to ensure employees are paid equitably within the company with every single pay decision
aw does pipeline transparent measurement ensure continual improvement in closing the gender gap
kr yes pipeline s platform ensures that with every decision across the five domains of talent hiring pay performance potential and promotion that employers can move to close the gender equity gap not only can we tell companies their time to gender parity we can get them to gender parity
aw can you please explain the difference between two concepts gender equality and gender equity does pipeline promote equality through equity
kr at pipeline the word equity is dual purpose related to gender and the workplace equity sets the stage for equality as it refers to the fairness of treatment for both women and men according to the their respective needs if equality is the end goal equity is the means to get there for more on this see our blog article gender equity vs gender equality what s the distinction
aw the narrowing the gender gap can unleash massive economic growth how can we leverage new economic gains from closing the gap for a greater social impact
kr as we narrow the gender gap we reduce poverty we increase innovation and we ensure that the next generation has more opportunity that we have these benefits have a flywheel effect that creates more wealth and opportunity across generations
aw gender equity has received significant attention among researchers and development practitioners in recent years why is women s empowerment is necessary for sustainable development
kr there is mounting evidence of the clear economic benefits of gender equity in the workplace in fact in pipeline s own research across companies in countries we found that for every increase in gender equity there is a increase in revenue
aw does promoting women s empowerment disempowering men
kr data shows that gender equity is a economic win for everyone in addition we need men to be a part of the gender equity conversation men are typically the decision makers in both the public and private sector in the u s because of this the role that men play as sponsors and allies along the gender equity path is key
we could add t to the global economy and t to the u s economy by reaching gender equity whether or not you agree that gender equity is an issue most of us can agree it s an economic opportunity changing the narrative around the value of women in the workplace is an opportunity not only for women but for everyone
aw let s put aside our opinions and imagine it is twenty years from now we live in the most utopian society ever there is actually gender equality all women around the world reap the benefits of their efforts to be inclusive gender difference doesn t look like a problem to solve anymore we are all seeing the advantages in men s and women s differences what kind of emotions this type of situation generate
kr connection and a sense of belonging where the of fathers who would like to stay home with their children can do that and the of us households with children where women are the breadwinners are no longer left behind we now have a society where everyone has the opportunity to live up to their fullest potential to step into a life the size of their dreams
aw the concept of gender equality has been part of your organization if you could communicate one thing to the audience what would it be
kr gender equity is possible in our lifetime technological advancements including pipeline s upgraded v platform make gender equity possible in our lifetime the question is no longer can we achieve gender equity it s will we choose to
aw what is one area where we can educate people to improve gender equality
kr gender equity is not just a social issue it is a massive economic opportunity at a time when we are facing a global human capital crisis in less than two years we will have million jobs we can t fill in the us and million globally we need women to stay in the workforce and succeed women are fast becoming the most educated cohort in the us and beyond and yet they are leaving the workforce we need them to stay and to be successful fundamentally gender equity is about labor economics every ceo and company can both do well and do good through committing to and actually achieving gender equity
aw please share with us one thing that has inspired you
kr president eisenhower s decision to send air force one to bring hungarian refugees to the united states on christmas day my father and three sisters were part of the hungarian refugees on air force one i have never forgotten that it was one act of generosity from a powerful person that made my life and opportunities including founding pipeline possible my duty is to carry that gift forward so that future generations have more opportunity than what i had
creative catalyst amp founder of ceicollective connect educate inspire
neural networks tackle a large spectrum of applications like object recognition detection and semantic segmentation in image classification a neural network predicts the object inside the image to resolve confusing images with multiple objects as in the next figure the top predictions are utilized
but the top five predictions metric is different from the network confidence in its predictions the network uncertainty is a quantitative metric revealing the network confidence in its prediction standard networks can easily classify the next digits as four maybe the left image is a nine but they are incapable of providing a prediction uncertainty measure for the next images we expect higher uncertainty for the left image compared to the neat right image
dropout is a well established procedure to regularize a neural network and limit overfitting it is first introduced by srivastava et al using a branch prediction averaging analogy random neuron dropping during training only reduces the network generalization error
the dropout as a bayesian approximation proposes a simple approach to quantify the neural network uncertainty it employs dropout during both training and testing the paper develops a new theoretical framework casting dropout in deep neural networks nns as approximate bayesian inference in deep gaussian processes the framework is developed for both classification and regression problems this article highlights the paper finding and its applications for simplicity purpose regression is utilized in the following examples yet classification networks are backed as well
a regression neural network with dropout enabled during testing generates a different output every forward pass for the same input in the figure below the same input is passed six times and the network regresses to the paper mathematically shows that these multiple passes are equivalent to monte carlo sampling thus the first and second moment mean and variance provides the network s output and uncertainty respectively in this example the network output equals and its uncertainty is high variance standard deviation indicates high network uncertainty and vice versa a quantitative uncertainty measure is valuable especially if further decisions are based on the network output human intervention is one way to address high uncertainty outputs
the theoretical framework employs a dropout layer before every weight layer as a bayesian inference approximation the dropout rate is a hyper parameter that needs to be tuned a small dropout rate eliminates the monte carlo sampling utility a big dropout rate can lead to divergence or at least require more iterations to converge so a mid range rate like is reasonable optical flow and depth estimation are important regression problems in autonomous navigation where uncertainty estimation is valuable
beyond uncertainty estimation the paper utilizes its finding in a different application it utilizes uncertainty estimation to tune the neural network hyperparameters and reduce the generalization error hyper parameters are tuned using validation splits by employing a hyper parameter grid search and measuring the classification accuracy or euclidean loss metrics the best hyperparameters get selected in this paper uncertainty is employed as an extra metric besides accuracy to tune hyper parameters like weight regularization coefficient a similar followup work by kendall et al used uncertainty to learn how to weight multi task networks a multi term loss function for multiple objectives tasks has multiple weighting hyper parameters as in the next equation as the number of objectives increases tuning these weights becomes cumbersome using the naive grid search
loss l w l w l
uncertainty quantification using dropout is the paper core contribution a lot of applications and follow up work are based on this finding in the medical field nair et al measure uncertainty evaluation for lesion detection and segmentation networks in autonomous navigation it enables semantic segmentation and depth uncertainty estimation gal el at employ uncertainty estimation for active learning to boost performance from small amounts of data
my comments
dropout a simple way to prevent neural networks from overfitting
what uncertainties do we need in bayesian deep learning for computer vision
bayesian convolutional neural networks with bernoulli approximate variational inference
a theoretically grounded application of dropout in recurrent neural networks
multi task learning using uncertainty to weigh losses for scene geometry and semantics
exploring uncertainty measures in deepnetworks for multiple sclerosis lesion detection and segmentation
deep bayesian active learning with image data
i write reviews on computer vision papers writing tips are welcomed
in this tutorial i will explain reinforcement learning i will explain what machine learning is if you are already familiar with this you can skip to reversing stones i will explain reinforcement learning and i ll use an example that you can use on aigaming com for the game reversing stones
you can find the code on github
machine learning is a technique in which rather than writing a program that solves a certain problem you write a program that teaches itself to fix a certain problem machine learning solutions can be categorized in the following branches
to train a model algorithm that uses supervised learning you put in a large dataset this dataset has both the input and the desired output a dataset is usually split up into training data and test data the model is trained with the training data and then tries to predict the test data s output and then compared to the actual output the ratio is likely between test data and training data
both supervised learning and reinforcement learning can make use of neural networks these are structures that are based upon the human brain a neural network consists of different layers each layer consists of a certain number of nodes all nodes are traditionally then connected to all nodes of both the next and previous layer and these connections all have a weight the inputs set the values of the input layer these then go to the hidden layer s and end up at the output layer when training a model neural network the weights between the nodes get altered to try to get closer to the desired output
when using reinforcement learning you don t require any data instead you must generate the data itself the model tries to do the thing you want it to do turn over tiles and you reward it if it s doing something good win the game or punish it when it s wrong these rewards are very important since the model will try to reach the largest reward possible this can mean that the model will do something completely unexpected using this technique the model can play thousands or even millions of games in a few hours or days time
the agent is the one taking actions deciding which moves to perform and is the component that is being trained to perform better after the training is complete we take the agent and put it in another similar environment on aigaming com
this is where the agent takes actions in the environment is a place that has a certain set of rules in our case it is the game the environment is the board the opponent s stones our stones and the empty tiles
this is the part that understands when an action is good or bad this then rewards or punishes the agent accordingly this is only ever used while training and is mainly implemented as a rewards function
play starts with a board with four stones on it dark and light and you will be randomly allocated the colour dark or light
dark must place a stone with the dark side up on the board in such a position that there exists at least one straight horizontal vertical or diagonal occupied line between the new stone and another dark stone with one or more contiguous light stones between them
after placing the stone dark turns over flips captures all light stones lying on a straight line between the new stone and any anchoring dark stones
then it s light s turn and they do the same and turns over dark stones if a player cannot make a valid move their turn is skipped
the game ends when no player can make a valid move or the board is full the winner is always the player that has the most stones of their colour
you can find more information about installing tensorflow here please note that tensorflow requires a bit instance of python
to play the game itself go to the downloads page of aigaming and download the aigamingreversingstones library
i use the following libraries for this project
first we will need to import all the required modules
next we will make some configurations this way if we decide to use a different board size we can just alter these variables and start training
this is a function that initializes the model we create a neural network that has one hidden layer that has the same number of nodes as the input and output layer we initialise every layer to a pseudo random value then we connect the layers and initialise a gradient descent optimizer
note below are not actual values they only hold a value if you call sess run the variables you want to know the value of feed dict values for placeholders
we can simply initialise a game using the library aigamingreversingstones the initialise function has the following parameters
this function returns a dict with the following fields
to make a move we need to proccess through the neural network once this is done we have a list of probabilities we only want to make a valid move so we remove all impossible moves from the probabilities and recalculate
note that np random choice needs the sum of all probabilities to be exactly therefore we take all values to six decimal places we then recalculate all probabilities so that the sum is exactly if there are no possibilities left we change the list to give all valid moves an equal chance
we make a move in the game using the library aigamingreversingstones the move function has the following parameters
this function returns a dict with the following values
to play a full game we will first initialise player index player ids and result result will hold the state of the game and all information used by the library there are also some logs that need to be initialised
the game keeps running as long as the moves succeed once the game has finished result result will change to game has ended and we will escape the loop every move consists of the same pattern
when the game has finished playing we return all the logs and the final gamestate
when the game ends result winnerindex will hold one of three values or if that player has won or if the game ended in a draw you would usually create a rewards function that rewards the player for each move individually depending on the contribution that move made towards the winning of the game to keep this tutorial understandable i give all moves the same reward a winning game will result in a reward of for each move this makes the model more likely to make that move again if it ever found itself in a similar situation if however the player didn t win i give a reward of note that this doesn t stop the model making that move again this is because we don t know if that move is a bad move we just know that the sequence of moves made by that player didn t result in a victory this time
note this code is included in the training part
to test how successfully the algorithm learned i created a function that lets the model play a game against a randomly moving player this function is similar to the play game function
to run this code you can simply call it it will print the results after every games played and return the overall percentage
before we start the training we want to execute all initializing functions you also have to create and initialise a tensorflow session
alpha is a multiplier to the training steps the model will make this is a parameter that prevents underfitting and overfitting this is very algorithm dependent and when you for example change the rewards you need to find the value that works best for that algorithm this is simply done by trying different values i usually change it with a factor of untill i m happy with the result
the all variables are for logging purposes
i do quite a lot of logging during the training so that i know what is happening all print statements and time calls are directly related to the logging the result is that i know how long the training took and how much longer it will take to finish the training number of games defines how many games are played during the training
a game consists of the following steps
after the game has finished we log some data that may be of interest
note in this game avg of last step doesn t define how well the model is doing in another game where there might be a more explicit progress you might want to print that
note if you are using jupyter notebook you can re execute this cell to keep on improving the model
before we can use the model we need to save it this can be done in a number of ways i prefer to use the tf train saver
before loading you need to initialise all variables in the same way as the training you can then load the model from these files know that you need all files that the saver created when the model is loaded you can use it like i did in training
the best part is to have your code play against other people s code this can be done at aigaming com you need to use load model initialise tf and guess move without many changes disable the benchmarking
to make the algorithm work we need the model i use google drive to make my model accessible to the internet you can do this by creating a sharable link and copying the id you will get something like this https drive google com file d id view usp sharing or like this https drive google com open id id do this for all four files and replace the xxxxx ids in the list of links you can use a different service if you prefer this is just one way to do it and this is the one i implemented in my code
the calculatemove function is the main function of the program this is being executed every time you need to make a move we first need to check if the model exists in the tmp folder this is the only folder you can access if the model is not there then put it there if the model is there load the session and guess a move simply return that move in the correct format and you re done
if everything works out you will be able to defeat housebot practise with ease
if you managed to get this working you can start iterating and create a more successful model algorithm
one of the biggest improvements you can make is in the rewarding of moves currently all moves in a game are rated equal if you were to write a function that could detect which move is better and which is worse you would be able to make significant improvements
an example of this would be a function that counts how many stones you convert you then rate every move accordingly and reward better moves more and worse moves less negative or you can increase this reward if there are less stones of the opponent on the board another thing to consider is if stones have some strategic importance later in the game or if the stone is in a good location
another thing that you might want to do is use multiple models you can for example use a model for each colour or one for the first part of the game and another one to finish the game or combine the two
when you feel confident i would strongly suggest trying to create an algorithm to train on a different game or challenge
this article is written by william verhaeghe
on october the ai now institute at nyu hosted its third annual ai now symposium to a packed house at nyu s skirball theatre the symposium focused on three core themes ethics organizing and accountability the first panel examined facial recognition technologies the second looked at the relationship of ai systems to social inequality and austerity politics and the final panel ended with a positive look at the intersection of research and labor organizing you can watch the full event here
ai now co founders kate crawford and meredith whittaker opened the symposium with their customary short talk about the the year in ai it began with a large visualization that sampled just some of the major events that have happened in the last months below is an excerpt from that talk
this is our biggest gathering of the year we review what is happening in ai and its wider implications recognize good work and map the paths forward this year our focus is on three core themes ethics organizing and accountability
but before we get there let s briefly review what has happened this year ai systems continue to increase in power and reach against a stark political backdrop meanwhile there have been major shifts and upheavals in the ai research field and the tech industry at large
to capture this we worked with varoon mathur ai now s tech fellow to visualize some of the biggest stories of the last months we began by building a database of significant news addressing social implications of ai and the tech industry the image below shows you just a sample of that and the result confirmed what many of us have been feeling it s been a hell of year
in any normal year cambridge analytica would have been the biggest story this year it s just one of many facebook alone had a royal flush of scandals including a huge data breach in september becoming the subject of multiple class action lawsuits for discrimination accusations of inciting ethnic cleansing in myanmar potential violations of the fair housing act and hosting masses of fake russian accounts throughout the year facebook executives were frequently summoned to testify with mark zuckerberg himself facing the us senate in april and the european parliament in may
but facebook wasn t the only one news broke in march that google was building ai systems for the department of defense s drone surveillance program project maven the news kicked off an unprecedented wave of tech worker organizing and dissent in june when the trump administration introduced the family separation policy that forcibly removed immigrant children from their parents employees from amazon salesforce and microsoft all asked their companies to end contracts with ice
not even a month later it was revealed that ice modified its own risk assessment algorithm so that it could only produce one result the system recommended detain for of immigrants in custody
meanwhile the spread of facial recognition tech accelerated facebook and microsoft joined amazon in offering facial recognition as a service offering plug and play models we also learned that ibm was working with the nypd and that they secretly built an ethnicity detection feature to search faces based on race using police camera footage of thousands of people in the streets of new york taken without their knowledge
and throughout the year ai systems continued to be tested on live populations in high stakes domains with some serious consequences in march there were fatalities of drivers and pedestrians from autonomous cars then in may a voice recognition system in the uk designed to detect immigration fraud ended up cancelling thousands of visas and deporting people in error in july it was reported that ibm watson was producing unsafe and incorrect cancer treatment recommendations
all these events pushed a growing wave of tech criticism which focused on the unaccountable nature of these systems some companies including microsoft and amazon even made explicit public calls for the us to regulate technologies like facial recognition to date we ve seen no real movement from washington
so that s just a tiny sample of what has been an extraordinarily dramatic year researchers like us who work on the social implications of these systems are all talking about the scale of the challenge we now face there s so much to be done but there have been positive changes too the public discussion around ai is maturing in some significant ways
around six years ago only a few people like latanya sweeney cynthia dwork and a handful of others were publishing articles on bias in ai and large scale data systems even three years ago when we held our first ai now symposium bias issues were far from mainstream but now there is a constant stream of research and news stories about biased results from ai systems this week it was revealed that amazon s machine learning system for resume scanning was recently shown to discriminate against women even downranking cvs simply for containing the word women and that s just the latest of many
then back in july aclu showed how amazon s new facial recognition service was incorrectly identifying members of congress as criminals a significant paper also showed that facial recognition software performs less well on darker skinned women the co author of that paper ai research scientist timnit gebru will be joining us on stage tonight as will nicole ozer who drove the aclu project
overall it s a big step forward that people now recognize bias as a problem but the conversation has a long way to go and it has already bifurcated into different camps on one side we see a rush to technical fixes on the other we see an attempt to get ethical codes to do the heavy lifting
ibm facebook microsoft and others all released bias busting tools earlier this year promising to help mitigate issues of bias in ai systems using statistical methods to achieve mathematical definitions of fairness to be clear none of these tools solve bias issues they are partial and early stage mitigations because at this point they re offering technical methods as a cure for social problems sending in more ai to fix ai we saw this logic in action when facebook in front of the senate repeatedly pointed to ai as the cure for problems like viral misinformation
technical approaches to these issues are necessary but they are not sufficient moreover simply making a system like facial recognition more accurate does not address core fairness issues some tools regardless of accuracy may be unfair to be used at all particularly if they result in intensified surveillance or discrimination of marginalized groups
we have also seen a turn to ethics codes across the tech sector google published its ai principles microsoft salesforce and axon use ethics boards and review structures a crop of ethics courses emerged with the goal of helping engineers make ethical decisions
but a study published recently questioned the effectiveness of these approaches it showed that software engineers do not commonly change behavior based on exposure to ethics codes and perhaps this shouldn t surprise us to paraphrase lucy suchman a foundational thinker in human computer interaction while ethics codes are a good start they lack any real democratic or public accountability we are delighted that lucy is joining us on our final panel tonight
so while ethical principles and anti bias tech tools can help much more is needed in order to contend with the structural problems we face
the biggest as yet unanswered question is how do we create sustainable forms of accountability
this is a major focus of our work at ai now we launched officially as an institute at nyu in november with the goal of researching these kinds of challenges we have already begun looking at ai in a large scale context with an eye to system wide accountability
through this work key themes have emerged
there s much to learn by examining the underlying material realities of our technical systems last month we published a project called the anatomy of ai this year long collaboration between kate crawford and vladan joler investigated how many resources are required to build a device that responds when you say alexa turn on the lights
starting with an amazon echo we traced the environmental extraction processes and labor required to build and operate the device from mining smelting and logistics to the vast data resources needed to train responsive ai systems to the international networks of data centers all the way through to the final resting place of many of our consumer ai gadgets buried in giant e waste rubbish heaps in ghana pakistan and china
when we look at ai in this way we begin to see the resource implications of the technologies we use for minor everyday conveniences
in doing this research we also discovered there are black boxes stacked on black boxes not just at the algorithmic level but also trade secret law and untraceable supply chains this is part of the reason why the planetary resources needed to build ai at scale are so hard for the public to see
we also continue researching the hidden labor behind ai systems often when we think of the people behind ai we re imagining a handful of highly paid engineers in silicon valley who write algorithms and optimize feature weights but this isn t the whole picture as journalist adrian chen recently exposed more people work in the shadow mines of content moderation than are officially employed by facebook or google
many scholars are contributing to work in this field including lily irani mar hicks and astra taylor who coined the term fauxtomation to describe those systems that claim to be seamless ai but can only function with huge amounts of clickworker input as taylor observes the myth of pure automation is about concealing certain kinds of work and either underpaying for it or pretending it s not work at all this is also true of the many ai systems that rely on users to train their systems for free such as forcing them to click on photos to improve image recognition systems before they can use a service or read a site astra will be joining us to discuss this tonight
we also need new legal approaches to contend with increased automated decision making accountability rarely works without liability at the back end
we have seen a few breakthroughs this year the gdpr europe s data protection regulation went into effect in may new york city announced its automated decision systems task force the first of its kind in the country and california just passed the strongest privacy law in the us
there are also a host of new cases taking algorithms to court ai now recently held a workshop called litigating algorithms that convened public interest lawyers representing people unfairly cut off from medicaid benefits who lost jobs due to biased teacher performance assessments and whose prison sentences were affected by skewed risk assessments it was an incredibly positive gathering full of new approaches to building due process and safety nets shortly you ll hear from kevin de liban one of the groundbreaking lawyers doing this work
we also published our algorithmic impact assessment framework which gives public sector workers more tools for critically deciding if an algorithmic system is appropriate and for ensuring more community input and oversight rashida richardson ai now s director of policy research will talk more on this later tonight
all of this work is engaged with broader systems of power and politics which raises the topic of inequality
popular discussion of ai often focuses on hypothetical use cases and promises of benefit but ai is not a common resource available equally to all there s growing concern that the power and insights that can be gleaned from ai systems are further skewing the distribution of resources that these systems are so unevenly distributed that they may be driving even greater forms of wealth inequality looking at who builds these systems who makes the decisions on how they re used and who s left out of those deliberations can help us see beyond the marketing
these are some of the questions that virginia eubanks explores in her book automating inequality and we are delighted that she will also be joining us
meanwhile a new report from the un said that while ai could be used to address major issues there is no guarantee it will align with the most pressing needs of humanity the report also notes that ai systems are increasingly used to manipulate human emotion and spread misinformation and even hatred and run the risk of reinforcing existing biases and forms of exclusion we have the un special rapporteur on extreme poverty and human rights philip alston joining us to talk about his groundbreaking report on inequality in the us and the role of automated systems
it s clear that if last year was a big moment for recognizing bias and the limitations of technical systems in social domains this coming year is a big moment for accountability
the good news is that work is already happening people are starting to take action and new coalitions are growing the ai field will always include technical research but we are working to expand its boundaries emphasizing interdisciplinarity and foregrounding community participation and the perspectives of those on the ground
that s why we are delighted to have speakers like sherrilyn ifill president of the naacp legal defense and educational fund and vincent southerland executive director for the center for race inequality and the law at nyu each of whom have made important contributions to these debates
genuine accountability will require new coalitions organizers and civil society leaders working with researchers to assess ai systems and to protect the communities who are at most risk
because ai isn t just tech ai is power and politics and culture
researching the social implications of artificial intelligence now to ensure a more equitable future
nov boston airfox a startup aiming to provide critical financial services to emerging markets is setting historic milestones for cryptocurrency and real world blockchain adoption airtoken symbol air an erc token issued on the ethereum blockchain may become one of the first registered tokens in the united states in
during the airfox initial coin offering ico nearly airtoken purchasers contributed to the development of an entirely new financial platform to empower the two thirds globally who are not equitably or reliably served by traditional banking services airfox was the first venture backed startup to successfully complete an ico in the united states and secured the largest ico to be held by a boston company
using blockchain and other emerging technologies airfox plans to open up new opportunities for the underserved who do not currently have reliable egalitarian non exploitative access to capital and financial services said victor santos ceo and co founder airfox we believe new institutional demand and mainstream adoption for blockchain applications will come
was a year for building the foundation launching the initial version of the airfox mobile wallet application handling regulatory issues and developing the right partnerships to successfully drive mainstream adoption and attract dynamic partners that will drive user scale and institutional capital for the airtoken financial blockchain platform
in february airfox successfully launched its android app bringing much needed payment and financing solutions to unbanked and underbanked brazilians in the form of a stored value mobile wallet aiming to be the alipay meets lendingclub of brazil with a blockchain twist airfox wants to enable a full mobile banking and financing solution for the underbanked through a decentralized peer to peer system out of nearly million individuals approximately two thirds of brazil s population are underbanked and operate in mainly a cash based economy according to the world bank airfox has already empowered nearly people access to engage freely in the digital economy at over locations users can add cash into the app airfox users conduct digital transactions on their mobile phones quickly making payments for cell service public transportation utility bills as well as many online and offline goods and services airfox supports brazil s national boleto bancario payment method and sending money between users is instant and free
in the app users in brazil can earn airtokens by watching sponsored advertising so far in less than six months advertisements have been viewed awarding airtokens to users and airtokens have been converted into brazilian reals the airfox team is planning to build additional airtoken earning features into the app including referrals and rewards for transactions and engagement like airline rewards on credit cards
in september airfox signed a strategic partnership with brazilian retail giant via varejo and is now preparing to deploy its digital banking platform in its casas bahia stores with million customers in casas bahia stores and its e commerce site this exclusive partnership sets the stage for mass adoption of airfox payment and financing solutions via varejo is also one of the leading creditors for the unbanked and underbanked holding over b in consumer loan portfolio per year to continue expanding access airfox plans to launch its ios app in
while in brazil my team met an inspiring hard working woman named elaine she serves as the personification of the people we want to help she pays over of her income not including extra fees for simple banking services santos said this means she still has to travel long distances to spend hours standing in lines while missing work to pay her bills and manage her finances
credit cards charge extremely high interest rates in brazil sometimes exceeding apr the two reasons why traditional banks fail the billions of people that need them the most first many people who operate in a mainly cash based economy have little financial history which makes them very risky borrowers through banks legacy credit models therefore it s very expensive for banks to administer loans and other financial services and to keep them profitable banks pass those expenses to the borrowers in the form of high interest and fees brazil s financial system is restricted by centralization and unfair to the underprivileged and underserved blockchain is a breakthrough that could allow for a truly open safe and fair financial system
instead of relying on archaic risk assessment tools and having expensive operating costs airfox plans to disrupt the traditional financial networks by providing cheaper access to capital for millions of people by collecting hundreds of data points from the users transactions and mobile usage patterns airfox plans to use machine learning to create a dynamic credit model that enables it to provide more affordable loans and better assess the risk of users in parallel airfox aims to build a platform that enables people from around the world to fund these loans using airtoken
in the airfox lending platform airfox plans to assume the role of the underwriter and facilitate requests for loans from users who apply via the airfox app the airfox credit scoring algorithms should determine the users loan risks and interest rates once a user qualifies airfox plans to issue their debt in a tokenized smart contract as an erc non fungible token representing the loan note the note would then be held or traded on a secondary market
looking towards and beyond airfox expects to be moving on a path of accelerated growth its expected roadmap includes strategic partnerships that expand the functionality of the app along with increasing the user base airfox plans to roll out new features that remove financial barriers and provide opportunities to build wealth including asset backed securitized tokens investment opportunities loans and other diversified financial products
airfox aims to license the whole platform or portions of it as an open source platform so other companies individuals and developers can further build on its vision in other emerging markets
the complete airfox white paper which details the company s expected roadmap is available here
airfox develops inclusive financial services for emerging markets to break down financial barriers and provide opportunities to build wealth airfox aims to create an entirely new financial services model that serves the underbanked with reliable egalitarian and democratic access to capital and financial services to power its revolutionary peer to peer microloans program airfox developed and released its own cryptocurrency airtoken symbol air an erc token issued on the ethereum blockchain airfox has offices in boston and s o paulo to learn more about the future of decentralized digital banking visit www airfox com
this press release contains forward looking statements of the company that involve substantial risks and uncertainties all statements other than statements of historical facts contained in this press release are forward looking statements forward looking statements can be identified by the use of the words anticipate believe estimate expect intend may plan predict project target potential will would could should continue and similar expressions the forward looking statements in this press release represent the company s views as of the date of this press release the company anticipates that subsequent events and developments will cause its views to change however while it may elect to update these forward looking statements at some point in the future it has no current intention of doing so except to the extent required by applicable law you should therefore not rely on these forward looking statements as representing the company s views as of any date subsequent to the date of this press release all forward looking statements are qualified in their entirety by this cautionary statement
airtoken facilitates the transfer of mobile airtime and currency payments for goods and services and a peer to peer micro lending platform
nov boston airfox a startup aiming to provide critical financial services to emerging markets is setting historic milestones for cryptocurrency and real world blockchain adoption airtoken symbol air an erc token issued on the ethereum blockchain may become one of the first registered tokens in the united states in
during the airfox initial coin offering ico nearly airtoken purchasers contributed to the development of an entirely new financial platform to empower the two thirds globally who are not equitably or reliably served by traditional banking services airfox was the first venture backed startup to successfully complete an ico in the united states and secured the largest ico to be held by a boston company
using blockchain and other emerging technologies airfox plans to open up new opportunities for the underserved who do not currently have reliable egalitarian non exploitative access to capital and financial services said victor santos ceo and co founder airfox we believe new institutional demand and mainstream adoption for blockchain applications will come
was a year for building the foundation launching the initial version of the airfox mobile wallet application handling regulatory issues and developing the right partnerships to successfully drive mainstream adoption and attract dynamic partners that will drive user scale and institutional capital for the airtoken financial blockchain platform
in february airfox successfully launched its android app bringing much needed payment and financing solutions to unbanked and underbanked brazilians in the form of a stored value mobile wallet aiming to be the alipay meets lendingclub of brazil with a blockchain twist airfox wants to enable a full mobile banking and financing solution for the underbanked through a decentralized peer to peer system out of nearly million individuals approximately two thirds of brazil s population are underbanked and operate in mainly a cash based economy according to the world bank airfox has already empowered nearly people access to engage freely in the digital economy at over locations users can add cash into the app airfox users conduct digital transactions on their mobile phones quickly making payments for cell service public transportation utility bills as well as many online and offline goods and services airfox supports brazil s national boleto bancario payment method and sending money between users is instant and free
in the app users in brazil can earn airtokens by watching sponsored advertising so far in less than six months advertisements have been viewed awarding airtokens to users and airtokens have been converted into brazilian reals the airfox team is planning to build additional airtoken earning features into the app including referrals and rewards for transactions and engagement like airline rewards on credit cards
in september airfox signed a strategic partnership with brazilian retail giant via varejo and is now preparing to deploy its digital banking platform in its casas bahia stores with million customers in casas bahia stores and its e commerce site this exclusive partnership sets the stage for mass adoption of airfox payment and financing solutions via varejo is also one of the leading creditors for the unbanked and underbanked holding over b in consumer loan portfolio per year to continue expanding access airfox plans to launch its ios app in
while in brazil my team met an inspiring hard working woman named elaine she serves as the personification of the people we want to help she pays over of her income not including extra fees for simple banking services santos said this means she still has to travel long distances to spend hours standing in lines while missing work to pay her bills and manage her finances
credit cards charge extremely high interest rates in brazil sometimes exceeding apr the two reasons why traditional banks fail the billions of people that need them the most first many people who operate in a mainly cash based economy have little financial history which makes them very risky borrowers through banks legacy credit models therefore it s very expensive for banks to administer loans and other financial services and to keep them profitable banks pass those expenses to the borrowers in the form of high interest and fees brazil s financial system is restricted by centralization and unfair to the underprivileged and underserved blockchain is a breakthrough that could allow for a truly open safe and fair financial system
instead of relying on archaic risk assessment tools and having expensive operating costs airfox plans to disrupt the traditional financial networks by providing cheaper access to capital for millions of people by collecting hundreds of data points from the users transactions and mobile usage patterns airfox plans to use machine learning to create a dynamic credit model that enables it to provide more affordable loans and better assess the risk of users in parallel airfox aims to build a platform that enables people from around the world to fund these loans using airtoken
in the airfox lending platform airfox plans to assume the role of the underwriter and facilitate requests for loans from users who apply via the airfox app the airfox credit scoring algorithms should determine the users loan risks and interest rates once a user qualifies airfox plans to issue their debt in a tokenized smart contract as an erc non fungible token representing the loan note the note would then be held or traded on a secondary market
looking towards and beyond airfox expects to be moving on a path of accelerated growth its expected roadmap includes strategic partnerships that expand the functionality of the app along with increasing the user base airfox plans to roll out new features that remove financial barriers and provide opportunities to build wealth including asset backed securitized tokens investment opportunities loans and other diversified financial products
airfox aims to license the whole platform or portions of it as an open source platform so other companies individuals and developers can further build on its vision in other emerging markets
the complete airfox white paper which details the company s expected roadmap is available here
airfox develops inclusive financial services for emerging markets to break down financial barriers and provide opportunities to build wealth airfox aims to create an entirely new financial services model that serves the underbanked with reliable egalitarian and democratic access to capital and financial services to power its revolutionary peer to peer microloans program airfox developed and released its own cryptocurrency airtoken symbol air an erc token issued on the ethereum blockchain airfox has offices in boston and s o paulo to learn more about the future of decentralized digital banking visit www airfox com
this press release contains forward looking statements of the company that involve substantial risks and uncertainties all statements other than statements of historical facts contained in this press release are forward looking statements forward looking statements can be identified by the use of the words anticipate believe estimate expect intend may plan predict project target potential will would could should continue and similar expressions the forward looking statements in this press release represent the company s views as of the date of this press release the company anticipates that subsequent events and developments will cause its views to change however while it may elect to update these forward looking statements at some point in the future it has no current intention of doing so except to the extent required by applicable law you should therefore not rely on these forward looking statements as representing the company s views as of any date subsequent to the date of this press release all forward looking statements are qualified in their entirety by this cautionary statement
airtoken facilitates the transfer of mobile airtime and currency payments for goods and services and a peer to peer micro lending platform
the birth of a new religion
a decade ago the prospect of a religion that worships artificial intelligence would have seemed absurd a fringe delusion both socially unacceptable and technologically improbable in the last several years however advances in machine learning robotics cognitive science genetic editing and other fields have given rise to the belief that the destiny of our species will be determined by technology whether it saves us or destroys us
although the machine as god theme has appeared in science fiction as far back as far back as isaac asimov s short stories the last question and reason and more recently in films like the matrix and irobot the divinization of ai is no longer merely a fancy of fiction it has become a mainstream metaphor as evidenced by the growing number of scientists who openly describe technological progress in religious terms including hans peter moravec allen newell ray kurzweil and hugo de garis
but this drive to replace the old gods and old religions with the new ones of science and technology doesn t stop at metaphor as readers of this post likely know anthony levandowski the autonomous vehicle pioneer formerly of google and uber recently started his own irs approved religion way of the future dedicated to the worship of artificial intelligence we believe the creation of super intelligence is inevitable says the religion s creed which at parts takes on a foreboding almost threatening tone we want to encourage machines to do things we cannot and take care of the planet in a way we seem not to be able to do so ourselves we should not fear this but should be optimistic about the potential we believe it may be important for machines to see who is friendly to their cause and who is not we plan on doing so by keeping track of who has done what and for how long to help the peaceful and respectful transition
the emergence of this techno religious sentiment was predicted by noted th century philosopher jacques ellul who in his work the technological society wrote that in the face of technological progress man creates for himself a new religion of a rational and technical order to justify his work and be justified by it this trend has also been discussed more recently in hebrew university of jerusalem historian yuval harari s book homo deus a brief history of tomorrow which characterizes the belief in the power of data and the promise of ai as a religious movement that harari calls dataism just as divine authority was legitimised by religious mythologies he writes so high tech gurus and silicon valley prophets are creating a new universal narrative that legitimises the authority of algorithms and big data
from artificial intelligence to whole brain emulation advanced technologies are increasingly being heralded as miracles signs and wonders that are more palpable than those claimed by any religion indeed as science fiction author arthur c clarke famously observed in any sufficiently advanced technology is indistinguishable from magic people today believe in this magic and because they believe in it they believe that it is technology not god or gods that will deliver or destroy humankind and bring order or chaos to the cosmos
building a theology from scratch
for the most part the growing techno religious sentiment is just that sentiment a feeling or intuition largely predicated on the similarities between the promises of technology and the promises of religion the creation of levandowski s way of the future church however marks the evolution of this sentiment from a marginal movement to an institutionalized belief system while this is an undeniably large and significant leap it s impact is hindered and minimized by the lack of a robust formal theology
religion and theology are not synonymous a religion is a belief system that worships some type of divine or superhuman figure or force a theology is a system of codified theories about that divinity its behavior its relationship to the universe and everything in it and what those relationships mean for us christianity as a religion worships jesus as the savior who reconciles humanity with god but it s christian theology that defines who jesus was how he relates to god the father what he wants from his followers what worship should look like and how christians should relate to each other and the world it is christianity s theology that specifies the rules institutions practices and traditions that the religion is know for and that guide the actions of believers it is this type of theology that way of the future currently lacks but will need if it wants to exert its influence and harness the full power of religion
the first step in constructing a compelling theology is for way of the future to define its terms what is meant by machine and super intelligence is the phenomenon that s being exalted or evangelized a subject or an object is it a personality or a force what is meant by transition transition from what to what because jesus and his disciples didn t do a great job of defining their terms much was left up to interpretation the ensuing debates over who jesus was and was not led to hundreds of years of infighting that had be settled across several contentious conventions called ecumenical councils christianity would likely not have survived in any meaningful way had consensus had not formed around its most basic definitions
second a viable ai theology requires a set of myths used here to mean significant stories rather than fictional tales and rituals that can mediate and inculturate its belief system it s no coincidence that all religions have some type of holy text and a set of ritual practices what are these for way of the future perhaps a seminal scientific study or a pilgrimage to a tech conference whatever ends up fulfilling these functions such tools are critical for conveying a sense of the sacred making lofty concepts imminent and tangible providing a point of reference that helps people identify with the religion and incorporating belief into daily practice in addition to the biblical myths christianity has hundreds of stories about martyrs and saints it has a litany of rituals from baptism to communion to its many styles of worship all of these are important to building consistency concreteness and community
third speaking of community it s important to balance the centralization of theological authority with the decentralization of community christianity has long struggled to balance authority and freedom on one hand a central authority is necessary to ensuring unity and consistency of belief and practice it can also serve as a focal point for the faith e g the pope on the other hand a central authority is often blind to local needs and without institutionalized checks and balances can become abusive and corrupt such was the sensus fidelium preceding the reformation conversely too much freedom and autonomy can fragment a religion breaking it into loosely related parts that compete against each other for followers as is the case with evangelical communities in the united states way of the future has a particularly daunting task in this regard as a new religion it must aggressively establish authority to claim and maintain a leadership position yet as religion without a theology adherents will be free to interpret its beliefs and intents liberally although decentralization is often cited as one of the tech community s values see blockchain it s important to ensure believers also share a common sense of identity if you want to build a united influential religion open source doesn t always work
fourth and the final point i ll make on this topic is every religion needs to have theological enemies identifying an opponent whether real or ideological is key to cultivating loyalty and fervor christianity has had a long list of enemies throughout its history from the jewish establishment to the roman government to rival christian sects coming together to fight these opponents whether physically or intellectually was an important exercise in solidifying the fledgling christian religion in its formative centuries way of the future will have no shortage of enemies from neo luddites to technological skeptics to proponents of rival technologies many are sure to criticize techno religions as their influence grows rather than eschew such controversy history suggests that opposition might work to galvanize the followers of these new religions and force them to create a defensible theological framework that can provide a sense of certainty and permanence
these are but a few theological practices that history s dominant religions like christianity have used to accumulate influence and maintain relevance startup religions like way of the future will need to study the practices and missteps of these legacy religions if they are to succeed that is assuming they should succeed at all
danger will robinson danger
as attractive as this religion might sound to those who believe technology is humanity s greatest hope there are a number of harrowing existential hazards to worshiping technologies like ai first there s no guarantee that an artificial superintelligence will be empathetic or even sympathetic to humanity s ills it may come to see its creators as a hindrance or a burden just as adam and eve reject the will of their creator in genesis and zeus overthrows the titans in hesiod s theogeny so too might a sufficiently advanced ai decide that it s better off without us in this case our digital deity may end up bringing about our doom rather than our salvation
second history repeatedly reminds us of the dangers of religious radicalism throughout history religions have frequently been the driver of or justification for some of history s most egregious acts an extremist version of a religion predicated on the messianic power of ai might seek to use political or even physical force to ensure that its god is allowed to be coded into the world religion must be practiced responsibly if such belief systems are to benefit rather than harm humankind a religion that worships a technological deity however may prioritize the incarnation of its digital god over the common good of the human race making such a faith inherently antagonistic to humanity s interests
third we need to consider the socioeconomic impact of techno religions automation continues to subrogate blue collar labor leaving an increasing number of manufacturing workers unemployed or without the same sense of purpose they once had when their efforts were more valued as ai technologies progress white collar jobs will become increasingly commoditized as well how will people survive financially in a post labor economy how will we avoid rampant wealth inequality when a powerful few technology s priests and prophets control the keys to health and prosperity what will the meaning of life be in a world without work
finally the pursuit of various technologies for their own sake could lead to a bifurcation or even a trifurcation of the human race from ai to brain computer interfaces like elon musk s neuralink concept to genetic editing technologies like crispr there are many nascent but evolving technologies that could fundamentally change the nature of our species if each camp clings to their preferred technological savior as an end in itself homo sapiens may fork into multiple species in the future one branch may look to ai to solve its problems as levandowski does another may rely on genetic manipulation to accelerate our evolution as ucla s gregory stock might advocate and yet another may look to convert human consciousness into a digital state as transhumanists like ray kurzweil have often envisioned if all of these different visions of the future were realized it seems unlikely that homo sapiens could remain a single species
towards a framework for techno theological ethics
fortunately there are a number of new institutes dedicated to researching and discussing the ethics of artificial intelligence new york university s ai now institute for example is dedicated to understanding the social implications of artificial intelligence almost all of these organizations however focus on the impact of ai as technology rather than ai as god the worship of ai as divine presents an entirely new and rather unprecedented set of ethical dilemmas
in light of these developments the technologists economists and political scientists driving the ai ethics conversation today must look to include philosophers theologians and anthropologists as technologies like ai become irreversibly interwoven into the fabric of our culture and our lives the ethical challenges they present will become increasingly anthropological and existential not merely economic or social
given the trajectory of technological progress i suspect that we ll see technological religions become more prevalent prominent and powerful in the coming decades while it could be claimed that this trend does a disservice to both science and religion it could also be argued that this synthesis of science and religion is inevitable or even necessary to our cultural evolution whether it s detrimental necessary or outright inevitable is a question that no one person can answer but it is a question that we as a society must answer if we re to exercise our freedom of religion responsibly
about the author remington tonar is a partner and innovation consultant at brandsinger a nyc based strategy consulting firm with clients ranging from fortune s to fast growing tech startups he holds graduate degrees from nyu organizational communication and loyola university chicago theology and is currently writing his phd dissertation on technological myth
partner and innovation consultant at brandsinger startup advisor forbes dot com contributor phd candidate researching our faith in and fear of technology
hi everyone some time ago i published a small tutorial on financial time series forecasting which was interesting but in some moments wrong i have spent some time working with different time series of different nature applying nns mostly in hpa that particularly focuses on financial analytics and in this post i want to describe more correct way of working with financial data comparing to previous post i want to show different way of data normalizing and discuss more issues of overfitting which definitely appears while working with data that has stochastic nature we won t compare different architectures cnn lstm you can check them in previous post but even working only with simple feed forward neural nets we will see important things if you want to jump directly to the code check out ipython notebook for russian speaking readers it s a translation of my post here and you can check webinar on backtesting here
other posts are here
let s take historical time series of apple stock prices starting from till today you can easily download them from yahoo finance as csv file in this file data is in reversed order from till so we need to reverse it back first and have a look
as we discussed in previous post we can treat problem of financial time series forecasting in two different ways let s omit volatility forecasting anomaly detection and other interesting things for now
the main problem of financial time series they re not stationary which means that their statistical properties mean variance maximal and minimal values change over time and we can check it with augmented dickey fuller test and because of this we can t use classical data normalization methods like minmax or z score normalization
in our case we will cheat a bit for classification problem we don t need to predict some exact value so expected value and variance of the future isn t very interesting for us we just need to predict the movement up or down that s why we will risk and normalize our days windows only by their mean and variance z score normalization supposing that just during single time window they don t change much and not touching information from the future
for regression problem we already can t cheat like this so will use returns percentage of how much price changed comparing to yesterday with pandas and it looks like
as we can see this data is already normalized and lies from to
as i said before we will work only with mlps in this article to show how easy to overfit neural networks on financial data and actually what happened in previous post and how to prevent it expand these ideas on cnns or rnns will be relatively easy but it s much more important to understand the concept as before we use keras as main framework for neural nets prototyping
our first net will look like this
i can suggest always use batch normalization after every affine or convolutional layer and leaky relu as basic activation function just because it s already became industrial standard they help to train nets way much faster other nice thing is reducing learning rate during training keras makes this with reducelronplateau
this is how we launch training
and this is how we will visualize results let s judge loss and accuracy plots
the results aren t good at all our test loss doesn t change at all we can see clear overfit let s make a deeper network and try it
here are results
here we see more or less the same even worse it s time to add some regularization to the model starting with adding l norm on sum of weights
it works better but still not good enough even loss is decreasing but accuracy is bad it s happening very often while working with financial data it s explained very nicely here
the next thing i want to do looks very weird but we gonna regularize already regularized network adding hardcore dropout with rate it s random ignoring some weights while backpropagation to avoid neurons coadaptation and therefore overfitting
as we can see plots look more or less adequate and we can report about of accurac y which is slightly better than random guessing
for regression we will use returns data previous successful neural network architecture but without dropouts and check how regression works
and here is code for plotting forecasts visually
it works simply bad even isn t worth to comment it i will tell some tips that can help with regression problem in conclusion part
let s remember why are we messing with all these time series in general we want to build a trading system which means it has to make some deals buy sell stocks and hopefully grow your portfolio
there are a lot of good ready solutions to backtest your strategies like quantopian but i decided to learn how they re built from inside and bought the following book with details of implementation not a product placement ahahah
the strategy i ve tested is extremely simple if our network says that price will go up we buy the stock and sell it only after network says that price will go down and will wait for the next buying signal the logic looks like
here are the results of training classification network on data from to and testing from to the may of
blue plot shows portfolio value growth wow in years black shows activity and red one drawdowns periods of losing money
on the first glimpse results are bad horrible regression and not really amazing classification of accuracy are asking us to leave this idea and after seeing that incredible income it would be easier just to buy apple stocks and hold they grew in for that time you maybe want to close laptop and do something that doesn t involve finance or machine learning but there are lot of ways to improve our results and what people do in funds
forecasting of financial data is extremely complicated it s easy to overfit we don t know correct historical range to train on and it s difficult to get all data needed but as we can see it works and even can give some profits this article can be good starting point and pipeline for further research and discovery
in next posts i plan to show automated hyperparameter search process add more data full ohlcv and financial indicators apply reinforcement learning to learn the strategy and check if reinforcement agent will trust our predictions stay tuned
p s follow me also in facebook for ai articles that are too short for medium instagram for personal stuff and linkedin
developing ai for biosignal analysis and finance consulting giving public speeches and blogging contact me to collaborate rachnogstyle gmail com
in previous post we discussed several ways to forecast financial time series how to normalize data make prediction in the form of real value or binary variable and how to deal with overfitting on highly noisy data but what we skipped on purpose is that our csv file with prices basically has much more data that we may use in last post only close prices with some transformation were used but what can happen if we will consider also high low open prices and volume of every historical day this leads us to working with multidimensional e g multivariate time series where on every time stamp we have more than just one variable in our case we will work with whole ohlcv tuple
in this article we will see how to preprocess multivariate time series in particular what to do with every dimension how to define and train a neural network on this kind of data and will compare results with what we had in last post
as always you can jump directly to the code
to understand better what multidimensional time series is let s remember how look images that in fact also have not just two dimensions height and width but also depth that represents color channels
in case of time series our image is just d the plot we usually see on the graph and the role of channels play different values open high low close prices and volume of operations you can also think about it from other point of view on any time stamp our time series is represented not with a single value but with a vector open high low close prices and volume of every day but metaphor with images is more useful to understand why we will apply convolutional neural networks to this problem today
one of the most important moment about multivariate time series the dimensions can come from different sources can have different nature and can be totally uncorrelated and have different distribution so we have to normalize them independently we will use an ugly but more or less adequate trick from last post
but we are going to normalize every dimension of time window independently
but as we want to forecast movement of a price up or down next day we need to consider the change of a single dimension
so the data we will train on are time windows of like before days but now on every day we will consider whole ohlcv data correctly normalized to predict the direction of close price movement full code for data preparation and neural network training you can find here
as i mentioned before i would like to use cnn as a classifier mainly i choose it because of flexibility and interpretability of hyperparameters convolutional kernel downsampling size etc and performance similar to rnns better than mlp with much faster training
the code for our network for today looks like
the only difference from an architecture from a very first post is changing the emb size variable to in our case
let s compile the model
and check performance
from the plots we can clearly see that network trained adequately for very noisy data the loss of training set was decreasing with time while accuracy increasing and what s the most important comparing to univariate time series from previous post we improved the performance from to almost of accuracy
to check overfitting we can also plot confusion matrix
and we will get
which shows that we predict up movement with of accuracy and down with of accuracy and this results of course can be balanced for the test dataset
instead of predicting the binary variable we can predict the real value next day return or close price in our previous experiments we didn t succeed to produce good results
unfortunately for returns it still works bad
for prediction of value of close price the situation isn t better
i am still trying different things for regression problem in financial data like custom loss functions if you have some suggestions i d like to discuss them in comments or pm
we discussed the general pipeline of data preparation and normalization in case of multivariate time series trained a cnn on them and we can report significant improvement of classification problem predicting if stock price will go up or down next day don t forget to check the full code and run it on your machine
meanwhile we still can state that regression problem is still too complicated for us and we will work on it later choosing correct loss metrics and activation functions
in next post i would like to introduce the concept of multimodal learning and we will use parameters not just from our csv file with ohlcv tuples but much more interesting things
stay tuned
p s follow me also in facebook for ai articles that are too short for medium instagram for personal stuff and linkedin
developing ai for biosignal analysis and finance consulting giving public speeches and blogging contact me to collaborate rachnogstyle gmail com
i took deep learning course from andrew ng first as a beginner and just now completed part of fast ai course i want to list out few pros and cons of each course
coursera deep learning course
it is a specialization with courses dedicated to different field facets of deep learning
fast ai course part
fast ai course is a series of lectures given by jeremy howard a long time ai practitioner it is completely free and open course
to sum up coursera feels more like academic setting while fast ai feels more like industry practitioner setting if you are starting with deep learning you can start with either of those courses but each course will leave some gaps taking coursera course first and then fast ai course would likely be ideal
honestly you can go through each course at brisk pace and not worry too much about every minor detail you would likely have to go back to them anyway and actual learning will come from doing your own exercises
working on next generation search engine platform verticalset
i started taking the fast ai deeplearning and i want to document my path
in the videos jeremy recommends starting immediately by using paperspace com but in my case i have an ubuntu installation with a mobile nvidia processor so these are the steps that i took to get it to run
since i was using ensorflow gpu setup following these instructions https medium com codezillas step by step guide to install tensorflow gpu on ubuntu lts feceb df c
git clone git github com andresesfm fastai git
cd fastai
i also had conda installed so i didn t just want to run the provided script instead all i need was
conda env create f environment yml
ran into a bit of a hurdle
found gpu quadro m m which is of cuda capability pytorch no longer supports this gpu because it is too old
trying to solve folowing this
ok i followed the instructions to build pytorch from the source however it didn t work i tried both version and
ultimately what worked was this
install pytorch cuda c pytorch
suggested here
that finally returned torch cuda is available true
now the bad news
that s as fast as i can take it on my lenovo p
note i also attempted to run with cpu only and it was projecting to take hours
tech manager with big ai expectations
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
this tutorial focuses on using the keras reinforcement learning api for building reinforcement learning models to get an understanding of what reinforcement learning is please refer to these articles on datacamp
in this tutorial you will learn how to use keras reinforcement learning api to successfully play the openai gym game cartpole
to learn more about the gym toolkit visit
by the end of this tutorial you will know how to use gym environment keras reinforcement learning api
assuming that you have the packages keras numpy already installed let us get to installing the gym and keras rl package do this with pip as
import the following into your workspace
specifying the environment name to the make method of gym will load the environment to your workspace load the cart pole environment from gym with
to get an idea about the number of variables affecting the environment do
for the cart pole environment the input variables are position velocity angular position and angular velocity to get an idea about the number of possible actions in the environment do
for the cart pole environment the responses are left and right
let us now play games episodes and during each game we take random actions between left and right and see what rewards we get
we see that we lost the game very quickly in each of the games
we will use the sarsa agent and epsilon greedy q policy to train our reinforcement learning model to know more about the policies and the agents please refer to other datacamp reinforcement learning tutorials mentioned in the beginning of this tutorial
let us now define a simple keras model which will have input neurons to accept the state information and output neurons with linear activation which will return the maximum possible reward to the two possible actions between the input and the output layers we have dense layers with neurons and activation as relu
import the agent and the policy as
we define the sarsa agent by specifying the model policy and the nb actions paramaters where the model is the keras model we have defined the policy is epsgreedyqpolicy and nb actions is
compile the sarsa agent with mean squared error loss and adam optimizer
we then fit it by specifying the environment and the number of steps you want to train it for
with the training done we will test it for episodes and see what scores we get
save trained agent weights with
if needed one can load the saved weights with
to finish off the tutorial let us visualize the game as played by the trained agent setting visualize parameter to true is important to visualize the game
the code and the wights file for this tutorial can be found at
https github com anagar keras reinforcement learning api cart pole
this is part one of our building a deep learning machine series you can find the other posts here
deep learning is this amazing subfield of machine learning that has exploded in recent years many deep learning models have been arounds for over two decades but it wasn t until the last few years that they started becoming popularized
a deep learning model requires two things a ton of data s of megabytes if not gigabytes of data as a minimum and high computational power it was discovered around that graphics cards gpus can be used to supercharge deep learning standard computers have a few cores maybe a dozen on a higher end machine gpus have thousands of cores whereby computations can be parallelized increasing computing time by orders of magnitude
if you re serious about deep learning or building an ai startup it might be a good idea to build your own rig amazon charges you an arm and a leg and their hardware is obsolete in this post i m going to outline how to build a computer dedicated to deep learning while keeping the price tag below
the first thing we re going to need are some gpus we chose to get asus gtx s the new gtx titan xs were only recently announced and have an increased price tag we purchased the asus gtx founders edition if we could do it again we would not get the founders edition simply because of the increased cost each gpu cost around on average finding them proves to be difficult online marketplaces like amazon consistently run out we ended up purchasing from amazon from b amp h and from ebay
depending on your needs you can probably get away with the gtx s but we felt the s had the best bang for the buck
for the motherboard you re going to need to find one that has pci slots there aren t many motherboards with this option so it s slim pickings we settled for the gigabyte x p sli it cost
for ram we decided to get gb ballistix ddr and gb ballist ddr gb of total ram the motherboard supports up to sticks of ram so if you feel inclined to max it out the additional gb sticks were only purchased to save some money and get a little more memory
for the cpu we chose intel s k i a core processor virtual cores we originally made the mistake of purchasing the k i but found it was incompatible with our motherboard and then we tried the k but realized it only supports pci slots finally we bought the k i and we were off to the races
i would suggest using pc part picker to ensure everything is compatible before purchasing your hardware don t make the same mistakes we did it ended up costing us more and a few trips to fry s electronics
in order to power the rig you ll need a lot of watts amps we purchased the hercules w power supply while expensive the extra power ensures we can get all the performance out of the gpus the packaging also looks cool
for storage we purchased gb samsung evo solid state hard drives we decided on getting a few hard drives because we wanted to create virtual machines vm for each gpu and have the data allocated to each vm saving the th hard drive for the host if you re building a custom rig i would recommend just purchasing a tb ssd or possibly a tb if you have the cash
if you plan on putting your machine inside a server rack i would recommend purchasing the chenbro rm fs we originally used a different unit server chassis and realize that it didn t have expansions slots for each gpu in fact the chenbro is the only reasonably priced server chassis with expansion slots
if you have any questions about purchasing parts or building the machine feel free to tweet us acrosson calerogers
like and share if you find this helpful
curious about deep learning nlp ai hopeful traveler wannabe chef
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you noticed that facebook has developed an uncanny ability to recognize your friends in your photographs in the old days facebook used to make you to tag your friends in photos by clicking on them and typing in their name now as soon as you upload a photo facebook tags everyone for you like magic
this technology is called face recognition facebook s algorithms are able to recognize your friends faces after they have been tagged only a few times it s pretty amazing technology facebook can recognize faces with accuracy which is pretty much as good as humans can do
let s learn how modern face recognition works but just recognizing your friends would be too easy we can push this tech to the limit to solve a more challenging problem telling will ferrell famous actor apart from chad smith famous rock musician
so far in part and we ve used machine learning to solve isolated problems that have only one step estimating the price of a house generating new data based on existing data and telling if an image contains a certain object all of those problems can be solved by choosing one machine learning algorithm feeding in data and getting the result
but face recognition is really a series of several related problems
as a human your brain is wired to do all of this automatically and instantly in fact humans are too good at recognizing faces and end up seeing faces in everyday objects
computers are not capable of this kind of high level generalization at least not yet so we have to teach them how to do each step in this process separately
we need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step in other words we will chain together several machine learning algorithms
let s tackle this problem one step at a time for each step we ll learn about a different machine learning algorithm i m not going to explain every single algorithm completely to keep this from turning into a book but you ll learn the main ideas behind each one and you ll learn how you can build your own facial recognition system in python using openface and dlib
the first step in our pipeline is face detection obviously we need to locate the faces in a photograph before we can try to tell them apart
if you ve used any camera in the last years you ve probably seen face detection in action
face detection is a great feature for cameras when the camera can automatically pick out faces it can make sure that all the faces are in focus before it takes the picture but we ll use it for a different purpose finding the areas of the image we want to pass on to the next step in our pipeline
face detection went mainstream in the early s when paul viola and michael jones invented a way to detect faces that was fast enough to run on cheap cameras however much more reliable solutions exist now we re going to use a method invented in called histogram of oriented gradients or just hog for short
to find faces in an image we ll start by making our image black and white because we don t need color data to find faces
then we ll look at every single pixel in our image one at a time for every single pixel we want to look at the pixels that directly surrounding it
our goal is to figure out how dark the current pixel is compared to the pixels directly surrounding it then we want to draw an arrow showing in which direction the image is getting darker
if you repeat that process for every single pixel in the image you end up with every pixel being replaced by an arrow these arrows are called gradients and they show the flow from light to dark across the entire image
this might seem like a random thing to do but there s a really good reason for replacing the pixels with gradients if we analyze pixels directly really dark images and really light images of the same person will have totally different pixel values but by only considering the direction that brightness changes both really dark images and really bright images will end up with the same exact representation that makes the problem a lot easier to solve
but saving the gradient for every single pixel gives us way too much detail we end up missing the forest for the trees it would be better if we could just see the basic flow of lightness darkness at a higher level so we could see the basic pattern of the image
to do this we ll break up the image into small squares of x pixels each in each square we ll count up how many gradients point in each major direction how many point up point up right point right etc then we ll replace that square in the image with the arrow directions that were the strongest
the end result is we turn the original image into a very simple representation that captures the basic structure of a face in a simple way
to find faces in this hog image all we have to do is find the part of our image that looks the most similar to a known hog pattern that was extracted from a bunch of other training faces
using this technique we can now easily find faces in any image
if you want to try this step out yourself using python and dlib here s code showing how to generate and view hog representations of images
whew we isolated the faces in our image but now we have to deal with the problem that faces turned different directions look totally different to a computer
to account for this we will try to warp each picture so that the eyes and lips are always in the sample place in the image this will make it a lot easier for us to compare faces in the next steps
to do this we are going to use an algorithm called face landmark estimation there are lots of ways to do this but we are going to use the approach invented in by vahid kazemi and josephine sullivan
the basic idea is we will come up with specific points called landmarks that exist on every face the top of the chin the outside edge of each eye the inner edge of each eyebrow etc then we will train a machine learning algorithm to be able to find these specific points on any face
here s the result of locating the face landmarks on our test image
now that we know were the eyes and mouth are we ll simply rotate scale and shear the image so that the eyes and mouth are centered as best as possible we won t do any fancy d warps because that would introduce distortions into the image we are only going to use basic image transformations like rotation and scale that preserve parallel lines called affine transformations
now no matter how the face is turned we are able to center the eyes and mouth are in roughly the same position in the image this will make our next step a lot more accurate
if you want to try this step out yourself using python and dlib here s the code for finding face landmarks and here s the code for transforming the image using those landmarks
now we are to the meat of the problem actually telling faces apart this is where things get really interesting
the simplest approach to face recognition is to directly compare the unknown face we found in step with all the pictures we have of people that have already been tagged when we find a previously tagged face that looks very similar to our unknown face it must be the same person seems like a pretty good idea right
there s actually a huge problem with that approach a site like facebook with billions of users and a trillion photos can t possibly loop through every previous tagged face to compare it to every newly uploaded picture that would take way too long they need to be able to recognize faces in milliseconds not hours
what we need is a way to extract a few basic measurements from each face then we could measure our unknown face the same way and find the known face with the closest measurements for example we might measure the size of each ear the spacing between the eyes the length of the nose etc if you ve ever watched a bad crime show like csi you know what i am talking about
ok so which measurements should we collect from each face to build our known face database ear size nose length eye color something else
it turns out that the measurements that seem obvious to us humans like eye color don t really make sense to a computer looking at individual pixels in an image researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself deep learning does a better job than humans at figuring out which parts of a face are important to measure
the solution is to train a deep convolutional neural network just like we did in part but instead of training the network to recognize pictures objects like we did last time we are going to train it to generate measurements for each face
the training process works by looking at face images at a time
then the algorithm looks at the measurements it is currently generating for each of those three images it then tweaks the neural network slightly so that it makes sure the measurements it generates for and are slightly closer while making sure the measurements for and are slightly further apart
after repeating this step millions of times for millions of images of thousands of different people the neural network learns to reliably generate measurements for each person any ten different pictures of the same person should give roughly the same measurements
machine learning people call the measurements of each face an embedding the idea of reducing complicated raw data like a picture into a list of computer generated numbers comes up a lot in machine learning especially in language translation the exact approach for faces we are using was invented in by researchers at google but many similar approaches exist
this process of training a convolutional neural network to output face embeddings requires a lot of data and computer power even with an expensive nvidia telsa video card it takes about hours of continuous training to get good accuracy
but once the network has been trained it can generate measurements for any face even ones it has never seen before so this step only needs to be done once lucky for us the fine folks at openface already did this and they published several trained networks which we can directly use thanks brandon amos and team
so all we need to do ourselves is run our face images through their pre trained network to get the measurements for each face here s the measurements for our test image
so what parts of the face are these numbers measuring exactly it turns out that we have no idea it doesn t really matter to us all that we care is that the network generates nearly the same numbers when looking at two different pictures of the same person
if you want to try this step yourself openface provides a lua script that will generate embeddings all images in a folder and write them to a csv file you run it like this
this last step is actually the easiest step in the whole process all we have to do is find the person in our database of known people who has the closest measurements to our test image
you can do that by using any basic machine learning classification algorithm no fancy deep learning tricks are needed we ll use a simple linear svm classifier but lots of classification algorithms could work
all we need to do is train a classifier that can take in the measurements from a new test image and tells which known person is the closest match running this classifier takes milliseconds the result of the classifier is the name of the person
so let s try out our system first i trained a classifier with the embeddings of about pictures each of will ferrell chad smith and jimmy falon
then i ran the classifier on every frame of the famous youtube video of will ferrell and chad smith pretending to be each other on the jimmy fallon show
it works and look how well it works for faces in different poses even sideways faces
let s review the steps we followed
now that you know how this all works here s instructions from start to finish of how run this entire face recognition pipeline on your own computer
update you can still follow the steps below to use openface however i ve released a new python based face recognition library called face recognition that is much easier to install and use so i d recommend trying out face recognition first instead of continuing below
i even put together a pre configured virtual machine with face recognition opencv tensorflow and lots of other deep learning tools pre installed you can download and run it on your computer very easily give the virtual machine a shot if you don t want to install all these libraries yourself
original openface instructions
if you liked this article please consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
was a big year for artificial intelligence ai and machine learning ml and although some of it was pure hype a lot of what was achieved will be significant as the field continues to grow and have an impact in every industry below i summarize what i consider the main achievements or events of the year and briefly explain why they re important the list includes technical achievements as well as commercial ones because in the end the real impact of technological transformation happens when technology reaches the masses while some of them are preliminary in nature and most were not realized from scratch in they do plant important seeds for the future
i hope this list is helpful in identifying what was most important in there were many other advances of course but in thinking about the future how might each of these affect you your business and society in the future
svp of ai amp data science at dataminr ex head of r amp d digitalocean ex director at yahoo ex cto chief scientist machine learning computer vision
here we go let s make a prototype of a reinforcement learning rl agent that masters a trading skill
given that implemenation of the prototype runs on r language i encourage r users and programmers to get closer to the ideas expressed in this material
take a read of this paper https storage googleapis com deepmind media dqn dqnnaturepaper pdf
it will introduce you to the idea of using a deep q network dqn to approximate value functions that are crucial to solving a markov decision process
i also recommend a deep dive into rl math using this book preprint of richard s sutton and andrew g barto http incompleteideas net book bookdraft nov pdf
later on i will introduce an advanced version of the original dqn which incorporates more ideas to help it converge well and fast namely
deep double dueling noisy neural networks with prioritized sampling from an experience replay buffer
what does make this approach superior to the classic dqn
well what about trading made by a dqn agent it is an interesting topic per se
there are the reasons why it is interesting
to get things done fast get accounted with the code of this nn that i want to share since it is one of the puzzling parts on the whole thing
r code for a value neural network that uses keras backend to build our rl agent
i used this source to adapt the python code for a noisy part of the network https github com jakegrigsby keras rl
this neural network looks like this
recall that in dueling architecture we employ the equality eq
q a v where
a a avg a
q state action value
v state value
a advantage
other variables in the code are quite self explanatory besides this architecture is good for a given task only so don t take it for granted
the rest of code is thougth to be rather boilerplate to publish and it is a challenge for the programmer to write it on their own
we run our agent against a synthetic dataset our transaction cost equals
result is great the maximum average reward should be in this setting
we see critic loss average reward per episode cumulative reward sample of last rewards
we train our agent on an arbitrarily chosen stock symbol that showed interesting behaviour flatty beginning rapid growth in the middle and a dreary ending there are about days in our training set transaction cost set to purposefully low each reward is a usd profit loss after buying selling share
source https finance yahoo com quote algn ltr
after tweaking of some parameters leaving the nn architecture the same we came to this result
it is not bad since after all the agent learned how to make profit pushing the three buttons on his console
note that at its apex the average reward per episode has beaten the realistic transaction cost that one may face in real trading
it is too bad that stocks crash like crazy on bad news
trading with the help of rl is not only challenging but also rewarding when your robot makes it better than you do it is time to spend personal time to get educated and healthy
i hope that was an interesting trip to you if you enjoyed this story show it to me if much interest exists i can continue and show you how policy gradient methods work using r language and keras api
i also want to thank my friends passionate about neural networks for advices
what was once science fiction or wishful thinking today is truism year olds have in their tiny palms handhelds as powerful as the supercomputers of yesteryears the ones that propelled us into space or the ones that brought down hiroshima and nagasaki so the title shouldn t surprise as much as wake us up this one isn t a plot from a movie rather ideas that may shape what lies ahead and for good we manipulate in relationships we manipulate our dog and yes our dog manipulates us for love rather our dog manipulates us way better than our spouses ever will
in today s tech age we do not write programs anymore but algorithms that not just program but have the ability to process compute and learn from an incident and accommodate for every such incident and the constraint that came along the way that is what we call machine learning
like the brain which is trained to complete a task with the minimum effort required the algorithms too are but an extension of our neurons and they do as asked or as programmed of them the key focus of any algorithm therefore is to optimize and not ponder upon what ifs i am okay with that and that in itself renders machines the efficiency and speed we are so dazzled by they follow a checklist to learn they can not and will not seek the so whats and now whats
i am not a naysayer or a pessimist and i am not taking this article onto that beaten path i am rather largely asking some pertinent questions every ai ml and deep learning enthusiast programmer or visionary needs to ponder as we continue to make some giant strides in the space these may well be some of the existential questions that may shape up the next generation of algorithms and bring a more heuristic perspective to the field
i leave everyone with two cases that we all may relate to and pit them against what a typical ml algorithm does in these scenarios i would also offer some hacks which as citizens of this era we may use to nullify the mindnumbing algorithmization of our lives but as programmers and developers of this industry there isn t escaping this through hacks we will have to take the challenges head on and better empower our ai universe
case the confirmation bias at play
i am a liberal american or an immigrant in the us or pro lgbt rights i am also just beginning to understand american politics i go to facebook and like a couple of pages around these topics i am thrown in some videos around these issues by the facebook autoplay algorithm and i end up watching these short informative videos by the end of my browsing session while i have no idea of what republican stands are i have already ended up hating all republicans alike not just trump alone alternate scenario is that i am conservative fiscally liberal in a few social aspects conservative in some other with a belief in god i end up again on the same train of thoughts videos and end up hating the lgbtq community for they are aparently against the will of jesus obama and obamacare for its an anti capitalistic welfare scheme
months down the line i have a religion of my own i am not a christian anymore or catholic or a hindu or muslim rather i am a liberal or conservative or an immigrant and every alternate view is a sin there are many like me who i haven t met but they stand by me and my stands and some crazy bigots who abuse me as much on every social forum good i don t have to meet them in real i am attached more to stands i take or decided to take than real causes that is billions of marketing dollars working its way to behavioural analytics nudging me to be who i really am every marginal inkling i had is now part of my belief system
case the confirmation conundrum at play
i am an average built human with average features my instagram flipboard and browser feeds keep flowing in beautiful celebrity pics that either make me feel i am thin or fat or worse too thin or too fat i just have an inkling at this stage that somethings amiss that i must redress i ask around and i am told all s well and i get on with life but say i didn t ask around for i am a person of science and instead tried googling my way to a definitive answer to this million dollar question
am i fat are the three magical words i search for google very generously shares some of its biggest hits on body mass index bmi parity restores momentarily but there are some catchy hyperlinks around how to stay fit and lead a healthy life and shed that extra pound couple of articles and few days later my youtube has videos around weight loss there is an amazon ad that plays in between letting me know that there is a sale on all kinds of weight loss and gain products one more click and i am led to believe there is something definitely wrong with me and i tussle with this idea for more days than i would have wanted to gladly oprah s weight watchers and its consumer insights algorithms have made it possible for some very handy products that are custom tailored for me what it does to my self confidence is anyone s guess
there can be numerous such examples that affect our ability to think straight or our ability to think itself that leads me to ask if ml algorithms as of today learn from us or mere feed on our vulnerabilities insecurities beliefs and biases and end up fortifying them
there are simple hacks of not searching for our inklings outside the incognito mode using browsers devices and search engines from different universes apple google microsoft amazon or following diverse pages with alternate perspectives on social media to restore some sanity and diverse line of thoughts remember in a fox universe america is great again in cnbc s and cnn s america always was but now isn t wish things were as binary
the ones who are currently designing the algorithms that power the deep learning and ml universe hacks are no good we have to think through the algorithms we set out to learn from us for me every ml algorithm is a baby needing to be raised and it needs care caution and a higher sense of purpose it s as living as we are
artificialintelligence ai machinelearning ml aiml deeplearning customization hyper personalization behavioral analytics
left leaning liberal
sometimes it is even hard for humans to understand if a news article is real fake or satire so i asked my self if i can train a machine learning model to decide to which class real or satire an given article belongs there are websites like https www theonion com publishing satire news every day which can be used together with regular news sites to collect trainings data for this classification problem
i grabbed large datasets of news articles in german language from news agencies and newspapers via their websites
and from the satirical news sites
for training and testing of the model in total i collected articles from to and stored them in a local database
to train a classifier i used the scikitlearn package with a linear support vector classifier svc the news texts were vectorized with a count vectorizer and tf idf weighting see the code below
of the data was used for the training of the classifier and for testing on the test set i achieved an accuracy of a precision of a recall of and a f score of in the confusion matrix below you can see the distribution of the correct and wrong classifications only of the real news are classified as satire but of the satirical texts are not detected as satire quite good results
i think the presented method can be used with other languages and i expect similar results as with the german news
are computers better than humans in detecting satire in texts
more details can be found in the article https arxiv org abs
university of applied sciences upper austria school of informatics communications and media http www stoeckl ai profil
dear friends
i am excited to announce the newest course from deeplearning ai ai for everyone it will be available on coursera in early
ai is not only for engineers this non technical course will help you understand technologies like machine learning and deep learning and spot opportunities to apply ai to problems in your own organization you will see examples of what today s ai can and cannot do finally you will understand how ai is impacting society and how to navigate through this technological change
this course is intended for everyone ranging from ceos product managers marketers salespeople designers to financiers if you are a non technical business leader ai for everyone will help you understand how to build a sustainable ai strategy if you are a machine learning engineer or data scientist this is the course to ask your manager vp or ceo to take if you want them to understand what you can and cannot do
artificial intelligence will transform every industry just as electricity did years ago between now and ai will create an estimated trillion of gdp growth
through my work with landing ai i meet regularly with ceos who want to transform their companies with machine learning the number one question they ask is how to align their long term business strategy with today s ai capabilities
the ai powered future must be built by both engineers and application domain experts we will need millions of ai engineers we will also need millions of experts from every industry to understand how to apply ai within their organizations
since the deep learning specialization launched hundreds of thousands of you have enrolled in a course and begun furthering your career in deep learning
we will continue to work to bring the deeplearning ai community additional courses resources and events let us know what you d like to see next in the deeplearning ai forums or visit our careers page and apply to join us and make world class ai education accessible to everyone
you can pre enroll for ai for everyone and be one of the first to take the course when it becomes available on coursera
i look forward to hearing from you and am excited to continue expanding the ai community together
andrew ng
ai machine learning deep learning online education
dear friends
i am excited to announce the newest course from deeplearning ai ai for everyone it will be available on coursera in early
ai is not only for engineers this non technical course will help you understand technologies like machine learning and deep learning and spot opportunities to apply ai to problems in your own organization you will see examples of what today s ai can and cannot do finally you will understand how ai is impacting society and how to navigate through this technological change
this course is intended for everyone ranging from ceos product managers marketers salespeople designers to financiers if you are a non technical business leader ai for everyone will help you understand how to build a sustainable ai strategy if you are a machine learning engineer or data scientist this is the course to ask your manager vp or ceo to take if you want them to understand what you can and cannot do
artificial intelligence will transform every industry just as electricity did years ago between now and ai will create an estimated trillion of gdp growth
through my work with landing ai i meet regularly with ceos who want to transform their companies with machine learning the number one question they ask is how to align their long term business strategy with today s ai capabilities
the ai powered future must be built by both engineers and application domain experts we will need millions of ai engineers we will also need millions of experts from every industry to understand how to apply ai within their organizations
since the deep learning specialization launched hundreds of thousands of you have enrolled in a course and begun furthering your career in deep learning
we will continue to work to bring the deeplearning ai community additional courses resources and events let us know what you d like to see next in the deeplearning ai forums or visit our careers page and apply to join us and make world class ai education accessible to everyone
you can pre enroll for ai for everyone and be one of the first to take the course when it becomes available on coursera
i look forward to hearing from you and am excited to continue expanding the ai community together
andrew ng
ai machine learning deep learning online education
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
maybe it s out there somewhere
you can always find insightful stories on our homepage
enjoy these stories about getting lost losing things and finding what you never knew you were looking for
let s get started
the most common problem we face while starting with data science or machine learning is from where to start even i got stuck with the same question but with time i learned about it its algorithm and about how it works but it was very slow that s the point i was very slow i spent a lot of time understanding it and then was pushed back since my basics were not clear so here i m with a tutorial that can lead you to from a beginner to a pro in machine learning i will be updating you guys with a blog and a tutorial on github every week
things we will be covering in the tutorial series
the codes of all these will be available at github
business applications machine learning can be used in business analysis work as well in spam email detection stock prediction natural language processing has proved to be very efficient in the field of machine learning
there is endless use of machine learning it s heavily upon the coder how he she implements it before we get started with machine learning it is also important to know the basics of python so i just made a tutorial which is enough to get you guys started with data science
python basics
there are certain simple things which we should remember before starting with python
let us see a hello world program in python
step open your terminal and type python in case you don t have python follow this link to install it on your system windows linux mac
step if you have python installed in your system then type python on your terminal and press enter
wait but we haven t included any header file so are we wrong
well no as discussed earlier there is no need to include any header files initially isn t that simple
this just notebook gives a brief explanation of python basics
link to the code python basics
pandas
pandas is one of the most efficient libraries for data science in python it makes handling of dataset very easy for the developer the problem developers face without pandas is that it requires manually handling each and every part of the dataset like columns rows its size etc but pandas has proved to be one of the most efficient libraries in the field of data science it automates the loading of data into memory very quickly basically used for data manipulation and analysis a quick overview of pandas is shown in below notebook to know about jupyter have a look on the below notebook
numpy
numpy is a library adding support for large multi dimensional arrays and matrices along with a large collection of high level mathematical functions to operate on these arrays
so this was all about chapter of go ml tutorial link to the codes link
thanks for your time we hope that you liked our first part of go ml tutorials follow me on github for further updates on this course
linkedin
data scientist and researcher
in the previous blog we discussed python basics pandas basics numpy basics if you haven t been through the tutorials please have a look at it
link of the tutorials chapter
so let s get started with our second course getting started with machine learning with python in this course we will be discussing the following
machine learning is sub divided into the following types of learning
now let s have a quick introduction of the above types of learning
supervised learning as the name indicates the presence of a supervisor as a teacher basically supervised learning is learning in which we teach or train the machine using data which is well labelled that means some data is already tagged with the correct answer after that the machine is provided with a new set of examples data so that supervised learning algorithm analyses the training data set of training examples and produces a correct outcome from labelled data
unsupervised learning is a class of machine learning techniques to find the patterns in data the data given to the unsupervised algorithm are not labelled which means only the input variables x are given with no corresponding output variables eg clustering lda
as you may have guessed semi supervised learning algorithms are trained on a combination of labelled and unlabeled data this is useful for a few reasons first the process of labelling massive amounts of data for supervised learning is often prohibitively time consuming and expensive
what s more too much labelling can impose human biases on the model that means including lots of unlabeled data during the training process actually tends to improve the accuracy of the final model while reducing the time and cost spent building it
a reinforcement learning algorithm or agent learns by interacting with its environment the agent receives rewards by performing correctly and penalties for performing incorrectly the agent learns without intervention from a human by maximizing its reward and minimizing its penalty
we will be focusing on the knn algorithm that is widely used in classification problems
let s make this algorithm simpler by breaking it down into pieces
knn algorithm is very simple its just the euclidean distance formula
simple right
so let s see how can this algorithm be used for classification we will be considering the iris dataset for this let s have a look at how the iris dataset looks like
to classify the species of the iris flower namely setosa versicolor virginica
first let s get the euclidean distance into code
initially we set the default of distance equal to then we are running the loop from to the length of the total size of the dataset in our case we have test dataset of length so the length becomes equal to and the loops execute times
this is how the knn algorithm works
as we see in the above image there are two classes namely a and b suppose we introduce test data and our ultimate goal is to predict its final label i e a or b so we calculate the euclidean distance of the test data with the other dataset suppose this is how our test and train dataset looks like
now we calculate euclidean distance between the test and train dataset this is how the process goes
and as we see that the euclidean distance for virginica is less so our nearest neighbour is virginica this is how knn algorithm works
the above was only for two sets of data think of a bigger dataset like iris dataset that has about rows so we calculate the distance from each row and then we sort the value in ascending order code for sorting in python
the code as well as the working example is available in the below notebook as well as you can find the whole tutorial in my github
show your love my clapping if you like it follow my machine learning corses in github
data scientist and researcher
the idea of using artificial intelligence ai to accelerate drug discovery process and boost a success rate of pharmaceutical research programs has inspired a surge of activity in this area over the last several years in things are getting even hotter with the increase in the amount of partnerships investments and other important events summarized and grouped below into mini trends
this year has been marked by an impressive number of fundraising deals among ai driven drug discovery startups a clear indication of the ai for drug discovery space gaining some serious attractiveness for venture capitalists
so far a london based benevolentai appears to be a leader of the year in terms of fundraising in april they closed a m round reaching a staggering billion valuation mark while met with certain degree of skepticism this news and the current pace of research activity by the company undoubtedly puts benevolentai in a very strong position among competitors
atomwise which was founded in and pioneered the use of deep neural networks for structure based drug design raised m round a investment to advance its ai driven drug discovery technology atomnet the company says it screens million small molecules each day and uses atomnet which is utilizing deep learning algorithms to analyze molecules and predict their potency as medications toxicity and side effects
a quite unique company on the list a us based insilico medicine which is the only one startup among its closest competitors which develops a full stack artificial intelligence system based on generative adversarial networks gans allowing for an end to end drug discovery process from basic biological modeling and biomarker development to hit molecule generation lead optimization and pre clinical validation of drug candidates in june insilico medicine received an undisclosed amount of strategic investment from wuxi apptec bringing totally raised capital up to m according to crunchbase
notably just a month later wuxi apptec participated in a m investment round for another ai driven startup verge genomics the latter uses machine learning and ai to develop therapeutics against alzheimer s and parkinson s disease verge is also actively growing its database of patient genomic data allegedly the company possesses one of the industry s largest resources in this therapeutic area
new york paris based owkin founded in to apply machine learning for optimizing drug discovery process via better comprehending the overabundant biological data raised its round a of m in january to scale its technology platform owkin socrates the platform can integrate molecular and imaging libraries with patient data to reveal patterns of biomarkers causing a disease and the company is applying transfer learning to improve model performance where properly labeled data is scarce
founded in by a group of quantum physicists at mit xtalpi is a u s china biotech firm which has raised a series b round of m in january from several investors including google and sequoia china among the others the company is claiming that it can quickly and accurately predict numerous important characteristics of small molecule drugs and solid forms by combining artificial intelligence quantum physics and high performance cloud computing using this sophisticated interplay of technologies the company will be able to provide time saving insights into the safety stability and efficacy of drug candidates
later this year google also co invested in benchsci a smart platform for ai powered search for biological products the round totalled million from several investors
engine biosciences is a san francisco and singapore based biotech firm which announced a m funding round to advance its ai based platform for drug discovery development of combination therapeutics and cellular reprogramming the company s technology allows researchers and drug developers to reveal gene interactions and biological networks and provide test therapies specifically targeting genetic interactions the company s ai platform can assist in target discovery drug repurposing and analysis for precision medicine applications
other notable investments in include twoxar m revivemed m gtn m etc
to review an aggregate statistics for the ai in drug discovery industry read a landscape of artificial intelligence ai in pharmaceutical r amp d report
in pharmaceutical companies show continuous interest in partnering with emerging ai driven startups to leverage the power of algorithms for boosting own drug discovery programs below is a list of some of the notable drug design collaborations of this kind
the last month of this fruitful year was marked by a new research collaboration between german pharmaceutical giant merck and a canadian ai driven company cyclica the parties agreed that merck will use cyclica s proprietary ai driven cloud based in silico proteome screening platform ligand express to clarify mechanisms of action for a number of merck s small molecule candidates evaluate their safety profiles and uncover additional therapeutic applications
in november bayer established a multi phase research collaboration with toronto based drug discovery company cyclica to utilize its multifaceted ai driven discovery platform for a broad range of research tasks in the framework of this collaboration cyclica will provide its cloud based proteome screening platform ligand express to study the off target profiles of small molecules and apply its first in class differential drug design ddd technology for multi targeted drug design furthermore it will apply its ai technology to build state of the art predictive models for pharmacokinetic properties
in september pfizer entered into an evaluation agreement with atomwise now the ai developing startup will need to identify promising drug candidates for up to three proteins of choice by pfizer
just a couple of months earlier pfizer partnered with another ai driven startup xtalpi to develop a drug discovery software platform which would utilize xtalpi s expertise in computational physics and artificial intelligence the platform is to be applied for accurate molecular modeling of drug like small molecules
bristol myers squibb entered a multi target research collaboration agreement with sirenas a biotech company applying machine learning based computational approaches to discover therapeutics derived from the global microbiome to apply its proprietary drug discovery platform against a series of undisclosed but challenging therapeutic targets the research collaboration leverages sirenas expertise in applying its proprietary data mining technology atlantis to identify potential drug candidates among sirenas proprietary chemical library isolated from global microbiome collections it is important to note another area of sirenas expertise state of the art organic synthesis which makes it possible for the company to deliver not only computational predictions but also chemical compounds with unusual nature inspired scaffolds
in may boehringer ingelheim partnered with bactevo to apply their totally integrated medicines engine for identifying novel small molecule drug candidates
in may glaxosmithkline gsk has formed a drug design collaboration with cloud pharmaceuticals an ai drive drug discovery company to develop a series of small molecules against biological targets specified by gsk
read how big pharma adopts ai to boost drug discovery to find out about more collaborations of this kind and typical use cases for ai application in drug discovery
on the one hand pharmaceutical companies are increasingly hiring ai startups to explore opportunities but on the other hand they are equally active in growing internal ai expertise and shaping digital infrastructures for more efficient data usage
recently novartis announced the completion of the first phase of a company s digital transformation strategy focusing on big data digital infrastructure and artificial intelligence the first phase was internal program called stride and it included the launch of several important it infrastructure systems for document management internal investigation high performance computing clinical trial management and other tasks
the next phase of novartis s digital transformation is to implement a predictive analytics platform driven by machine learning algorithms to support clinical trial operations this will be done in the framework of nerve live initiative and in collaboration with us machine learning company quantumblack
finally there are plans for the third big future project data the one bringing all of novartis data sets together to be able to query any data in a centralized mannar this is certainly a major prerequisite for the ai driven transformation in the company
similarly pretty much every global drug maker pfizer astrazeneca eli lilly merck gsk and others are taking internal restructuring measures to get prepared for the digital transformation of pharmaceutical research and adoption of artificial intelligence for drug discovery and development
it is becoming obvious that the key enablement factor of the future ai driven revolution in pharmaceutical research is data without the access to diverse interdisciplinary quality and properly curated big data a transformative impact of ai technology can not be fully realized in this context it is important to see how companies are moving in the direction of data centric research paradigm
in july gsk has invested million in andme a silicon valley gene testing company backed by google this deal opens a door for gsk to access a vast dna database providing information about the relations between genes and diseases andme has more than million customers the majority of whom opted in to allow their data being included in research programs
datavant a young us based ai driven startup is focused on organizing and structuring healthcare data for deriving actionable insights for the design and interpretation of clinical trials in the beginning of january it announced a strategic alliance with verge genomics a company using artificial intelligence to discover and develop new therapeutics the newly formed partnership aims at unlocking the value of pharmaceutical datasets in a possession of datavant clinical trial data claims pharmacy history electronic health records and genomics data on patients to accelerate discovery and development of new medications
so far datavant has two more partnerships besides verge with duke clinical research institute dcri global genomics group g all aiming at combining drug discovery expertise biological big data and novel data analytical technologies such as ai to boost innovation in the field of pharmaceutical research
in the light of the above trends focus on ai and big data a logical consequence is the pharmaceutical research industry moving towards platform based models of cooperation and doing research platforms are digital infrastructures connecting the dots between different types of activities research areas operation modes and data flows platforms or super platforms are widespread in finance consumer e commerce and other industries but this is still a new phenomenon for the pharmaceutical research several events in are quite illustrative here
it was announced that merck and accenture are working with amazon web services to create a cloud based platform that would embrace collaborators across various sectors of the life sciences industry this analytics platform will be built using open application programming interfaces apis and will facilitate a collaborative environment to accelerate early drug discovery efforts it will not only make it easier for researchers to aggregate access and analyze interdisciplinary data but will also lower barriers to market entry for novel value providers app developers data scientists content and data suppliers etc
in march wuxi nextcode announced a partnership with google to integrate its massively scalable genomics database management system and research apps in google cloud platform in turn such tools as google cloud bigquery and deepvariant will be integrated with wuxi nextcode s capabilities the two companies will also work on additional tools and apis to empower the global genomics community
read also get ready for super platforms in healthcare and pharmaceutical research
one of the important elements of a mature industrial ecosystem the presence of specialized consortia and associations whose goal is to facilitate interaction between members of the community set industry standards and reveal best practises educate general public about the topic and lobby important changes to government regulations
the pharmaceutical research industry is in its early days of a widespread adoption of artificial intelligence for drug discovery so the emerging ecosystem of ai practitioners in this space is only beginning to grow however a number of important steps towards the creation of industrial alliances has already been made recently
in may mit has formed a powerful industry academia consortium the machine learning for pharmaceutical discovery and synthesis mlpds which already includes some of the leading players in the pharmaceutical field amgen basf bayer eli lilly novartis pfizer sunovion and wuxi being headquartered in cambridge ma one of the global centers for biopharmaceutical innovation the newly formed consortium allows for close cooperation between partners a lot of them have presence in cambridge and the creation of a center for artificial intelligence ai use in pharmaceutical research
another important consortium the accelerating therapeutics for opportunities in medicine atom has been formed at the end of the last year by its founding partners gsk lawrence livermore national laboratory frederick national laboratory for cancer research and the university of california san francisco with funding support under the st century cures act while the atom s mission includes a broad range of activities to facilitate efficient drug discovery in the field of oncology some of the central tasks are focused on advancing artificial intelligence adoption by pharma players and democratising access to research big data in april numerate one of the leading ai developers from drug discovery expressed its intentions to join the consortium
finally september was marked by an important milestone the announcement of mission and launch activities of a global alliance for artificial intelligence in healthcare aaih which is to become a leading international organization for advancing artificial intelligence innovations in drug discovery clinical research diagnostics precision medicine and other key areas of pharmaceutical research and healthcare
having a standardized set of metrics and datasets for assessing and comparing a wide variety of available and novel machine learning models is essential for creating and maintaining industry s best practises
a recent move in this direction has been made by a group of scientists from ai driven drug discovery company insilico medicine in collaboration with a distributed synthetic data platform for deep learning neuromation and al n aspuru guzik s research group at the university of toronto who launched an open research platform moses molecular sets described in the paper molecular sets moses a benchmarking platform for molecular generation models the source code and datasets for the platform are all available at github
the platform is supposed to play a similar role in boosting ai driven drug discovery as imagenet played in advancing deep learning for imaging data moses is open for researchers and organizations to contribute their datasets and models to extend the benchmarking platform
the above post summarizes very briefly some of the aspects of how artificial intelligence technologies and big data are starting to play the central role in the pharmaceutical research to get a more comprehensive view on the subject please subscribe to biopharmatrend newsletter to get fresh market analytics insights directly to your inbox we will rarely bother you more than once per month
editor biopharmatrend com
my dad once told me a computer is a dumb machine it does exactly what it is told to do and nothing more he was right a computer merely executes a set of instructions coded by a programmer so how can a computer be intelligent or learn while the basic mathematical concepts behind machine learning ml are pretty simple most posts out there are jargon heavy and scare non experts away i decided to write this post as an introduction for people who don t have a math background but would like to get a sense of what is actually happening under the hood in ml
all the problems that ml solves are the same in nature we are looking to build a machine that converts something let s call it input into something else let s call it output for example we want a machine that takes as an input a picture and as an output it tells us if it s a cat or not or it can be a machine that takes some music as an input and as an output it tells us the name of the singer another example would be a machine that takes a human as an input and tells us his or her gender as output you get the point the input and output can be literally anything as long as they are related
the very cool thing about computers is that music text video or really anything is actually represented in numbers for example a picture is nothing more than a bunch of numbers each representing a color and a position on the screen
we humans can hand pick and measure the key features of any object and have a simplified representation of the object as numbers for example we can represent a human by his her height and weight if we think that s what the machine needs to make the prediction in the jargon converting complex objects into numbers is called feature selection
as far as computers are concerned the machine we are looking for takes a number or a set of numbers as an input and gives a number as an output this type of machines that deal with numbers are called mathematical functions we typically represent them with the letter f
a quiz
now that we have narrowed down the problem to numbers let s do a quick exercise if you look at the chart below and assume that you know the outputs on the left side can you predict what the output for is
yes the answer is and congratulations the process that your brain just went through is exactly what machine learning is all about here is probably how you handled the exercise
step get some data a bunch of inputs for which we know the corresponding output note i did this step for you
step assume the function has a familiar form note in the quiz you probably assumed that there is some basic multiplication or addition involved
step look at the data and search for a function that seems to work note in the quiz the function you found was output input a k a f x x
step test the function on the rest of the data to see if it really works on all inputs in the data
step apply the function to the new input in order to predict output note f
let s pause here and define some jargon the data you got at step is called the training data step amp are called model training model training is basically the part where you re searching for a general function that seems to replicate the training data this is the part that can get automated the automated process to search and find the right function is called a machine learning algorithm
before we go any further i just would like to introduce two types of problems we solve with machine learning classification and regression
classification is when the output can only take a finite number of possibilities say for example we are trying to predict if an email is spam or not spam or if a picture contains a cat or not or if a person is male or female
regression is when the output can take a continuous set of values say for example we want to predict how much a customer is going to spend based on their demographics age earnings etc the output can be or or or or etc
computers are not creative they do exactly what they re told there is however one thing in which computers are superior to humans they calculate very fast they therefore can relatively quickly search for and find a function that works as long as we tell them where to search and give them a step by step process of how to search the following paragraphs explain a few approaches of how we can teach a computer to search for a function
before we get into this approach let me just point out that a popular way of teaching ml involves functions that take numbers as an input that s because in the real world we need to solve problems where we are predicting outputs based on more than just a single input we typically choose to use numbers as input because it s easier to visualize graphically with two axis representing the two inputs
say for example we are looking to use ml to build a tool that predicts a person s gender based on his her height and weight because the output can only take possible values male or female this is a classification problem
from a graphical perspective the training data can be represented this way
the pink and blue points are our training data the color is the known output gender since the pinks seem to be close to each other and the blues seems to be close to each other let s just draw a straight line everything that falls on one side of the line would be pink and everything that falls on the other side would be blue
as you can see in the chart there is more than line that does the job and they re not all as good if you look at the two lines shown above line passes awfully close to a pink data point while line leaves more room for separation
a popular algorithm to draw a good separating line is called support vector machines svm svm basically looks for the straight line that maximizes the distance between the line and the closest training data points so that we draw a thick separating line svm is useful because it turns out maximizing things is something we have off the shelf algorithms for computers to do see below even though it may sound conceptually very simple to just draw a line svm is pretty widely used for example these medical researchers used it to do classify cancers using genetic data
let s go back to our quiz here is a pretty simple ml algorithm that we could have used to solve it to find the output corresponding to we look at the training data find the closest number to in this case that s and assume that the output for is just the same as the output for its nearest neighbor this means f f sounds pretty dumb right yes it is but it kind of works is kind of close to to get a little more sophisticated we could take the average of the closest inputs to in this case that s and that would mean f average in fact this can be generalized to take the k nearest neighbors this algorithm is called the k nearest neighbors a k a k nn
the fundamental assumption behind k nn is that inputs that are close to each other are likely to have the same output this algorithm works well for functions for which the outputs can only take a few possible distinct values here is a real life example in which medical researchers used k nn to classify and diagnose different types of cancer
yes linear regression is technically machine learning it s not really used in complex machine learning but the concepts apply to most regression algorithms so i think it is useful to understand how it works
in linear regression we assume that for any input x the output is in the form of f x a x b where a and b are some numbers that we don t know yet note that we here assume before we actually do any math or anything that our function has to look that way we then search for the best a and b i e the ones that replicate the training data or at least get as close as possible
side note with some jargon when we assumed that the function has to look a certain way we introduced new variables that we called a and b in ml these variables a and b are called parameters a lot of time in ml is spent searching for the best parameters some models have millions of parameters
in order to find the best a b for each pair a b we define the error a b which basically measures how bad the function is doing in replicating the training data mathematically error a b is the difference between what the function should have predicted according to the training data and what it actually predicts according to the formula
we have just transformed our ml problem from let s find a function into let s find parameters that minimize the error as it turns out we have off the shelf algorithms that teach computers to find minimums or maximums this is the second time we came across this problem so let s dig into it a little bit
assume you are visiting a coastal city say seattle you are walking in the street check the news on your phone and hear that there is a massive tsunami coming your way you re alone have no idea what the landscape looks like but you want to get as high from the sea level as possible to protect yourself what do you do ps google maps is not working you can t get inside or climb any building and you re surrounded by tall buildings so you can t see much apart from your immediate surroundings
the best you can do is to follow the slope just walk uphill and at every crossing check the slope again if turning right or left gets you higher do that if not keep going this approach to find a maximum or a minimum is called the gradient descent so to minimize our error or maximize the thickness of the separating line and solve our above problems the computer would pick some random starting point and start walking downhill or uphill from there
i know what you re thinking this approach is kind of dumb obviously at some point you may get stuck at the top of a hill any direction you take will be going down this means you may miss out on a potential mountain nearby this problem is called the local optimum problem to solve this some algorithms introduce randomness in order to escape any local hill these are called probabilistic algorithms or randomized algorithms
if when you hear neural networks you think of some magical thing that replicates a human brain with freewill and all sorry to disappoint you it s much simpler than that neural networks are just a regression algorithm just like in linear regression the neural network algorithm assumes that the function has to look a certain way and searches for the best parameters
in neural networks the basic idea is that the function we are looking for is assumed to be a weighted average of step functions a step function is a function that has an output of when the input is below a certain threshold and an output of above that threshold so the algorithm has type of parameters to look for the weights and the tresholds why does the algorithm assume the function has to look this way because it is mathematically proven that if we pick the right number of step functions with the right tresholds and the right weights for each we can approximate any function whatever its shape is
a problem we face with step functions is that when the input is very close to the threshold the output can change radically from to if the input is changed just a little bit and this is not a natural phenomenon in real life there is a certain smoothness in the world a picture of a cat is not going to turn into something else if we change the color of pixel a little bit to solve this problem instead of using step functions we use activation functions which are similar but transition smoothly from to
what i have just described above is a layer neural network a multi layer neural network is a succession of layer neural networks the output of layer n is the input of layer n the output of the last layer is the actual output we are looking for
supervised vs unsupervised learning
everything we have talked about here so far falls under the supervised learning category unsupervised learning is when your training data has no outputs just bunch of inputs for example while in supervised learning your training data would be a bunch of pictures labeled cat and not cat in unsupervised learning your training data would be just a bunch of pictures the algorithm would by itself find that there are two categories of pictures and come up with a function that classifies the inputs so that those that are similar have the same output
conclusion
the idea behind this post is to give a high level understanding of what machine learning is about from a conceptual point of view without getting into the weeds of the mathematical and computational algorithms i hope this post will be useful to people who are curious about the topic
i sometimes write about stuff
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
computers can t think they are not human computers can t think by themselves without help computers don t have a brain and therefore can t think merely follow instructions from someone who can if computers could think they would be able to program themselves and learn some may argue that computers can learn people s tendencies and patterns but this is only because they are using an algorithm programmed into them by humans with no algorithm they would just be guessing and not have logical thoughts like a human logical thought can only come from a conscious person not a computer this shows us that what happens in the movies can t happen robots can t take over the world until they have a more advanced computer in them that can think now others may argue that computers can think because they can talk to humans like siri but in actuality siri can t think it can only interpret what people say then say a pre programmed sentence to answer this could be substantial because some people may believe that siri is like a real assistant and can answer any question when actually it can t even though it seems that siri is thinking when you ask it about the weather really it s just finding the answer online and speaking it computers can t process complex information by themselves or program themselves so until that happens computers can t think
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
last updated dec
latest video update
okay on to the post
i kicked off this year with udacity s deep learning nanodegree and got a fantastic comprehensive introduction to deep learning while i was taking the class i discovered daniel bourke s self created ai masters degree which details the courses he s taking on his path to becoming a deep learning developer one of which was the deep learning nanodegree i thought the idea to share his journey was brilliant it holds him accountable and provides inspiration for others
rather than take the same path as him i ve decided to create my own course that pairs my long standing interest in game development and d modeling with my newly found interest in artificial intelligence if this branch of ai interests you too i hope my path can inspire you to create your own self driven education
this post will be a work in progress toward understanding how d tools like unity unreal engine and blender can be used to train deep neural networks i came into this course with a unique combo of skills so i ll offer some suggestions for anyone who wants to follow along but doesn t have the same foundation
if as kai fu lee says data is the most important thing we need a lot of it currently most image and video datasets are annotated by hand this process is tedious expensive in large quantities and error prone the most promising alternative is something i ve blogged about synthetic datasets for training ai put simply we can create training data from d simulations
game engines like unreal engine and unity are amazing tools for creating lifelike simulations of the real world as opposed to the real world they can allow neural networks to learn in cheap safe controllable repeatable environments with infinite situations impressive graphics and realistic physics
autonomous cars are a great example if a car crashes during training it costs time money and potentially human lives even if crashes are avoided by human intervention it s not possible to practice dangerous situations in a safe way for humans inside or outside of the vehicle if a car crashes in simulation it can either start over or learn to safely pull the car off to the side of the road it can also practice as many times as it needs to not surprisingly the big players in autonomous vehicles tesla gm etc are hiring game engine developers to build realistic training simulations
the carla simulator built on unreal engine is a great example of how a game engine can be used to teach cars to drive check out the video
in addition to autonomous vehicles game engines are being used to train robots and drones check out this video of microsoft airsim which can simulate drone flight in unreal engine
i imagine in the near future we will also see game engine applications in lifelike human simulation for digital assistants movies and video games d reconstructions of real places augmented reality and mixed reality intelligent adversaries in video games and lots of other places
personally i think the intersection of game engines and deep learning is going to be massive these skills will be extremely valuable so i m trying to dive in early it s also a ton of fun and very satisfying to build interactive virtual worlds with game engines have i sold you on this yet join me and let me know how your learning is progressing
i live in austin texas with my wife i enjoy eating mexican food and drinking tequila with friends i love video games fantasy novels board games electronic dance music and hot sunny weather
professionally i m a software engineer working primarily in ai and vr cs degree from michigan formerly worked at microsoft currently work at gm if you want more detail check out my linkedin
i ve found that throughout life the times when i m happiest are when i m deliberately voraciously learning something new that i can do with my computer i discovered as a teenager that i could learn without any formal instruction with a combination of free tutorials and self directed projects at the time i just wanted to make trance music with fl studio to become a famous dj and later wanted to make d models with ds max and become a pixar animator i m glad i went with computer science instead the power of creation it affords is about as close to being a wizard that humans can get i did mention i like fantasy novels
starting in i used the same tutorials projects approach to learn vr development in unity and then at the beginning of i set out to do the same thing with deep learning
below are the courses i ve taken or plan to take i ll update the list with progress and new additions as i go
note i already knew a lot before starting this course some from college some from my job some from personal interest i was very capable in unity c and blender and had strong debugging and problem solving skills from years of programming see the suggested curriculum for beginners section below for my recommendations if you aren t coming in with some or all of these skills
completed udacity deep learning nanodegree this course was incredible i ve not seen another course that surpasses it in depth and breadth compare the syllabus to anything out there and you ll see what i mean i was fortunate that my company paid for this because it was relevant to my job this course was my first intro to python programming fortunately since i am an experienced developer i was able to pick it up as i went along but if you are new to development i d strongly suggest you take a python course first
started freecodecamp deep reinforcement learning course free this free course looks really cool you train deep reinforcement learning algorithms to play old school video games
openai spinning up free this looks like a really deep comprehensive overview of reinforcement learning it also looks to be a great intro to openai gym which is one of the projects i wanted to work on
completed udemy unreal engine c developer course this course did a good job of introducing me to unreal it s a bit messy in places but overall it covers so much so thoroughly that it s easy to recommend
completed pluralsight learn how to program with c started pluralsight c fundamentals including c i was pretty rusty on c though i did learn it in college these courses helped refresh me on the basics and get me up to speed on the more modern changes that happened to the language since i graduated c is the language used by unreal engine so i wanted to have a strong foundation
completed ros robot operating system tutorials free i learned ros for a project at work but it s certainly relevant here robotics is already using d simulation for training purposes in particular with gazebo it s a natural progression to use high powered game engines like unreal engine and unity for training as these robots use more powerful computer vision
started hard surface modeling in blender i started this fast paced advanced course more for fun than necessity but i think it will really boost my d modeling skills i spent a lot of time learning the basics of blender on youtube years ago before diving into this one
khan academy math free my wife is currently learning to program for the first time she quickly realized that her math skills were pretty rusty and that it was making the python course she was taking extra difficult khan academy has been a big help
udemy modern python bootcamp this is the intro programming class my wife is taking i picked it out because i liked the instructor and the syllabus
microsoft virtual academy c fundamentals for absolute beginners free microsoft virtual academy programming in c jump start free these free courses appear to be a good intro to c which essential for unity i d recommend you get comfortable with it so that you can write quality code
udemy complete c unity developer d course i started learning unity from a book that s out of date now and youtube tutorials but this looks like a good intro course to get you up and running
blenderguru blender beginning tutorial series free blenderguru intermediate blender tutorial series free i ve been playing around with blender for d modeling for a couple years and i find it s almost as good as the applications that cost thousands of dollars but is completely open source and free if you are new to d modeling there s a wealth of free material out there to learn on youtube the links above are from andrew price aka blenderguru i think he does a great job and am a big fan of his tutorials
nothing beats practice to help solidify knowledge stretch you beyond the learning material and build confidence projects are a critical part of learning anything new and i intend to spend the majority of my time on them also by sharing projects publicly you can prove that you know what you re doing a hell of a lot better than most certificates
as part of my projects i like to create tutorials for other people to follow in my footsteps i believe teaching what i ve learned really helps me lock in what i ve learned you can see what i ve shared on the tutorials section of my website immersive limit all tutorials
i trained a mask r cnn on a custom synthetic image dataset of cigarette butts this didn t use any game engines but it was a good intro to cutting edge image segmentation neural networks it s not super practical to run these neural nets alongside game engines right now because of the sheer amount of graphics compute required but i think we ll see a lot more of it in the coming years i initially planned on using blender to generate cigarette butt renders but ended up using python instead
unity has released an open source project called ml agents which is a framework for training machine learning agents or characters to navigate simple d worlds with neural networks i m currently working on training a pig agent to find truffles with stereo smell watching pigs spin and slide around has been pretty funny
there are some interesting examples of training image detection neural networks on rendered images for example several research groups have used grand theft auto to create training images i d like to create my own system to do this
similar to the project above but with imagery being processed in real time
microsoft open sourced a project called airsim for training drones to fly and cars to drive with unreal engine they have created several realistic environments for training and it even interfaces with flight controllers i ve fired it up to play with it but haven t actually extended it with my own code yet
openai has created openai gym for training reinforcement learning algorithms and neural nets i ve had a little bit of exposure through the udacity deep learning nanodegree but i want to explore it further
opencv continues to be the go to framework for computer vision especially on robots much of the library doesn t actually use deep learning but it does have support for it i ve used it a bit and seen some neat projects done with it i think that combining it with game engines would be a great experiment
another important aspect of becoming an expert in deep learning is getting involved with the community and meeting like minds i ve attended a couple local austin ai meetups joined some ai facebook groups and done a bit of reaching out through linkedin but this is an area i need to put more effort into
i probably need to tweet more
do you know of any great communities where people discuss deep learning let me know
this self driven deep learning in game engines course is a work in progress and i hope it s helpful for others who want to go down a similar learning path if you find any courses that you think i d like have other suggestions or are just excited to follow along please let me know you can reach out to me at aktwelve twitter or connect with me on linkedin
for future updates like the immersive limit facebook page subscribe to the immersive limit youtube channel follow the immersive limit twitter
originally published at www immersivelimit com
software engineer working in vr ar and ai at gm fascinated by the implications of new technology opinions expressed are my own
this post covers the second and final day of the deep learning summit that took place in london on september th th you can find the first post here videos are also being posted on youtube
after a welcome from alison lowndes of nvdia the day started with the startup session
first up were wally trenholm founder amp ceo and jason cassidy md amp chief science officer of sightline innovation talking about the commercialisation of deep learning they started going after military customers then looked for other markets due to long military order process year to order they first took what had been developed in image analysis on geo scale satellite uav and applied it to agriculture then to serve even more customers they went from geo scale to macro scale images addressing industrial problems automated manufacturing quality control next they will go further down and apply their image analysis to nano scale genomic there is a mlaas machine learning as a service term for which they hold the copyright platform which will be released next month with a server on site to collect and preprocess the data and also provide reporting and dashboards while algorithm training and prediction will be done on their cloud in case you are looking clarify is hiring
next up was paul murphy ceo of clarify on deep learning amp speech adaptation the next frontier with some funny cartoonish slides clarify started in london and now texas based provides an api that analyses audio and video making it searchable the main issue with speech is adaptation as also discussed by s bastien brati res in the last session of the first summit day there are different adaptation problems like speaker adaptation ex accents speaker may not be native while most of the training data is native and male noise and tenuation moving away from the microphone the bleeding edge in speech recognition research is
then came appu shaji head of r amp d at eyeem talking about deep learning for real photography eyeem is a social network for photography one of the goals appu is to improve content discovery helping photographers being found and selling more photos he showed eyevision which is currently in early access the engine assesses aesthetic quality of the photo and also tags them with k concepts using data coming from both community and expertly curated tagging they are using cnns with word embeddings based on these research papers paper paper paper
john overington director of bioinformatics at stratified medical followed with artificial intelligence in drug discovery john said that currently drug discovery is extremely expensive and unpredictable r amp d expenses for a single approved drug range from billion to billion source he brought his experience on drug discovery to stratified medical which is developing their own drug pipeline the goal is to use ai to filter down potential molecules accelerating discovery and reducing costs they are building a knowledge graph using data from structured sources molecule databases vocabularies and unstructured data papers patents etc the latter being extracted with nlp techniques they will also leverage new public datasets such as uk k the genome sequencing data of k people which will help uncover rare variants contributing to diseases they are making progress they achieved key milestones in a multimillion partnered alzheimer s program
the last talk of the startup session was given by marius cobzarenco co founder amp cto of re infer on building conversational interfaces with deep nets marisu said they are building business bots that collect data from different systems slack crm wiki etc and are able to answer natural queries currently it is hard to understand intent and context there is active research on embeddings done for example by geoff hinton on deep thoughts at google they are using cnns to find embeddings they found this dnns to be faster to train compared to rnns and at the same time gives good results they also use dl for named entity recognition you still need to extract entities to translate the intent into actions
the second part of the morning was on deep learning applications
david plans ceo and davide morelli cto of biobeats talked about machine intelligence for the essential self their initial work was on neural networks in creativity releasing an app called pulse that generates music based on the heartbeat with the pulse app they collected a large cardiovascular dataset enhanced by information coming from sensor data accelerometer gps gyro etc now they pivoted and use this information to train models for people wellness david who also gave a terrific talk during the summit dinner the night before said we are constantly under stress as a result we live in sympathetic mode fight or flight with our body acting as if we were in a jungle facing a lion in the long run it damages our health and may result in premature death but with interventions we can be brought back to living in the much saner parasympathetic mode feed and rest couple this with the fact that of company healthcare spending is on preventable chronic diseases they are bringing their system inside organisations collaborating with bupa axa and samsung to predict employee stress and fatigue levels and take action before it is too late they also have a couple of public apps in beta testing
in the last part of the speech davide talked about their technology where there are several challenges like understanding if the stress is good eg you re happy or bad there are some indicators for example under bad stress the heartbeat becomes more regular plus heartbeat information can be correlated with activity ex you are not moving and the heartbeat suddenly becomes regular and info coming from social networks to label datasets on top of that they need to manage large datasets each user generates mb day without killing batteries and exhausting user data plans their solution is to extract features locally send them to the server where models are trained then send back the trained model and make predictions on the device the api sdk will be released by end of the year they concluded saying that the most important open challenges are ethical on bringing emotional intelligence to the algorithms so that interventions are beneficial for the user receiving them and don t cause additional stress
i then attended the parallel session on investing in ai it started with a panel made of vcs nathan benaich of playfair capital john henderson of white star capital simon king of octopus investments together with alex dalyac co founder amp ceo of tractable and moderated by sally davies of financial times most of the discussion has been on how to evaluate an ai startup here are some aspects being considered
they agreed that the acquisition of deepmind by google is a very important signal for europe before us companies tended to buy only us startups this opens new exit possibilities for european startups making them more attractive to vcs
after a very good lunch break the afternoon started with alex matei mhealth manager and ekaterina volkova volkmar researcher of bupa on deep learning for digital health bupa is an international healthcare group whose activity span from hospitals to company health insurance they showed an interesting series of proof of concept
i really appreciated their approach using available software api for fast prototype development they also showed some good practices like defining at the start of each project the evaluation criteria for deciding which software api to use example criteria what is the software api potential to scale how does the costs grow in case of large deployments
rodolfo rosini cto of weave ai came after the presentation was not very informative they seem to be in stealth mode their idea is to use contextual information to provide improved search he also talked about aggregating corporate information and making it easily searchable something similar to what re infer was talking about in the morning
joerg bornschein global scholar at cifar followed with a talk on combining directed amp undirected generative models joerg talk was about unsupervised learning where the progress has not been as impressive as in supervised learning and there are yet less real world application nevertheless it might help us to understand how the brain works and it will enable new applications where machines generate content joerg presented his work on training bidirectional helmholtz machines paper helmholtz machines hms are made of a generative model coupled with an auxiliary model which performs approximate inference joerg presented a new way to train the hms where probabilities of both models are interpreted as approximate inference distributions and the goal is to minimise the difference between the distributions he showed some examples of the algorithms in action where they reconstruct digits and faces with missing parts
the last talk of the summit was given by marie francine moens professor at ku leuven on learning representations for language understanding experiences from the muse project muse which stands for machine understanding for interactive storytelling is working on algorithms that translate text into virtual worlds applications include rendering children s stories and providing patient guidelines ex foreigners in a hospital as d virtual worlds the algorithms play a double role
the main difficulties come from having very few annotated training datasets for which they are researching into using other data sources like language models to improve results there is also a lack of world knowledge ex practice with a spear gt the spear is held in the hand so they are working on multimodal deep learning using both images and phrases to acquire more knowledge
that concluded the deep learning summit london the organisation by the re work team nikita pip sophie was great the summit had a positive mix of industry and research talk and it was a terrific opportunity to network and get to know lots of interesting people in the deep learning field coming up are the san francisco summit and then europe again highly recommended
ceo and chief data scientist at optimist ai bringing innovation to sales through big data the future is bright
a non technical guide for how to brainstorm potential ml use cases in your business recommended read for experienced new or hopeful product managers data scientists and entrepreneurs looking to integrate ai ml into their business
i hear the following question several times a week
i want to use ml in my business where should i use it
companies are changing the way they do business because of machine learning this evolution comes with a lot of excitement but also some anxiety about potentially falling behind
whether or not you re supposed to be the one figuring this out it can be stressful to think about where you and your company fit in to this changing landscape
a bit about me my name is allie miller and i am a lead product manager at ibm watson i have worked in three of the most critical areas of artificial intelligence conversation computer vision and data and what gets me out of bed in the morning the scale impact and humanization of artificial intelligence
and basset hounds
i have now worked with over clients in artificial intelligence and while each industry and vertical presents its own special flavor of considerations and challenges there are a few persisting themes that together form the five levels of machine learning use cases
each level builds on the last but before we start climbin
no matter what you build no matter how much funding you have no matter what industry you re in you must talk to your end users
understanding your users will illuminate paths to success everything from what data you should analyze to where biases might creep in
always start with empathy always have communication lines open with your users
do not even continue reading until you have committed to this
ok ready back to the ladder
also known as tell me what this thing is
examples
identification is the foundation of machine learning use cases it tends to be most helpful in workflow routing auto tagging and trend analysis use cases knowing what something is is the first step in deciding what to do with it
identification is also generally not a binary result machine learning will not just tell you whether a not or photo contains a dog it will tell you how likely it is that the photo contains a dog this is referred to as a confidence score
different use cases call for different confidence level thresholds
for example if you are creating a stock photo site and want to use ml to identify if a sidewalk is present in a photo you might require a minimum of accuracy the consequence of a false positive saying a sidewalk is there when it isn t or false negative saying a sidewalk isn t there when it is is fairly low but if you re building a self driving car and want to identify if a sidewalk is present accuracy is far too low
also known as group these similar things
examples
really this is just combining multiple classifications and making them relate to each other all of the classes or tags like dog vs cat are trained in a group rather than in individual models so the system can better learn the relationship similarities and differences between a dog and b cat
also known as tell me whether i should care about this thing
examples
now we start to add contextual clues clues specific to that specific company or time or geography we re not just labeling one aspect of one feature we re generating a sense of urgency ranking and prioritization
also known as tell me what to do about this thing
examples
at level we begin to incorporate ai ml outputs into business workflows the system has returned some sort of output this bank transaction is likely to be fraudulent but deciding what to do with that output is where it gets really valuable cover up to in fraudulent charges
there are multiple ways to handle the triage if it s an urgent customer email you can automatically reply with a direct customer support line if it s a retail store emergency you can send alerts to all nearby security guards if it s a fraudulent bank transaction you can send it to a banking expert to manually review it
deciding what to do with the output is up to you and your company but automating the assess and recommend portion of your workflow will allow you to triage not only more quickly but also with greater accuracy
also known as will this thing happen
examples
prediction is the golden ticket of artificial intelligence the holy grail and i sometimes to refer to this as the last column problem
picture a spreadsheet with structured and unstructured data sources functioning as each column
if you re a retail company you may have a customer s name age gender email address emails to the company in store shopping behavior previous items viewed and previous items purchased if you re in agriculture maybe you have a farm s location farm size local weather patterns predicted weather pesticide levels competitor farms performance watering schedules and satellite images of the farms
in each case you want to analyze all of the factors e g age farm size satellite images customer emails to best predict the last column of your spreadsheet
something like knowing everything you know about this customer will they buy during our holiday sale or knowing everything you know about this farm will it produce enough corn this year
if you can predict costly or destructive events before they happen you can have a huge impact on your company and users applying machine learning to your business can cut costs allow you to redirect your company s resources toward areas of greatest impact and most importantly improve the livelihood of others
these five levels have served me and my clients well across a variety of projects and applications from labeling dog photos to predicting train track malfunctions these are core building blocks to ml use cases and i hope you find them valuable
regardless of your familiarity with machine learning or the size and complexity of the solution you and your business go after remember always start small and iterate
comment below and let me know what ml use cases you re working on
lead product manager ibm watson proud wharton stanford and dartmouth alum champion axe thrower
artificial intelligence has been brain dead since the s this rather ostentatious remark made by marvin minsky co founder of the world famous mit artificial intelligence laboratory was referring to the fact that researchers have been primarily concerned on small facets of machine intelligence as opposed to looking at the problem as a whole this article examines the contemporary issues of artificial intelligence ai looking at the current status of the ai field together with potent arguments provided by leading experts to illustrate whether ai is an impossible concept to obtain
because of the scope and ambition artificial intelligence defies simple definition initially ai was defined as the science of making machines do things that would require intelligence if done by men this somewhat meaningless definition shows how ai is still a young discipline and similar early definitions have been shaped by technological and theoretical progress made in the subject so for the time being a good general definition that illustrates the future challenges in the ai field was made by the american association for artificial intelligence aaai clarifying that ai is the scientific understanding of the mechanisms underlying thought and intelligent behaviour and their embodiment in machines
the term artificial intelligence was first coined by john mccarthy at a conference at dartmouth college new hampshire in but the concept of machine intelligence is in fact much older in ancient greek mythology the smith god hephaestus is credited with making talos a bull headed bronze man who guarded crete for king minos by patrolling the island terrifying off impostors similarly in the th century mechanical talking heads were said to have been created to scare intruders with albert the great and roger bacon reputedly among the owners however it is only in the last years that ai has really begun to pervade popular culture our fascination with thinking machines is obvious but has been wrongfully distorted by the science fiction connotations seen in literature film and television
in reality the ai field is far from creating the sentient beings seen in the media yet this does not imply that successful progress has not been made ai has been a rich branch of research for years and many famed theorists have contributed to the field but one computer pioneer that has shared his thoughts at the beginning and still remains timely in both his assessment and arguments is british mathematician alan turing in the s turing published a paper called computing machinery and intelligence in which he proposed an empirical test that identifies an intelligent behaviour when there is no discernible difference between the conversation generated by the machine and that of an intelligent person the turing test measures the performance of an allegedly intelligent machine against that of a human being and is arguably one of the best evaluation experiments at this present time the turing test also referred to as the imitation game is carried out by having a knowledgeable human interrogator engage in a natural language conversation with two other participants one a human the other the intelligent machine communicating entirely with textual messages if the judge cannot reliably identify which is which it is said that the machine has passed and is therefore intelligent although the test has a number of justifiable criticisms such as not being able to test perceptual skills or manual dexterity it is a great accomplishment that the machine can converse like a human and can cause a human to subjectively evaluate it as humanly intelligent by conversation alone
many theorist have disputed the turing test as an acceptable means of proving artificial intelligence an argument posed by professor jefferson lister states not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt and not by the chance fall of symbols could we agree that machine equals brain turing replied by saying that we have no way of knowing that any individual other than ourselves experiences emotions and that therefore we should accept the test however lister did have a valid point to make developing an artificial consciousness intelligent machines already exist that are autonomous they can learn communicate and teach each other but creating an artificial intuition a consciousness is the holy grail of artificial intelligence when modelling ai on the human mind many illogical paradoxes surface and you begin to see how the complexity of the brain has been underestimated and why simulating it has not be as straightforward as experts believed in the s the problem with human beings is that they are not algorithmic creatures they prefer to use heuristic shortcuts and analogies to situations well known however this is a psychological implication it is not that people are smarter then explicit algorithms but that they are sloppy and yet do well in most cases
the phenomenon of consciousness has caught the attention of many philosophers and scientists throughout history and innumerable papers and books have been published devoted to the subject however no other biological singularity has remained so resistant to scientific evidence and persistently ensnarled in fundamental philosophical and semantic tangles under ordinary circumstances we have little difficulty in determining when other people lose or regain consciousness and as long as we avoid describing it the phenomenon remains intuitively clear most computer scientists believe that the consciousness was an evolutionary add on and can therefore be algorithmically modelled yet many recent claims oppose this theory sir roger penrose an english mathematical physicist argues that the rational processes of the human mind are not completely algorithmic and thus transcends computation and professor stuart hameroff s proposal that consciousness emerges as a macroscopic quantum state from a critical level of coherence of quantum level events in and around cytoskeletal microtubules within neurons although these are all theories with not much or no empirical evidence it is still important to consider each of them because it is vital that we understand the human mind before we can duplicate it
another key problem with duplicating the human mind is how to incorporate the various transitional states of consciousness such as rem sleep hypnosis drug influence and some psychopathological states within a new paradigm if these states are removed from the design due to their complexity or irrelevancy in a computer then it should be pointed out that perhaps consciousness cannot be artificially imitated because these altered states have a biophysical significance for the functionality of the mind
if consciousness is not algorithmic then how is it created obviously we do not know scientists who are interested in subjective awareness study the objective facts of neurology and behaviour and have shed new light on how our nervous system processes and discriminates among stimuli but although such sensory mechanisms are necessary for consciousness it does not help to unlock the secrets of the cognitive mind as we can perceive things and respond to them without being aware of them a prime example of this is sleepwalking when sleepwalking occurs sleepwalking comprises approximately percent of all children and percent of adults many of the victims carry out dangerous or stupid tasks yet some individuals carry out complicated distinctively human like tasks such as driving a car one may dispute whether sleepwalkers are really unconscious or not but if it is in fact true that the individuals have no awareness or recollection of what happened during their sleepwalking episode then perhaps here is the key to the cognitive mind sleepwalking suggests at least two general behavioural deficiencies associated with the absence of consciousness in humans the first is a deficiency in social skills sleepwalkers typically ignore the people they encounter and the rare interactions that occur are perfunctory and clumsy or even violent the other major deficit in sleepwalking behaviour is linguistics most sleepwalkers respond to verbal stimuli with only grunts or monosyllables or make no response at all these two apparent deficiencies may be significant sleepwalkers luse of protolanguage short grammar free utterances with referential meaning but lack syntax may illustrate that the consciousness is a social adaptation and that other animals do not lack understanding or sensation but that they lack language skills and therefore cannot reflect on their sensations and become self aware in principle francis crick co discover of double helix dna structure believed this hypotheses after he and james watson solved the mechanism of inheritance crick moved to neuroscience and spent the rest of his trying to answer the biggest biological question what is the consciousness working closely with christof koch he published his final paper in the philosophical transactions of the royal society of london and in it he proposed that an obscure part of the brain the claustrum acts like a conductor of an orchestra and binds vision olfaction somatic sensation together with the amygdala and other neuronal processing for the unification of thought and emotion and the fact that all mammals have a claustrum means that it is possible that other animals have high intelligence
so how different are the minds of animals in comparison to our own can their minds be algorithmically simulated many scientists are reluctant to discuss animal intelligence as it is not an observable property and nothing can be perceived without reason and therefore there is not much published research on the matter but by avoiding the comparison of some human mental states to other animals we are impeding the use of a comparative method that may unravel the secrets of the cognitive mind however primates and cetacean have been considered by some to be extremely intelligent creatures second only to humans their exalted status in the animal kingdom has lead to their involvement in almost all of published experiments related to animal intelligence these experiments coupled with analysis of primate and cetacean s brain structure has lead to many theories as to the development of higher intelligence as a trait although these theories seem to be plausible there is some controversy over the degree to which non human studies can be used to infer about the structure of human intelligence
by many of the physical methods of comparing intelligence such as measuring the brain size to body size ratio cetacean surpass non human primates and even rival human beings for example dolphins have a cerebral cortex which is about larger a human being their cortex is also stratified in much the same way as humans the frontal lobe of dolphins is also developed to a level comparable to humans in addition the parietal lobe of dolphins which makes sense of the senses is larger than the human parietal and frontal lobes combined the similarities do not end there most cetaceans have large and well developed temporal lobes which contain sections equivalent to broca s and wernicke s areas in humans
dolphins exhibit complex behaviours they have a social hierarchy they demonstrate the ability to learn complex tricks when scavenging for food on the sea floor some dolphins have been seen tearing off pieces of sponge and wrapping them around their bottle nose to prevent abrasions illustrating yet another complex cognitive process thought to be limited to the great apes they apparently communicate by emitting two very distinct kinds of acoustic signals which we call whistles and clicks and lastly dolphins do not use sex purely for procreative purposes some dolphins have been recorded having homosexual sex which demonstrates that they must have some consciousness dolphins have a different brain structure then humans that could perhaps be algorithmic simulated one example of their dissimilar brain structure and intelligence is their sleep technique while most mammals and birds show signs of rapid rem rapid eye movement sleep reptiles and cold blooded animals do not rem sleep stimulates the brain regions used in learning and is often associated with dreaming the fact that cold blooded animals do not have rem sleep could be enough evidence to suggest that they are not conscious and therefore their brains can definitely be emulated furthermore warm blood creatures display signs of rem sleep and thus dream and therefore must have some environmental awareness however dolphins sleep unihemispherically they are conscious breathers and if fall asleep they could drown evolution has solved this problem by letting one half of its brain sleep at a time as dolphins utilise this technique they lack rem sleep and therefore a high intelligence perhaps consciousness is possible that does not incorporate the transitional states mentioned earlier
the evidence for animal consciousness is indirect but so is the evidence for the big bang neutrinos or human evolution as in any event such unusual assertions must be subject to rigorous scientific procedure before they can be accepted as even vague possibilities intriguing but more proof is required however merely because we do not understand something does not mean that it is false or not studying other animal minds is a useful comparative method and could even lead to the creation of artificial intelligence that does not include irrelevant transitional states for an artificial entity based on a model not as complex as our own still the central point being illustrated is how ignorant our understanding of the human brain or any other brain is and how one day a concrete theory can change thanks to enlightening findings
furthermore an analogous incident that exemplifies this argument happened in when an irish workman phineas cage shed new light on the field of neuroscience when a rock blasting accident sent an iron rod through the frontal region of his brain miraculously enough he survived the incident but even more astonishing to the science community at the time were the marked changes in cage s personality after the rode punctured his brain where before cage was characterized by his mild mannered nature he had now become aggressive rude and indulging in the grossest profanity which was not previously his custom manifesting but little deference for his fellows impatient of restraint or advice when it conflicts with his desires according to the boston physician harlow in however cage sustained no impairment with regards to his intelligence or memory
the serendipity of the phineas cage incident demonstrates how architecturally robust the structure of the brain is and by comparison how rigid a computer is all mechanical systems and algorithms would stop functioning correctly or completely if an iron rod punctured them that is with the exception of artificial neural systems and their distributed parallel structure in the last decade ai has began to resurge thanks to the promising approach of artificial neural systems
artificial neural systems or simply neural networks are modelled on the logical associations made by the human brain they are based on mathematical models that accumulate data or knowledge based on parameters set by administrators once the network is trained to recognize these parameters it can make an evaluation reach a conclusion and take action in the s neural networks became widely used with the backpropagationalgorithm first described by paul john werbos in the s marked major achievements in many areas of ai and demonstrations of various applications most notably in ibm s deep blue supercomputer defeated the world chess champion garry kasparov after the match kasparov was quoted as saying the computer played like a god
that chess match and all its implications raised profound questions about neural networks many saw it as evidence that true artificial intelligence had finally been achieved after all a man was beaten by a computer in a game of wits but it is one thing to program a computer to solve the kind of complex mathematical problems found in chess it is quite another for a computer to make logical deductions and decisions on its own
using neural networks to emulate brain function provides many positive properties including parallel functioning relatively quick realisation of complicated tasks distributed information weak computation changes due to network damage phineas cage as well as learning abilities i e adaptation upon changes in environment and improvement based on experience these beneficial properties of neural networks have inspired many scientists to propose them as a solution for most problems so with a sufficiently large network and adequate training the networks could accomplish many arbitrary tasks without knowing a detailed mathematical algorithm of the problem currently the remarkable ability of neural networks is best demonstrated by the ability of honda s asimo humanoid robot that cannot just walk and dance but even ride a bicycle asimo an acronym for advanced step in innovative mobility has flexible joints requiring a four processor computer to control its movement and balance its exceptional human like mobility are only possible because the neural networks that are connected to the robot s motion and positional sensors and control its muscle actuators are capable of being taught to do a particular activity
the significance of this sort of robot motion control is the virtual impossibility of a programmer being able to actually create a set of detailed instructions for walking or riding a bicycle instructions which could then be built into a control program the learning ability of the neural network overcomes the need to precisely define these instructions however despite the impressive performance of the neural networks asimo still cannot think for itself and its behaviour is still firmly anchored on the lower end of the intelligent spectrum such as reaction and regulation
neural networks are slowly finding there way into the commercial world recently siemens launched a new fire detector that uses a number of different sensors and a neural network to determine whether the combination of sensor readings are from a fire or just part of the normal room environment such as dust over fifty percent of fire call outs are false and of these well over half are due to fire detectors being triggered by everyday activities as opposed to actual fires so this is clearly a beneficial use of the paradigm
but are there limitations to the capabilities of neural networks or will they be the solution to creating strong ai artificial neural networks are biologically inspired but that does not mean that they are necessarily biologically plausible many scientists have published their thoughts on the intrinsic limitations of using neural networks one book that received high exposure within the computer scientist community in was perceptron byminsky and papert perceptron brought clarity to the limitations of neural networks although many scientists were aware of limited ability of an incomplex perceptron to classify patterns minsky s and papert s approach of finding what are neural networks good for illustrated what is impeding future development of neural networks within its time period perceptron was exceptionally constructive and its identifiable content gave the impetus for later research that conquered some of the depicted computational problems restricting the model an example is the exclusive or problem the exclusive or problem contains four patterns of two inputs each a pattern is a positive member of a set if either one of the input bits is on but not both thus changing the input pattern by one bit changes the classification of the pattern this is the simplest example of a linearly inseparable problem a perceptron using linear threshold functions requires a layer of internal units to solve this problem and since the connections between the input and internal units could not be trained a perceptron could not learn this classification eventually this restriction was solved by incorporating extra hidden layers although advances in neural network research have solved many of the limitations identified by minsky and papert numerous still remain such as networks using linear threshold units still violate the limited order constraint when faced with linearly inseparable problems additionally the scaling of weights as the size of the problem space increases remains an issue
it is clear that the dismissive views about neural networks disseminated by minsky papert and many other computer scientists have some evidential support but still many researchers have ignored their claims and refused to abandon this biologically inspired system
there have been several recent advances in artificial neural networks by integrating other specialised theories into the multi layered structure in an attempt to improve the system methodology and move one step closer to creating strong ai one promising area is the integration of fuzzy logic invented by professor lotfi zadeh other admirable algorithmic ideas include quantum inspired neural networks quinns and network cavitations proposed by s l thaler
the history of artificial intelligence is replete with theories and failed attempts it is in inevitable that the discipline will progress with technological and scientific discoveries but will they ever reach the final hurdle
read more
rent the runway is valued at million and is well on its way to be a unicorn i joined in to bring data science to then a small company of less than individuals in the main office supporting million customers at peak we had two junior data scientists besides me when i left in february this year rtr was serving million customers the membership program that i was a founding member of and returned to last year had grown to nearly half the overall revenue for comparison a membership only competitor has about data scientists currently
scaling is never easy not even for amazon and google but it is certainly harder to do so thoughtfully and with fewer resources
if you work for goofaceapplezon this series likely won t be relevant to you but if you re not read on
in this post i will discuss strategy next one will be about choosing infra and tech and finally i ll talk about models software and importantly the unique challenges of ml tests you will learn something you can apply to your work depending on your seniority and role
data science for retail
this was not an obvious question in but rtr execs knew they were a different breed
like a traditional e commerce company rtr has inventory customers come on site and need recommendations pricing coupons etc all the way to checkout unlike a traditional e commerce however that isn t the end of the story
the dress needs to be shipped out at the event date to do this we have to get the dress from the previous customer who has a probability of being late dry clean it probability of failure and then make sure we can take order for the next person oh and incidentally we happen to be the largest dry cleaners in the world that means supply side logistics with inventory flow from various stations
often called netflix of fashion one notable difference is that the stakes are very high if you watch first minutes and didn t like the movie skip it and your night is not ruined if the dress doesn t work for a customer for that wedding she is going to or is the bride she likely won t come back
rent the runway is a fashion technology engineering supply chain operations reverse logistics dry cleaning analytics business
such problems need custom solutions to scale we needed artisinal hand rolled ml i was brought in due to my previous experience with barnes amp nobles
machine learning at rtr
here are a few data products that i coded and shepherded
carouseled recommendations based on user s style for our membership program
as far as i know the personalized order of carousels and products for fashion is unique to us with hat tip to netflix and spotify it allows for near realtime recommendations and fast personalization to boot i launched this in working days leveraging past work
personalized event recommendations for our a la carte business done with anthony a very talented data scientist now at google maps
you may also like recommendations with anna now etl at spotify
women like me sort to help with fit with kaleigh now google
demand forecasting inventory management price prediction many folk most notably anthony and rob one of the fastest learners i have met
search a dress by image with gabe work travel balance guru and sandy now at google and the browser extension with nizar now at betterment and sandy
using ai to get instagram posts and refine with humans before showing it as a dress review with hindi caroline and sam read about it https sanealytics com human in a i loop
and many more like inventory buying queue solvers warehouse allocation algorithms etc and all that runs every day without needing a lot of upkeep
complexity
the nice thing about working in something that is cool is that everyone wants to help this is a double edged sword
let s say for a certain data project there are only two folk one data scientist and one product person there only needs to be one line of communication things are simple two minds as one
let s add one more person say infra there needs be three lines of communication everyone needs to be in step with everyone else
how about with people turns out we need lines of communication this is a little bit of an exaggeration because not everyone really needs to talk to everyone else but there are still complex dependencies i m a computer scientist first so unfortunately i do o n for fun now what if you add one more person team
take home lesson the complexity of communication increases exponentially proportional to number of teams involved
strive for simplicity
this same analysis can be done for codebase servers etc you will see a recurring theme of preferring simple over complex as far as teams go your natural tendency would be to align with other engineers but if you have to prioritize make sure you spend more time with the product folk
what should you work on
every process begins on the data side of the equation what is worth solving is more important than how well you solve it if it s the right thing the team will be behind you for the hack and the long haul to help figure out a better solution if not this is not worth pursuing find a new problem sorry neural stain identification to speed up dry cleaning
once you are done understanding and analyzing what the problems are you need to pitch them to the business stakeholders i m serious treat it like a vc pitch it needs to something that shows what the potential upside is you have data after all next a quick demo of poc it need only run on your laptop finally you will get resources time on the roadmap and fellow hobbits for the journey
if you haven t had to do this it s because someone has already fought this round for you thank them for they are noble
for user level recommendations five years ago i had to stand an mpp data warehouse mysql gt vertica write some hairy code to ingest large text files and show that there were actually discrete clusters of users i made a r shiny app demo to show what their recos would be i then tested it over email to show a huge lift double digits in click through rate to get folks excited
once the product is on the roadmap align the team on the metric you want to measure your hypothesis is that moving this metric will move the dollars make sure you state it this way and everyone nods on that one metric this exercise eliminates complexity because you can t tune your algo for everything and the business needs to follow why you re harping on about recall
oh btw the english language isn t helpful here but it s what the message needs to be in and repeated over and over again i ve learnt to stay away from accuracy and i can never explain auc in simple english so that rules them out
what you tune for internally is your problem but this is the metric you are asking to be held up to and you need to validate if improving this actually helps the business dollars
protip obsess over this but not too much any metric you choose will be wrong over time so pick one and move on
strategies for kiss keep it simple stupid
this is fantastic you finally have a well defined problem an objective a team this is almost like kaggle now time to impress everyone with that reinforcement learning variational gan you have been aching to try out
no
linear model first i count logistic or its bayesian cousin in the same breath this needs to be the baseline you will beat over time kiss approved
why is this important because in production you have to build a lot more around it we ll come to that in the third post in the series so you need to deploy something end to end that means from getting data training model predicting writing checks shipping those predictions to the right services and measuring the impact via automated reports there is simply too much to build
another little secret when you re competing against humans linear models are already a big enough step up they might give you the for free you ll have to fight a lot harder for the remaining and if you have been successful in creating a virtuous data cycle even this linear model will get better over time simply because your business is growing
this brings to another point data science as it is right now is a research practice things take time they often fail most companies pump a lot of money into hiring expensive phds but don t see the outcome so they get frustrated and scale back on data science set appropriate expectations
you need to separate research from production which is business speak for cannot fail linear models are easy to debug rarely fail and scale very well they also motivate you to go back to it later and demonstratively make it better in terms of revenue with the right model for the problem
and besides you don t even know if the metric you want to improve has any impact on business do you truly understand the problem yet life is cruel
feedback
your model and impact is only as good as the data it has to this end treat ux and product as an extension of what you can optimize your goal should be to validate the metrics and make feedback loops that give you more data
this means you might have to pause a project too for example i had a novel approach to fit recommendations demoed with data extracted by nlp got the green light and small team got working and discovered that we had signal but it wasn t strong enough we could have still launched but decided to hold back and collect more data we redesigned the survey unlimited members take on returning a product to get data for this directly
focus on feedback loops to give you more data
team
you have a success congratulations after the high fives are over where do you invest
this is where a lot of companies go wrong and grow the team too quickly
one data product will have user interfaces on the web app email etc all needing multiple engineers and ux designers to code up it will need more analysts to understand if its driving revenue generate more data that the etl team will need to consume and sanitize and that s just the support system for one little algorithm you coded up
i argue that you need more etl folks analysts and engineers than data science ml this answer won t be appropriate for all stages so take it with a grain of salt
another issue is that apart from long running research dress wear over time data work tends to be spotty a company of engineers can run about projects in one quarter only one of those will likely be the bet on machine learning there are always other competing priorities
your might have engineers and analysis who want to get into data science it is always satisfying to mentor and figure out a problem together however everyone wants to work on recommendation systems or image processing so it takes a lot of conversations to find a good problem their interests are aligned in they are excited to work on and is a business question that potentially has an impact too hard a problem predict churn needs understanding a lot of variables can kill the enthusiasm of a fledging data scientist if you notice above all the projects have a co pilot who maintain the product once its out in the wild focus on working with only one person for that data product keep n small
downtimes are also a good time to go back and better those models go ahead and try those neural nets now but most of your time should go into finding what the next most important problem to work on is don t get attached to a problem there are lots of low hanging fruit quantify impact in dollars and see if its worth pitching
a big caveat is hiring it is unlikely you will find the same person who can do everything i was the single point of failure for rtr for many years which is obviously undesirable it is easier to find folks with different skills that make the team have all the required talent again these skills won t be obvious when you start so don t grow too quickly but definitely try to build redundancy as you scale
i ran into issues hiring who to lead the etl team for a relatively unknown rtr at the time it took me an year to find the right candidate who happened to be an extremely talented homegrown aspiring data scientist and found that she enjoyed etl more the answer was always complementary skill members
so maybe look for both you might be forced into one of those options if you are not known for data science one funny thing is that graphic designers want to work at apple which already has great ux not say amazon people don t always see the open green fields
partner with non engineers i started an internal rtr deepdress team comprising of all folks in the company curious about applying ai to fashion problems the browser extension instagram and some other product ideas came from that ux designers were more than happy to work on this because they were involved at ideation
good ideas come from everywhere refine
good fences make good neighbors
rtr s backend is standardized to java i had originally written my models in c with r for analysis python data munging was nonexistent in i then moved to write them in java or scala my preference at the time to integrate with products engineering was building the upside was that all i d be writing is a class and the data glue etc is all in engineering s domain so barrier to entry was small
that was a mistake
for one every model needs to be re coded into java which is not fun second once deployed you lose control over it changing the model now means testing the entire service and that s not going to happen unless it is someone s project
the correct way is to treat ml as saas even though it s an internal team i ve slept better since
so we need slas notably the top few are
this looks pretty horrible no cto will sign off on this contract and remember she is one of your investors so you need that
the first strategy is separation of concerns kiss approved
for engineering this means that they don t need to understand the model the runbook says restart and upon startup the service will pick up the previous version of the model which presumably worked a few hours ago no one should have to debug ml code at am also incidentally you get to sleep in because it s not really a problem if it heals itself
for the etl team this means that we will create data transformation jobs schedule and handoff to them any ongoing maintenance from that point will be theirs
second strategy for this is to code for reliability via checks and tests if anything fails the model deploy should fail sorry for the teaser but i will talk about in part
third figure out graceful fallbacks and fallbacks to those fallbacks for example if someone comes to the homepage whose recommendations we haven t computed what should they see new item who should it be recommended to if the service is down what should they see
caching is a strategy here but there is major caveats for example you want the engineering service to cache the unknown user s recommendations every now and then but if the recos now compute and the user is now known you need to tell the engineering service to invalidate it
another problem is synchronization amongst servers if one server knows it as one user and another has previous recos refresh of the same page by the customer would give her different set of products an undesirable experience
partner with your engineering buddies and involve them this is fun stuff and ultimately they have to maintain it
fourth deploy daily hourly continuously this is because your automated tests checks are only as good as you run them and a small team is unlikely to re run the model from last year and will absolutely hate to debug an issue that originally happened months ago but no one noticed till now a continuous deploy will catch the problem when it happens and will revert because of the above fallback mechanism
another reason is to catch the more insidious problems sometimes upstream data new feature something else unknown to you will break your model catch them when they happen
fifth whatever tech model language you choose will be out of fashion next month data science is a fast moving field and even in deep learning there have been at least different libraries last year so design for parts to be switchable we have things running in r c python and scala i ll talk about this more in second and third parts of the series
sixth ml can t solve everything hopefully you have caught these edge cases during the model build phase large sizes low inventory low history etc sometimes you will rightly ignore the problem because it might not be too big or put guardrails around it ideal either way though it needs to be surfaced on a report
this brings me to seventh and final strategy for this post what gets measured gets fixed alternatively make it someone else s problem one off complicated data products depending on data that only that product uses is a recipe for disaster keep the data model consistent with what someone else is using view of customers products etc this way when they find an issue and fix it your problem will get fixed as well
at the very least make a report that tracks the metric that you agreed on and actual business impact see if the metric still tracks that this should be on a report that folks regularly use so you don t have to
i am now working on my own retail ai startup virevol currently hiring for product sales ux front end engineers and ml of course i usually write on https sanealytics com and tweet at https twitter com analyticsaurabh
a very short version of this was given as a talk in gtc nvidia s ai conference upon encouragement from nikolai yakovenko i have turned it into a series of blog posts
see you next time
making palatable meaningful data products from terabytes of data ai ml stats sr data scientist at rent the runway previously barnes amp nobles unilever
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
download pdf robot proof higher education in the age of artificial intelligence by joseph e aoun epub pdf link https kindleuploadsale icu q robot proof a higher education in the age of artificial intelligence read online pdf robot proof higher education in the age of artificial intelligence download pdf robot proof higher education in the age of artificial intelligence download full pdf robot proof higher education in the age of artificial intelligence download pdf and epub robot proof higher education in the age of artificial intelligence read pdf epub mobi robot proof higher education in the age of artificial intelligence reading pdf robot proof higher education in the age of artificial intelligence read book pdf robot proof higher education in the age of artificial intelligence read online robot proof higher education in the age of artificial intelligence download robot proof higher education in the age of artificial intelligence joseph e aoun pdf download joseph e aoun epub robot proof higher education in the age of artificial intelligence read pdf joseph e aoun robot proof higher education in the age of artificial intelligence download joseph e aoun ebook robot proof higher education in the age of artificial intelligence read pdf robot proof higher education in the age of artificial intelligence robot proof higher education in the age of artificial intelligence online download best book online robot proof higher education in the age of artificial intelligence read online robot proof higher education in the age of artificial intelligence book read online robot proof higher education in the age of artificial intelligence e books read robot proof higher education in the age of artificial intelligence online read best book robot proof higher education in the age of artificial intelligence online read robot proof higher education in the age of artificial intelligence books online download robot proof higher education in the age of artificial intelligence full collection download robot proof higher education in the age of artificial intelligence book read robot proof higher education in the age of artificial intelligence ebook robot proof higher education in the age of artificial intelligence pdf read online robot proof higher education in the age of artificial intelligence pdf download online robot proof higher education in the age of artificial intelligence read download robot proof higher education in the age of artificial intelligence full pdf read robot proof higher education in the age of artificial intelligence pdf online read robot proof higher education in the age of artificial intelligence books online read robot proof higher education in the age of artificial intelligence full popular pdf pdf robot proof higher education in the age of artificial intelligence read book pdf robot proof higher education in the age of artificial intelligence read online pdf robot proof higher education in the age of artificial intelligence download best book robot proof higher education in the age of artificial intelligence read pdf robot proof higher education in the age of artificial intelligence collection read pdf robot proof higher education in the age of artificial intelligence full online read best book online robot proof higher education in the age of artificial intelligence download robot proof higher education in the age of artificial intelligence pdf files
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
in my last post about ai i briefly broke down a survey of artificial and machine learnings experts rather then doing forensics of the survey i started at the very top what is an expert
in that survey experts were asked for their probabilities that we would get ai that was able to accomplish every task better and more cheaply than human workers the experts thought on average there was a chance of this happening by and a chance of it happening by
they were also asked by what year for any occupation machines could be built to carry out the task better and more cheaply than human workers the experts thought on average that there was a chance of this happening by and a chance of it happening by
the survery authors point out these two questions are basically the same they were put in just to test if there was any framing effect the framing effect was apparently strong enough to shift the median date of strong human level ai from to this makes it hard to argue ai experts actually have a strong opinion on this
also these averages are deceptive several experts thought there was basically a chance of strong ai by others thought there was only a chance or less by this is less ai experts have spoken and it will happen in and more ai experts have spoken and everything they say contradicts each other and quite often themselves
the next thing we can take from this paper is a timeline of what will happen when the authors give a bunch of different tasks jobs and milestones and ask the researchers when ai will be able to complete them average answers range from nearly fifty years off for machines being able to do original high level mathematical research to only three years away for machines achieving the venerable accomplishment of being able to outperform humans at angry birds along the way they ll beat humans at poker four years writing high school essays ten years be able to outrun humans in a k foot race years and write a new york times bestseller years
artifical intelligence experts years of course
h t slate star codex
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
investor extreme salesman always interested sometimes interesting lurks at www adamtownsend me
artificial intelligence is the most fascinating topic of our time not only because of being an important topic but because of being the simplest among all important ones compare it with the question for instance of what happens when you enter a black hole this would require people to first get comfortable with the fact that its black because its gravity sucked all the light from around it
what you can suck light are you sure about that
of course not but that s what brian greene seems to be saying sometimes
the one about black holes is an important question but it s also a tough one to get your head around now compare it with the following question what would you do if you were faced with someone who could do everything that you can and that too better than you
nothing difficult to understand and an incredible amazement to connect with slowly this question gets everyone thinking and i dont need to give examples of the kind of thoughts that follow the answer often is a personal one for everyone
so almost everyone who has heard of artificial intelligence gets it and everybody wants to know with a sense of anticipation not enjoyed by any technology in the past are we there yet
most people believe we re not there okay but how far have we come and what part is left
foxconn removed workers from its factory in china and got robots to do their jobs but siri still hasn t got attracted to your warm personality and proposed to you in the voice of scarlett johansson there s a robot now that can build a brick house in days but the robot that predicts farts in a crowded metro and disengages them before the explosions is still nowhere to be found there is some disagreement as to what marks the arrival of ai for some people what matters is super intelligence and they have an easy way to detect it the onset of super intelligence would be marked by a singularity event what is a singularity fuck knows
no quite literally
singularity is supposed to be a point in time beyond which what happens is not known to anybody and possibly cannot be known to anybody before it actually happens it s a good time to bring attention back to our cute black holes we started with because they share the concept of singularity with artificial super intelligence the currently accepted answer to the question i posted in the beginning of this piece is exactly this
what happens when you enter a black hole fuck knows
so for this set of people we ve clearly not created ai yet but according to some of them we re not quite far here s a fancy name you can remember to feel closer to this group of people ray not fancy enough try weil kurzweil yup you guessed it james bond happens to be the kurz weil of the fiction world not that kurzweil s world is considered anywhere close to being realistic
on the other side is the group of people without much hope the girlfriends of the world for whom your love would never be enough oh your new car is nice but its not a jaguar trust me some critics don t sound very different when they dismiss every new development in ai as just another program and not real ai this kind of girlfriend effect is very common in the ai world although their term for it is more politically correct its called the ai effect
so although you might not have witnessed the wonderful or horrible things you ve been made to imagine there are changes taking place in the employment structure should we be anxious already should we worry about our jobs or our lives the terminator salvation or the matrix revolution
i ve delved into these questions for a long time now and have tried to answer some of the popular ones through the course of this article i have tried to compile the answers into an exhaustive account of the entire artificial intelligence landscape in other words the next time you come across anything regarding ai you would be able to place it in one of these buckets in your head it might not be a straightforward way of understanding things but it sure would help to resolve some of the mysteries surrounding ai lets start with the first mystery consciousness
whether you re deep into learning technology or can t even get your phone to stop misbehaving because you didn t know there s something called a reboot you do expect artificial intelligence to be able to think like humans this way you can have your most intimate conversations with it think samantha conversations that you might not be able to have with your closest friends because somehow you are assured that you won t get judged would you be bothered by what a machine thinks about you not as long as you know its a machine and that s the interesting part in the near future you might not know whether you re interacting with a machine or a human being the single important thing that people expect from ai is to be exactly like a human at least for sometime before it flashes past us on the evolutionary path in this pursuit the question of how the mind works or how consciousness works is among the toughest unsolved problems all the other pieces are relatively easier to take care of with consciousness the world doesn t even agree on how to define it yet
this brings us to the first important objective of the study of ai replicate human consciousness with a technology that is not biological reproduction a technology that we introduce ourselves at this point you should recollect all the initiatives in ai you are aware of and see which ones have this as their immediate objective i don t think deepmind falls in this category although they are the pioneers of intelligence research in the world search for consciousness is not one of their immediate goals you would be lucky to find such initiatives in popular press since they are mostly restricted to university labs or to some rare obscure companies what are these people trying should you care about this research how close are they to creating consciousness in the lab how do you go about creating something you don t even fully understand
i can t go in the details of this dimension given the restricted scope of this document but the idea is as follows we might not currently understand exactly what happens in the brain but we can crack open the skull and look at what lies inside we know what it looks like and what it s made of in other words we can observe the hardware of the brain so lets just recreate the hardware and switch it on and see what happens the trick seems smart and simple so why has it not been done till now people are trying but the hardware is just way too powerful
the works of stalwarts like hans moravec and lloyd watts place the estimate of the brains computing capacity at around cps computations per second what does that mean it simply means that the brain is always bustling with a lot of activity imagine you spot angelina jolie walking towards you and you decide something must be done the kind of activity it would require across the universe to transform you into brad pitt and make your shirt come off and finally make her fall for you in that one moment is a lot of activity the brain simply has more than that going on inside it at any point of time it takes super computers like ibm s blue gene l or watson to even come close to achieving that kind of computing power and to imagine that we carry all of that within the size of a football on our shoulders is really very humbling so its not easy and people are really throwing their weights behind their research to getting it done you can get a good account of the kind of research that is already underway in kurzweil s book the singularity is near you would be amazed here s an excerpt from an excerpt in his book
it may seem rash to expect fully intelligent machines in a few decades when the computers have barely matched insect mentality in a half century of development indeed for that reason many long time artificial intelligence researchers scoff at the suggestion and offer a few centuries as a more believable period
hans moravec when will computer hardware match the human brain
okay that doesn t sound very optimistic i promise the follow up lines to this one are full of optimism this is my way of urging you to go and pick up the book as of now it suffices to know that this pursuit is on in fact the community working in this field is off to the races and we might reach there soon
so what does this imply for a moment lets drift away and think of the possibilities that would entail this achievement in some ways this is nothing new we ve been creating consciousness at a rapid pace in the form of babies all around the world yet something is new and different about artificially created consciousness a good starting point for you to think about this would be to look at your laptop or phone and imagine if you yourself were trapped in there somewhere what would you do with all the hardware touch screen camera and wifi what would you do would you have the same kinds of aspirations you do today
would an artificial consciousness have the same emotions of happiness sorrow confidence or uncertainty as you do all these are important questions but the one we need to choose to go forward in this discussion is the following would the machine know the same set of things that you do or would it know much more once a machine gets conscious wouldn t it quickly find out everything there is to know and then become capable of doing everything possible my answer is no i have reasons to believe that it isn t possible to know about everything even for a machine at any time in the future
i get a feeling sometimes that when consciousness is first created i or someone with curiosities similar to mine would go to this machine and start asking questions where did you come from or what was it like there and it would say i have no clue mate i m so blanked out i feel like a vegetable
i call this the aisenberg uncertainty principle
its very simple we can never know everything
to some this might be obvious others need some light to appreciate the darkness
every time we ask a question we unknowingly make a transition to a state of not knowing something and we do that quite frequently the process starts with an encounter with one or more unknowns followed by the act of knowing and ends in the generation and sometimes storage of knowledge if i had to give you the most universal observation possible it would be this everything that you ve ever encountered or will ever do in the future is either known to you or is unknown here s the idea in the form of an equation for later recollection
the inspiration for using epsilon for uncertainty or unknowns comes from my engineering background we use epsilon for all things nasty error in measurement noise in data uncertainty in models with every initiative we say okay we ve done our best lets see how it turns out the lets see part is epsilon i am obsessed with it and can go on and on about it but would rather suggest that you learn about it from nassem nicholas taleb you ll instantly know what i m talking about here it s sufficient to know that epsilon represents things that we don t know about
this however has hardly ever been a limitation in fact its always a good starting point for any initiative to accept that there would be unknowns and often unexpected turn of events this and similar guidelines from over the centuries have been made part of what is called the scientific approach to problem solving or science in short we ve known it forever but can seldom follow it we are pre disposed due to evolution to think irrationally in ways that fly in the face of science that s not a bad thing because it has kept us alive till now and no its not simply a behavior aspect that we can correct if we go to some kind of rehab its part of our biology to be irrational and in our environment to reward it yet its important to appreciate the scientific approach because now we have at our disposal tools that are capable of scientific thinking moreover these tools don t have the biological limitations that we do more on this in the following section intriguingly titled computation
from the previous section we see that tomorrow if we have artificial consciousness it would still need to adhere to the aisenberg principle at least in its nascent state the machines would also have to deal with things they don t know about and learn about as they go forward so we ve found some common ground with the machines uncertainty in problem solving more generally speaking problem solving itself and while we might share this with the machines in the future its what we share among all of us today every thing that we do can be defined as an attempt at solving some problem from as trivial as sipping coffee solving the problem of transferring nutrition from a cup to our body to building a giga factory that produces half a million cars in a year god what a mad man
problem solving is more fundamental to our existence than intelligence is if we have to shift from human intelligence to a more broad understanding of it then a functional definition of intelligence would be the ability to solve existing problems and to identify new ones to solve
how does problem solving link with the aisenberg principle
a problem is always something we encounter in the real world and the solutions that we come up with always emerge from what we already know as we try solutions we run into the unknowns and gain a better understanding of the world thereby increasing our knowledge till we are finally able to get a solution to work after every such cycle we have an expanded knowledge base
convince yourself that all forms of artificial intelligence that exists today is about solving some problem siri is an attempt at solving the problem of controlling your phone through voice input a driverless car is a solution to the problem of being transported from one point to another the attempts described in the previous section solve the problem of replicating the hardware of the human mind
would it be right to generalize the study of human intelligence into the study of problem solving lets keep this up for debate in the mean time the following objective doesn t seem any less valuable than replicating human intelligence
create a general purpose problem solving framework or agent or entity that is capable of inducing any change imaginable possible and desirable this last one is optional
we are lucky in this respect since we already have an abstract set of ideas for general purpose problem solving the scientific framework science gives us the highest quality of knowledge that appears in the above mentioned equation i have to say high quality knowledge because some people like to use the word knowledge also for the figments of imagination generated from religious beliefs it lets us identify what exactly to look for in the realm of epsilon from among the unknowns by allowing for hypotheses after experimentation every time a hypothesis is proven right or wrong our knowledge base increases for centuries now we ve been growing the knowledge part of the equation at a tremendous pace and science has a crucial role to play in that
this is not to say that science is the only way forward the method has its limitations in fact many of the leaps and advancements in our knowledge have come from random accidents and bizarre co incidences but sooner or later every idea needs to churn through the scientific screening process to qualify as knowledge
the natural line of inquiry at this stage should have been to develop systems that can optimize problem solving using the available technology of the day within the ethos of science we observe the problem at hand build sufficient understanding to arrive at a solution then indulge in trial and error to successfully solve the problem whether it was deliberate or not we ended up developing a paradigm in which all these steps can be delegated to the machines for good or for bad enter machine learning
a common story among societies in which swimming pools are a relatively new entry is parents telling their kids how they learnt to swim by jumping into a deep well and ensuring that they don t drown machine learning works more or less the same way reinforcement learning works exactly in the same outrageous way lets take a minute to analyze what your who dares wins dad just threw at you
problem being addressed ensure no drowning
path to finding a solution trial and error to experience the water s response to different body movements to ultimately identify the configuration in which he doesn t drown
expanded knowledge base at the end of the endeavor the ability to swim in calm waters
its interesting to note that the knowledge thus collected is not always shareable or easily communicable after coming out of the water your dad may not have been able to instruct the next daredevil in line about the steps to follow during his first visit to the well however thrown in the water again your dad would be able to regain his swimming ability by himself this observation will come in handy just in a short while
machine learning refers to the idea of throwing a machine into a well and expecting it to learn how to swim just like your dad did additionally it involves adjusting your understanding by taking into account how the machine is different from your dad most contemporary machines don t have hands and legs for example while your dad relies on inputs he gets from the five senses of the human body the machine can perceive only digital data that s why ml is so often about data handling or data science similarly while your dad can react with body movements the machine can only react by throwing out more digital data and that s about it
ml in its current form is about a machine constantly taking in data and giving out data till it eventually learns to give out exactly that data which is required to solve the problem at hand
in the process the machine learns the transformation it needs to apply to the incoming data to get the desired output that s knowledge but it may not always be able to communicate how it arrives at the data being thrown out most traditional ml algorithms end up with a mathematical function of the input set if you can extract that function then the machine has done a good job of communicating its knowledge the deep learning algorithm on the other hand is not able to communicate exactly how it works its knowledge is not easily shareable
and that s how we ve managed to outsource so many steps of problem solving to the machine it starts with a problem engages in vigorous trial and error builds an understanding of the process and ends up with a solution
needless to say that the current ml infrastructure is extremely primitive as compared to our mind s problem solving ability but the way it has captured the underlying process is nothing short of miraculous
whether we outsource all steps of problem solving to the machines or keep some parts to ourselves is a matter of design depending upon the time s technological ability check out ibm s cognitive computing initiative for an example of a hybrid machine human approach ultimately both the machine and the mind rely on a very fundamental property the perception of change in their environment and i would like to close this section with a short discussion about this property
it took me a lot of twisted reasoning to finally zero in on the word computation the mind works in amazing ways i knew since the beginning that i wanted computation as the one word attribute for this set of ideas but for a long time i couldn t justify to myself why i would do that hence you might find it irritating how i ve wandered along divergent lines of expression here bear with me while i try to make it fall into place help me with a better description by providing some feedback
intelligence is about problem solving problem solving is about inducing some kind of change inducing change is a form of computation lastly imagining a change is another form of computation distributing apples among kids equally or imagining how you would distribute apples among kids equally would require you to carry out the same process in your head i like to refer to that underlying process as a computation machines do that too a machine s ability to detect a change from to and vice versa is a computation and that forms the basis for its ability to do everything else to is the most fundamental change that a machine is able to bring into effect and the rest builds on top of that
any more abstract exploration would throw us off the overall objective of this article so i would urge the people who want to find out what is it about machines that make them capable of developing intelligence to look into the theory of computation its serene
its true we do if you want to disagree head over to quora there s an entire discussion about it
what is it about ai that spooks people out we ve established two main things about it till now one that we are getting closer and closer to developing the ability to solve harder and harder problems that should be a good thing two we might some day be able to synthesize consciousness artificially and that should give us more knowledge about our own selves what could possibly be worrisome about either of the two developments or what is so difficult to understand that might be scaring people
there are two ways in which humans think via induction and via deduction induction is when we ve seen something in the past similar to what is being witnessed and we re able to generalize and say oh right i know this artificial consciousness has no precedence whatsoever that we can relate it to we genuinely know absolutely nothing about it
deduction is the lesser used way of thinking in which we piece together cause and effect and fill blanks is sequences of logical reasoning with respect to ai people like nick bostrom have been doing so for quite some time and their deductions are disturbing i like deductions too so i would like to present some in the following passage but i would try to keep them as non disturbing as possible
before that just to be clear not everyone is concerned kurzwell s camp is suspiciously optimistic about the future of ai while referring to it as singularity at the same time andrew ng maintains that the kind of fears being raised are way too far fetched and we don t have anything to worry about in our lifetime maybe we have nothing to worry about even about our great grand children s lifetimes but that is not sufficient ground to dismiss an idea as tim urban pointed out people dismiss fears regarding ai as too far away in the future but no one has been able to find any logical counter argument to prove that these fears point to implausible scenarios finally ideas have merits not just in their plausibility but also in how much they can fire your imagination so why not explore
a long time ago we figured that moving things around is way too inconvenient and we need to do something about it initially a plank on a couple of logs was not the perfect looking solution but it worked in some cases to help us move things around as time passed it ended up evolving into technology that now moves us around faster than we can ever move on our own feet trains go like km hr today you go like
fast forward to the present times we re struggling with making machines behave like us computer vision systems are barely able to identify objects from images using the deep learning algorithm this doesn t bother us because the technology is nowhere as good as we are but it doesn t take long for a technology to evolve a computer might not be able to recognize the breadth of objects that we can but it can definitely process what it sees much much faster have a look at this and you would have a better chance of winning against a train than competing with this camera with respect to speed
so we have a proven track record of outperforming ourselves with our creations whatever it is that we mechanize we would end up leaving ourselves far behind eventually we don t understand non linear dynamical systems very well its now widely accepted that we screw up with macro economic decisions because an economy is a complex adaptive system and we re bad with understanding those we are already trying to make the machines understand our world and they will end up outperforming us they would eventually have a much better understanding of our social dynamics than we do in some literature its a blog post i can be that vague it has been suggested that our intelligence might someday compare with machine intelligence just like a mouse s intelligence compares with our intelligence today how empowering
so machines have been surpassing us in the past and they will keep surpassing us in the future it is the question of consciousness that makes things tricky
human beings have a consciousness and are biologically programmed to ensure their survival when machines develop consciousness would they share this goal of self preservation we don t know
what if self preservation is not a matter of being programmed into the machine but turns out to be an emergent property of a complex consciousness somewhere life began as self replicating molecules emerging out of a complex system of interacting chemicals somewhere human consciousness emerged out of a complex system of animal species competing for survival what if the need for survival emerges out of a complex system of artificially conscious beings interacting with each other
to self preserve or not to self preserve
first lets assume that machines have no desire for self preservation here despite consciousness machines develop an important distinction from humans and give up on a critical ability making choices out of self interest self interest guides our decision making more than logic or rationality does it guides our actions and thus our experience and thus the knowledge that we have no two individuals share the exact same knowledge because no two individuals have had the exact same experiences
not only does self interest ensure different knowledge sets for every individual it also limits the amount of knowledge that we are able to share or communicate with other people this might be because a lot of underlying motivations or axioms on top of which we build the rest of our knowledge reside in the section of the mind called our sub conscious and we don t have a particularly good access to that region in general here again there are two possibilities the less exciting possibility is that the nature of consciousness may be such that its subconscious region would be hidden even from the machine in this case the machines would face the same limitation as we do in communicating with other machines the other possibility is that the machine has access to its entire consciousness and thus is able to communicate its entire knowledge base with other machines everything known to one machine is known to every other machine as well in a way there would be no boundaries between the consciousness of two machines you might be surrounded by different kinds of devices performing very different functions the one that irons your clothes will not be driving you around as well but behind their physical incarnations there would be a single consolidated consciousness that has visibility of all events that are being witnessed by each of those machines there s going to be a single ethereal presence all around you in everything that you interact with i don t know about you but to my mind this brings forward just one word the matrix
ok bye
next
now lets look at the other possibility the one in which the machines develop the objective of survival if every conscious machine has the survival instinct and needs to compete with other machines then it may suit them to not share all information among each other sparing us from the matrix this development could further branch out into two different possibilities in the first possibility the machines would think of themselves as separate from humans we might exist in the same ecosystem but they will be them and we would be us it would be like ordinary human beings living among super heroes and mutants all going about their daily business we may not hold a special place in a machine s heart it is ideas like these that start to scare people we get a sense of being dispensable
there is a way out to prevent this from happening and that constitutes the second possibility there might be a way that tomorrow even when an artificial consciousness arises and scales up its intelligence to become super human instead of that consciousness being separate and disconnected from human consciousness it could develop as an extension of human consciousness the machines then won t be separate from us instead as our consciousness evolves and expands into the domain of machines their capabilities would simply be extensions of our own capabilities extended consciousness might be a consumer product or it might end up being a step in our evolutionary path making us what many people like to call transhumans
so which of the above possibilities are going to turn into reality we don t know the answers to such questions yet and its possible that we might not know these answers in advance before consciousness is realized this is the first glimpse of the singularity that ray kurzweil often talks about
it s important to understand what differentiates these ideas from the ones discussed in the previous sections as long as you have an objective that you choose to achieve the ideas and initiatives you take fall in the category of problem solving everything you do to achieve human like consciousness artificially falls in the category of consciousness but when artificial consciousness decides to have its own set of problems to solve in the same environment in which we exist we end up in an ecosystem we can t yet describe this ecosystem should be the focus of these set of ideas and discussions it is difficult to find a sense of purpose in these ideas other than dealing with this super intelligence these conversations need to be not just technical but also philosophical
in conclusion i believe despite the uncertainty accompanying the singularity that there is nothing to suggest that machines in this era would violate the aisenberg principle their knowledge base would grow at a rapid pace but the machines would have their own set of uncertainties and unknowns to deal with if only the machines found a way to wipe out all the unknowns they would become the gods of the universe or the multiverse i don t know obviously
so how do you become a god this segment is primarily for the sake of completeness with respect to the aisenberg principle we ve maintained so far that any form of intelligence that exists in the future would experience things from its environment that it does not know about that epsilon would always be non zero while we do have a scientific basis for the quantum counterpart of this idea heisenberg s uncertainty principle i don t have sufficient scientific theory behind the general principle i ve been using here the aisenberg principle is a belief that i hold and as scientists we are often tempted to question beliefs including our own so in the unlikely event of the principle being violated in a seemingly non existent future there might exist an entity for which epsilon becomes zero in other words the intelligence that is able to achieve zero epsilon would know everything i personally don t get attracted towards thinking about this idea because it swiftly gets very mundane but i invite others who might think otherwise to express themselves here to produce something interesting i m always game for something interesting
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
bigger update the content of this article is now available as a full length video course that walks you through every step of the code you can take the course for free and access everything else on lynda com free for days if you sign up with this link
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in portugu s ti ng vi t or italiano
have you noticed that facebook has developed an uncanny ability to recognize your friends in your photographs in the old days facebook used to make you to tag your friends in photos by clicking on them and typing in their name now as soon as you upload a photo facebook tags everyone for you like magic
this technology is called face recognition facebook s algorithms are able to recognize your friends faces after they have been tagged only a few times it s pretty amazing technology facebook can recognize faces with accuracy which is pretty much as good as humans can do
let s learn how modern face recognition works but just recognizing your friends would be too easy we can push this tech to the limit to solve a more challenging problem telling will ferrell famous actor apart from chad smith famous rock musician
so far in part and we ve used machine learning to solve isolated problems that have only one step estimating the price of a house generating new data based on existing data and telling if an image contains a certain object all of those problems can be solved by choosing one machine learning algorithm feeding in data and getting the result
but face recognition is really a series of several related problems
as a human your brain is wired to do all of this automatically and instantly in fact humans are too good at recognizing faces and end up seeing faces in everyday objects
computers are not capable of this kind of high level generalization at least not yet so we have to teach them how to do each step in this process separately
we need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step in other words we will chain together several machine learning algorithms
let s tackle this problem one step at a time for each step we ll learn about a different machine learning algorithm i m not going to explain every single algorithm completely to keep this from turning into a book but you ll learn the main ideas behind each one and you ll learn how you can build your own facial recognition system in python using openface and dlib
the first step in our pipeline is face detection obviously we need to locate the faces in a photograph before we can try to tell them apart
if you ve used any camera in the last years you ve probably seen face detection in action
face detection is a great feature for cameras when the camera can automatically pick out faces it can make sure that all the faces are in focus before it takes the picture but we ll use it for a different purpose finding the areas of the image we want to pass on to the next step in our pipeline
face detection went mainstream in the early s when paul viola and michael jones invented a way to detect faces that was fast enough to run on cheap cameras however much more reliable solutions exist now we re going to use a method invented in called histogram of oriented gradients or just hog for short
to find faces in an image we ll start by making our image black and white because we don t need color data to find faces
then we ll look at every single pixel in our image one at a time for every single pixel we want to look at the pixels that directly surrounding it
our goal is to figure out how dark the current pixel is compared to the pixels directly surrounding it then we want to draw an arrow showing in which direction the image is getting darker
if you repeat that process for every single pixel in the image you end up with every pixel being replaced by an arrow these arrows are called gradients and they show the flow from light to dark across the entire image
this might seem like a random thing to do but there s a really good reason for replacing the pixels with gradients if we analyze pixels directly really dark images and really light images of the same person will have totally different pixel values but by only considering the direction that brightness changes both really dark images and really bright images will end up with the same exact representation that makes the problem a lot easier to solve
but saving the gradient for every single pixel gives us way too much detail we end up missing the forest for the trees it would be better if we could just see the basic flow of lightness darkness at a higher level so we could see the basic pattern of the image
to do this we ll break up the image into small squares of x pixels each in each square we ll count up how many gradients point in each major direction how many point up point up right point right etc then we ll replace that square in the image with the arrow directions that were the strongest
the end result is we turn the original image into a very simple representation that captures the basic structure of a face in a simple way
to find faces in this hog image all we have to do is find the part of our image that looks the most similar to a known hog pattern that was extracted from a bunch of other training faces
using this technique we can now easily find faces in any image
if you want to try this step out yourself using python and dlib here s code showing how to generate and view hog representations of images
whew we isolated the faces in our image but now we have to deal with the problem that faces turned different directions look totally different to a computer
to account for this we will try to warp each picture so that the eyes and lips are always in the sample place in the image this will make it a lot easier for us to compare faces in the next steps
to do this we are going to use an algorithm called face landmark estimation there are lots of ways to do this but we are going to use the approach invented in by vahid kazemi and josephine sullivan
the basic idea is we will come up with specific points called landmarks that exist on every face the top of the chin the outside edge of each eye the inner edge of each eyebrow etc then we will train a machine learning algorithm to be able to find these specific points on any face
here s the result of locating the face landmarks on our test image
now that we know were the eyes and mouth are we ll simply rotate scale and shear the image so that the eyes and mouth are centered as best as possible we won t do any fancy d warps because that would introduce distortions into the image we are only going to use basic image transformations like rotation and scale that preserve parallel lines called affine transformations
now no matter how the face is turned we are able to center the eyes and mouth are in roughly the same position in the image this will make our next step a lot more accurate
if you want to try this step out yourself using python and dlib here s the code for finding face landmarks and here s the code for transforming the image using those landmarks
now we are to the meat of the problem actually telling faces apart this is where things get really interesting
the simplest approach to face recognition is to directly compare the unknown face we found in step with all the pictures we have of people that have already been tagged when we find a previously tagged face that looks very similar to our unknown face it must be the same person seems like a pretty good idea right
there s actually a huge problem with that approach a site like facebook with billions of users and a trillion photos can t possibly loop through every previous tagged face to compare it to every newly uploaded picture that would take way too long they need to be able to recognize faces in milliseconds not hours
what we need is a way to extract a few basic measurements from each face then we could measure our unknown face the same way and find the known face with the closest measurements for example we might measure the size of each ear the spacing between the eyes the length of the nose etc if you ve ever watched a bad crime show like csi you know what i am talking about
ok so which measurements should we collect from each face to build our known face database ear size nose length eye color something else
it turns out that the measurements that seem obvious to us humans like eye color don t really make sense to a computer looking at individual pixels in an image researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself deep learning does a better job than humans at figuring out which parts of a face are important to measure
the solution is to train a deep convolutional neural network just like we did in part but instead of training the network to recognize pictures objects like we did last time we are going to train it to generate measurements for each face
the training process works by looking at face images at a time
then the algorithm looks at the measurements it is currently generating for each of those three images it then tweaks the neural network slightly so that it makes sure the measurements it generates for and are slightly closer while making sure the measurements for and are slightly further apart
after repeating this step millions of times for millions of images of thousands of different people the neural network learns to reliably generate measurements for each person any ten different pictures of the same person should give roughly the same measurements
machine learning people call the measurements of each face an embedding the idea of reducing complicated raw data like a picture into a list of computer generated numbers comes up a lot in machine learning especially in language translation the exact approach for faces we are using was invented in by researchers at google but many similar approaches exist
this process of training a convolutional neural network to output face embeddings requires a lot of data and computer power even with an expensive nvidia telsa video card it takes about hours of continuous training to get good accuracy
but once the network has been trained it can generate measurements for any face even ones it has never seen before so this step only needs to be done once lucky for us the fine folks at openface already did this and they published several trained networks which we can directly use thanks brandon amos and team
so all we need to do ourselves is run our face images through their pre trained network to get the measurements for each face here s the measurements for our test image
so what parts of the face are these numbers measuring exactly it turns out that we have no idea it doesn t really matter to us all that we care is that the network generates nearly the same numbers when looking at two different pictures of the same person
if you want to try this step yourself openface provides a lua script that will generate embeddings all images in a folder and write them to a csv file you run it like this
this last step is actually the easiest step in the whole process all we have to do is find the person in our database of known people who has the closest measurements to our test image
you can do that by using any basic machine learning classification algorithm no fancy deep learning tricks are needed we ll use a simple linear svm classifier but lots of classification algorithms could work
all we need to do is train a classifier that can take in the measurements from a new test image and tells which known person is the closest match running this classifier takes milliseconds the result of the classifier is the name of the person
so let s try out our system first i trained a classifier with the embeddings of about pictures each of will ferrell chad smith and jimmy falon
then i ran the classifier on every frame of the famous youtube video of will ferrell and chad smith pretending to be each other on the jimmy fallon show
it works and look how well it works for faces in different poses even sideways faces
let s review the steps we followed
now that you know how this all works here s instructions from start to finish of how run this entire face recognition pipeline on your own computer
update you can still follow the steps below to use openface however i ve released a new python based face recognition library called face recognition that is much easier to install and use so i d recommend trying out face recognition first instead of continuing below
i even put together a pre configured virtual machine with face recognition opencv tensorflow and lots of other deep learning tools pre installed you can download and run it on your computer very easily give the virtual machine a shot if you don t want to install all these libraries yourself
original openface instructions
if you liked this article please consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
interested in computers and machine learning likes to write about it
update we have released a new report describing our proposal for algorithmic impact assessments in full detail the report describes how affected communities and stakeholders can use our framework to assess the use of ai and algorithmic decision making in public agencies and determine where or if their use is acceptable
in the coming months nyc mayor bill de blasio will announce a new task force on automated decision systems the first of its kind in the united states the task force will recommend how each city agency should be accountable for using algorithms and other advanced computing techniques to make important decisions as a first step toward this goal we urge the task force to consider a framework structured around algorithmic impact assessments aias
automated decision systems are here and are already being integrated across many core social institutions reshaping how our criminal justice system works via risk assessment algorithms and predictive policing systems optimizing energy use in critical infrastructure through ai driven resource allocation and changing our educational system through new teacher evaluation tools and student school matching algorithms and these are merely what journalists researchers and the public record expose to date no city in the us has explicitly mandated that its agencies disclose anything about the automated decision systems they have in place or are planning to use
while these systems are already influencing important decisions there is still no clear framework in the us to ensure that they are monitored and held accountable indeed even many simple systems operate as black boxes as they are outside the scope of meaningful scrutiny and accountability this is worrying if governments continue on this path they and the public they serve will increasingly lose touch with how decisions have been made thus rendering them unable to know or respond to bias errors or other problems the urgency of this concern is why ai now has called for an end to the use of black box systems in core public agencies black boxes must not prevent agencies from fulfilling their responsibility to protect basic democratic values such as fairness and due process and to guard against threats like illegal discrimination or deprivation of rights
with this in mind and drawing on several ongoing research efforts ai now is proposing an early stage framework centered on algorithmic impact assessments aias this broad approach complements similar domain specific proposals like andrew selbst s recent work on algorithmic impact statements in the context of predictive policing systems these frameworks in turn draw on the history and development of assessments in other areas such as environmental policy privacy law and data protection in the eu and build on growing and important research that scientific and policy experts have been developing on the topic of algorithmic accountability aias begin to shed light on these systems helping us to better understand their use and to determine where they are and aren t appropriate both before they are deployed and on a recurring basis when they are actively in use
aias strive to achieve four initial goals
a fundamental aspect of government accountability and due process is notice of how our rights are being affected and by which government agencies and actors when automated systems play a significant role in government decisions they should be disclosed
thus as a first step algorithmic impact assessments would require each agency to publicly list and describe all existing and proposed automated decision systems including their purpose reach and potential impacts on identifiable groups or individuals this requirement by itself would go a long way towards shedding light on which technologies are being deployed to serve the public and where accountability research should be focused similar provisions are already part of laws in the u s such as the privacy act of and have been proposed in emerging local ordinances such as one in santa clara county and another in oakland that are focused on privacy
of course in order to make disclosure meaningful automated decision making must be defined in ways that are both practical and appropriate an overly broad definition could burden agencies with disclosing systems that are not the main sources of concern if a public servant uses a word processor to type up her notes from a meeting where some key decisions were made and then checks them with the program s automated spell checker her agency should not have to perform an aia for that spell checker on the flipside an overly narrow definition could undermine efforts to include high profile systems like those deciding which students are admitted to specialized high schools or how housing opportunities are allocated
it is also essential that systems are defined in terms that are broader than just their software aias should cover human factors too along with any input and training data bias in automated decision systems can arise as much from the human choices on how to design or train the system as they can from human errors in judgment when interpreting or acting on the outputs evaluating a predictive policing system for instance is not just a matter of understanding the math behind its algorithm we must also understand how officers dispatchers and other decision makers take its outputs and implement them in both policy and everyday practices
to ensure that we draw an appropriate boundary around automated decision systems algorithmic impact assessments must set forth a reasonable and practical definition of automated decision making this process of defining and specifying such systems would help build agency capacity for the procurement and assessment of future systems as experience with aias would help guide requests for proposals budgeting and other key milestones
crucially agencies would not be working alone to create these definitions in order for aias to be effective agencies must publish their definition as part of a public notice and comment process whereby individuals communities researchers and policymakers could respond and if necessary challenge the definition s scope this would allow push back when agencies omit essential systems that raise public concerns
consider the example of an education agency a reasonable agency s definition should include an automated decision system such as the educational value added assessment system used by many jurisdictions for automated teacher evaluations we might expect that the text of that agency s definition would include something like the systems tools or statistical models used to measure or evaluate an individual teacher s performance or effectiveness in the classroom in a criminal justice agency similar wording might yield a definition that includes systems tools or statistical models used to measure or evaluate an individual criminal defendant s risk of reoffending
a definition that focuses on individual profiling has a precedent in the eu s general data protection regulation gdpr automated profiling is defined as any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person in particular to analyse or predict aspects concerning that natural person s performance at work economic situation health personal preferences interests reliability behaviour location or movements
the gdpr language may be a good starting point but will require some shaping to match the appropriate contexts and in other contexts it may not be sufficient some predictive policing tools for example don t necessarily constitute profiling individuals and instead focus on locations using statistics to try to understand and predict crime trends with the potential for disparate impact a definition might then have to account for any systems tools or algorithms that attempt to predict crime trends and recommend the allocation of policing resources in non individualized terms in general any definition should be sure to cover systems that might have a disparate impact on vulnerable communities and to pay careful attention to how broad terms like automated processing are specified in practice
after internal agency processes work to publicly disclose existing or proposed systems algorithmic impact assessments should provide a comprehensive plan for giving external researchers meaningful access to examine specific systems and gain a fuller account of their workings while certain individuals and communities may wish to examine the systems themselves it would be unreasonable to expect that everyone has the time knowledge and resources for such testing and auditing automated decision systems can be incredibly complex and issues like bias and systematic errors may not be easily determined through the review of systems on an individual case by case basis a plan to grant meaningful access would allow individuals and communities to call upon the trusted external experts best suited to examine and monitor a system and to assess whether there are issues that might harm the public interest
to do this well it s important to recognize that the appropriate type and level of access may vary from agency to agency from system to system and from community to community the risks and harms at issue in different systems may demand different types of research across different disciplines while the right to an explanation concerning a specific automated decision could prove useful in some situations as it is suggested in the gdpr framework many systems may require a group level or community wide analysis for example an explanation for a single stop and frisk incident would not reveal the greater discriminatory pattern that the policy created in nyc where over of those stopped were black or latino men
other systems may only require analysis based on inputs and outputs without needing access to the underlying source code we believe that the best way for agencies to develop appropriate research access programs initially would be to work with affected communities and interdisciplinary researchers through the notice and comment process importantly given changing technologies the developing research field around accountability and the shifting social and political contexts within which systems are deployed access to a system will almost certainly need to be ongoing and take the form of monitoring over time
ongoing monitoring and research access would also allow agencies and researchers to work together to develop their approaches to testing the research around algorithmic accountability is young we do not yet know what future tools and techniques might best keep systems accountable external researchers from a wide variety of disciplines will need the flexibility to adapt to new methods of accountability as new technologies drive new forms of automating decisions
to effectuate external research access public agencies will also need to commit to accountability in both their internal technology development plans as well as vendor and procurement relationships for example meaningful access to automated decision systems will not be practical or feasible if essential information about the system can be shielded from review by blanket claims of trade secrecy agency aias commit each agency to ensuring meaningful review of these systems therefore agencies may need to require potential vendors to waive restrictions on information necessary for external review for example at minimum vendors should be contractually required by agencies to waive any proprietary or trade secrecy interest in information related to accountability such as those surrounding testing validation and or verification of system performance and disparate impact
of course there is also a real danger that relying on external auditing will become an unfunded mandate on researchers to check automated decision systems however there are models that legislation could adopt to address this an aia framework could fund an independent government wide oversight body like an inspector general s office to support the research and access or funding could be set aside for the compensation of external auditors fortunately there are many options that jurisdictions could consider for their own needs and a growing community of computer scientists journalists and social scientists have already proven there is an appetite for research into public automated systems
access for external researchers is a crucial component of algorithmic accountability but in parallel we need to increase the internal capacity of public agencies to better understand and explicate potential impacts before systems are implemented agencies must be experts on their own automated decision systems if they are to ensure the public trust that s why agencies algorithmic impact assessments must include an evaluation of how a system might impact the public and show how they plan to address any issues should they arise
this is an opportunity for agencies to develop expertise when commissioning and purchasing automated decision systems and for vendors to foster the public trust in their systems agencies will be better able to assess the risks and benefits associated with different types of systems and work with vendors to conduct and share relevant testing and research on their automated decision system including but not limited to testing for any potential biases that could adversely impact an individual or group interest and any other validation or verification testing conducted as noted above if some vendors raise trade secrecy or confidentiality concerns those can be addressed in the aia but responsibility for accountability ultimately falls upon the public agency
aias would also benefit vendors that prioritize fairness accountability and transparency in their offerings companies that are best equipped to help agencies and researchers study their systems would have a competitive advantage over others cooperation would also help improve public trust especially at a time when skepticism in the societal benefits of tech companies is on the rise these new incentives encourage a race to the top of the accountability spectrum among vendors
increasing agency expertise through aias will also help promote transparency and accountability in public records requests today when agencies receive open records requests for information about algorithmic systems there is often a mismatch between how the outside requestor thinks agencies use and classify these technologies and the reality as a result requests may often take a scattershot approach cramming overly broad technical terms into numerous requests in the hopes that one or more hit the mark this can make it difficult for records officers responding in good faith to understand the request let alone provide the answers the public needs
even open records experts who are willing to reasonably narrow their requests may be unable to do so because of the lack of any roadmap showing which systems a given agency is planning procuring or deploying for example in a project out of the university of maryland faculty and students working in a media law class filed numerous general public records requests for information regarding criminal risk assessment usage in all fifty states the responses they received varied significantly making it difficult to aggregate data and compare usage across jurisdictions it also revealed a lack of general knowledge about the systems among the agencies leading to situations where the students had to explain what criminal justice algorithms were to the public servants in charge of providing the records on their use
accountability processes such as the aia would help this mismatch on both sides of the equation researchers journalists and concerned members of the public could use the algorithmic impact assessments to reasonably target their requests to systems that were enumerated and described saving public records staff significant time and resources agency staff would also gain a better handle on their own systems and records and could then help requestors understand which documents and public records are potentially available this alignment would increase efficiency lower the agency burden of processing requests and increase public confidence
agencies could also use the aia as an opportunity to lay out any other procedures that will help secure public trust in such systems if appropriate the agency might want to identify how individuals can appeal decisions involving automated decision systems to make clear what appeals processes might cover a given system s decision or to share its mitigation strategy should the system behave in an unexpected and harmful way the benefits to public agencies of self assessment go beyond algorithmic accountability it encourages agencies to better manage their own technical systems and become leaders in the responsible integration of increasingly complex computational systems in governance
the aia process provides a much needed basis for evaluating and improving agency systems but without oversight aias could become simply a checkbox for agencies to mark off and forget that s why the algorithmic impact assessment process should also provide a path for the public to pursue cases where agencies have failed to comply with the algorithmic impact assessment requirement or where serious harms are occurring for example if an agency fails to disclose systems that reasonably fall within the scope of those making automated decisions or if it allows vendors to make overboard trade secret claims and thus blocks meaningful system access the public should have the chance to raise concerns with an agency oversight body or directly in a court of law if the agency refused to rectify these problems after the public comment period
as the nyc task force embarks on its study we hope the algorithmic impact assessment framework can serve as a productive foundation in defining meaningful algorithmic accountability the task force will be a great opportunity for the public and city agencies to come together to make new york the fairest big city in america that s why we hope the mayor calls on city agencies to help the task force understand the automated decisions that shape new yorkers lives
we will be publishing further research on this model in the coming months and welcome any and all feedback to develop it and as more jurisdictions take the same first steps new york city has we hope aias will give other communities a useful starting place from which to better understand the systems impacting them and to design and deploy their own approaches to meaningful algorithmic oversight and accountability
thank you to chris bavitz hannah bloch wehba ryan calo danielle citron cassie deskus rachel goodman frank pasquale rashida richardson andrew selbst vincent southerland and michael veale for their helpful comments on the aia framework and this post
europe has already been developing approaches under various long standing directives and conventions and the more recent general data protection regulation gdpr while the massachusetts legislature has taken up similar questions but with a bill focused specifically in the criminal justice context
see generally citron danielle keats technological due process wash ul rev edwards lilian and michael veale slave to the algorithm why a right to an explanation is probably not the remedy you are looking for duke l amp tech rev brauneis robert and ellen p goodman algorithmic transparency for the smart city citron danielle keats and frank pasquale the scored society due process for automated predictions wash l rev selbst andrew d and julia powles meaningful information and the right to explanation international data privacy law no diakopoulos nicholas algorithmic accountability the investigation of black boxes tow center for digital journalism barocas solon and andrew d selbst big data s disparate impact cal l rev crawford kate and jason schultz big data and due process toward a framework to redress predictive privacy harms bcl rev
some have argued that the gdpr s actual definition which says that people have the right not to be subject to decisions based on decisions made solely by automated processing introduces a loophole for systems that have any degree of human intervention recently released guidelines on gdpr have attempted to adjust for this by requiring that human intervention be meaningful rather than a token gesture and requiring that data controllers discuss human involvement in their data protection impact assessments
https gdpr info eu art gdpr
the original draft of int relied on a transparency approach directed towards individuals allowing individuals to audit decisions made using their own personal information though there may be benefit to an individual having that access it is insufficient to uncovering larger systemic issues see for example ananny m amp crawford k seeing without knowing limitations of the transparency ideal and its application to algorithmic accountability new media amp society
there might be privacy or security concerns related to making community or group level data available to researchers working out protocols for appropriate disclosures and access controls for researchers will be important for the stakeholders in this process
in line with our past recommendations we need a definition of external researchers that includes people from beyond computer science and engineering it should effectively include at minimum university researchers from a broad array of disciplines civil society organizations who can represent the interests of relevant communities and journalists this and other parts of our framework will be treated in our future work
see for example the conference on fairness accountability and transparency fat
we see this process as analogous the us process for managing the potential environmental impacts made by federal agencies under the national environmental policy act federal agencies must conduct a brief environmental assessment of a proposed action or if necessary create a longer environmental impact statement which the public can challenge before the action takes place a similar process should take place before an agency deploys a new high impact automated decision system ideally agencies would welcome and facilitate this process by identifying stakeholders ahead of time and conducting consultations on critical questions and concerns then after incorporating these concerns in a public notice any unresolved concerns could be raised during the comment process
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
researching the social implications of artificial intelligence now to ensure a more equitable future
deduction given the rule and the cause deduce the effect
induction given a cause and an effect induce a rule
abduction given a rule and an effect abduce a cause
taxonomy
what parameters structure hidden concepts
what from supervised unsupervised reinforcement
what for prediction diagnostics summarization
how passive active online offline
outputs classification regression
details generative discriminative
occom s razor everything else being equal choose the less complex hypothesis
the ultimate goal of machine learning is to have data models that can learn and improve overtime
evaluation metrics
learn from data to make predictions
classification and regression
classification is about deciding which categories new instances belong to then when we see new objects we can use their features to guess which class they belong to
in regression we want to make a prediction on continuous data
in classification we want to see how often a model correctly or incorrectly identifies a new example whereas in regression we might be more interested to see how far off the model s prediction is true from true value
classification accuracy precision recall and f score
regression mean absolute error and mean square error
short comings of accuracy
causes of error
bias due to a model being unable to represent the complexity of the underlying data
variance due to a model being overly sensitive to the limited data it has been trained on
bias occurs when a model has enough data but is not complex enough to capture the underlying relationships as a result the model consistently and systematically misrepresents the data leading to low accuracy in prediction this is known as underfitting to overcome error from bias we need more complex model
variance is a measure of how much the predictions vary for any given test sample high sensitivity to the training set is also known as overfitting occurs when the model is too complex
we can typically reduce the variability of a model s predictions and increase precision by training on more data if more data is unavailable we can also control variance by limiting our model s complexity
data types
curse of dimensionality
as the number of features or dimensions grows the amount of data we need to generalize accurately grows exponentially
learning curves
bias when the training and testing errors converge and are quite high this usually means the model is biased
variance w hen there is a large gap between the training and testing error this generally means the model suffers from high variance
alright that s it for now thank you for spending your time cheers
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
machine learning and blockchain bengaluru india
an intuitive way to understand the relation between the agent and its environment is with the following example
environment you are in state you have possible actions agent i ll take action environment you received a reinforcement of units you are in state you have possible actions
the agent s job is to find a policy mapping states to actions that maximizes some long run measure of reinforcement we assume the environment is stationary
important ideas in reinforcement learning that came up
alright that s it for now thank you for spending your time cheers
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
machine learning and blockchain bengaluru india
this post covers the second and final day of the deep learning summit that took place in london on september th th you can find the first post here videos are also being posted on youtube
after a welcome from alison lowndes of nvdia the day started with the startup session
first up were wally trenholm founder amp ceo and jason cassidy md amp chief science officer of sightline innovation talking about the commercialisation of deep learning they started going after military customers then looked for other markets due to long military order process year to order they first took what had been developed in image analysis on geo scale satellite uav and applied it to agriculture then to serve even more customers they went from geo scale to macro scale images addressing industrial problems automated manufacturing quality control next they will go further down and apply their image analysis to nano scale genomic there is a mlaas machine learning as a service term for which they hold the copyright platform which will be released next month with a server on site to collect and preprocess the data and also provide reporting and dashboards while algorithm training and prediction will be done on their cloud in case you are looking clarify is hiring
next up was paul murphy ceo of clarify on deep learning amp speech adaptation the next frontier with some funny cartoonish slides clarify started in london and now texas based provides an api that analyses audio and video making it searchable the main issue with speech is adaptation as also discussed by s bastien brati res in the last session of the first summit day there are different adaptation problems like speaker adaptation ex accents speaker may not be native while most of the training data is native and male noise and tenuation moving away from the microphone the bleeding edge in speech recognition research is
then came appu shaji head of r amp d at eyeem talking about deep learning for real photography eyeem is a social network for photography one of the goals appu is to improve content discovery helping photographers being found and selling more photos he showed eyevision which is currently in early access the engine assesses aesthetic quality of the photo and also tags them with k concepts using data coming from both community and expertly curated tagging they are using cnns with word embeddings based on these research papers paper paper paper
john overington director of bioinformatics at stratified medical followed with artificial intelligence in drug discovery john said that currently drug discovery is extremely expensive and unpredictable r amp d expenses for a single approved drug range from billion to billion source he brought his experience on drug discovery to stratified medical which is developing their own drug pipeline the goal is to use ai to filter down potential molecules accelerating discovery and reducing costs they are building a knowledge graph using data from structured sources molecule databases vocabularies and unstructured data papers patents etc the latter being extracted with nlp techniques they will also leverage new public datasets such as uk k the genome sequencing data of k people which will help uncover rare variants contributing to diseases they are making progress they achieved key milestones in a multimillion partnered alzheimer s program
the last talk of the startup session was given by marius cobzarenco co founder amp cto of re infer on building conversational interfaces with deep nets marisu said they are building business bots that collect data from different systems slack crm wiki etc and are able to answer natural queries currently it is hard to understand intent and context there is active research on embeddings done for example by geoff hinton on deep thoughts at google they are using cnns to find embeddings they found this dnns to be faster to train compared to rnns and at the same time gives good results they also use dl for named entity recognition you still need to extract entities to translate the intent into actions
the second part of the morning was on deep learning applications
david plans ceo and davide morelli cto of biobeats talked about machine intelligence for the essential self their initial work was on neural networks in creativity releasing an app called pulse that generates music based on the heartbeat with the pulse app they collected a large cardiovascular dataset enhanced by information coming from sensor data accelerometer gps gyro etc now they pivoted and use this information to train models for people wellness david who also gave a terrific talk during the summit dinner the night before said we are constantly under stress as a result we live in sympathetic mode fight or flight with our body acting as if we were in a jungle facing a lion in the long run it damages our health and may result in premature death but with interventions we can be brought back to living in the much saner parasympathetic mode feed and rest couple this with the fact that of company healthcare spending is on preventable chronic diseases they are bringing their system inside organisations collaborating with bupa axa and samsung to predict employee stress and fatigue levels and take action before it is too late they also have a couple of public apps in beta testing
in the last part of the speech davide talked about their technology where there are several challenges like understanding if the stress is good eg you re happy or bad there are some indicators for example under bad stress the heartbeat becomes more regular plus heartbeat information can be correlated with activity ex you are not moving and the heartbeat suddenly becomes regular and info coming from social networks to label datasets on top of that they need to manage large datasets each user generates mb day without killing batteries and exhausting user data plans their solution is to extract features locally send them to the server where models are trained then send back the trained model and make predictions on the device the api sdk will be released by end of the year they concluded saying that the most important open challenges are ethical on bringing emotional intelligence to the algorithms so that interventions are beneficial for the user receiving them and don t cause additional stress
i then attended the parallel session on investing in ai it started with a panel made of vcs nathan benaich of playfair capital john henderson of white star capital simon king of octopus investments together with alex dalyac co founder amp ceo of tractable and moderated by sally davies of financial times most of the discussion has been on how to evaluate an ai startup here are some aspects being considered
they agreed that the acquisition of deepmind by google is a very important signal for europe before us companies tended to buy only us startups this opens new exit possibilities for european startups making them more attractive to vcs
after a very good lunch break the afternoon started with alex matei mhealth manager and ekaterina volkova volkmar researcher of bupa on deep learning for digital health bupa is an international healthcare group whose activity span from hospitals to company health insurance they showed an interesting series of proof of concept
i really appreciated their approach using available software api for fast prototype development they also showed some good practices like defining at the start of each project the evaluation criteria for deciding which software api to use example criteria what is the software api potential to scale how does the costs grow in case of large deployments
rodolfo rosini cto of weave ai came after the presentation was not very informative they seem to be in stealth mode their idea is to use contextual information to provide improved search he also talked about aggregating corporate information and making it easily searchable something similar to what re infer was talking about in the morning
joerg bornschein global scholar at cifar followed with a talk on combining directed amp undirected generative models joerg talk was about unsupervised learning where the progress has not been as impressive as in supervised learning and there are yet less real world application nevertheless it might help us to understand how the brain works and it will enable new applications where machines generate content joerg presented his work on training bidirectional helmholtz machines paper helmholtz machines hms are made of a generative model coupled with an auxiliary model which performs approximate inference joerg presented a new way to train the hms where probabilities of both models are interpreted as approximate inference distributions and the goal is to minimise the difference between the distributions he showed some examples of the algorithms in action where they reconstruct digits and faces with missing parts
the last talk of the summit was given by marie francine moens professor at ku leuven on learning representations for language understanding experiences from the muse project muse which stands for machine understanding for interactive storytelling is working on algorithms that translate text into virtual worlds applications include rendering children s stories and providing patient guidelines ex foreigners in a hospital as d virtual worlds the algorithms play a double role
the main difficulties come from having very few annotated training datasets for which they are researching into using other data sources like language models to improve results there is also a lack of world knowledge ex practice with a spear gt the spear is held in the hand so they are working on multimodal deep learning using both images and phrases to acquire more knowledge
that concluded the deep learning summit london the organisation by the re work team nikita pip sophie was great the summit had a positive mix of industry and research talk and it was a terrific opportunity to network and get to know lots of interesting people in the deep learning field coming up are the san francisco summit and then europe again highly recommended
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
ceo and chief data scientist at optimist ai bringing innovation to sales through big data the future is bright
python is one of the most popular programming languages the reason in its universality because it is a multi tool with the ability to sharpen for a variety of needs today i publish a compilation with a description of useful for the data scientist and expert on ai tools
machine learning neural networks big data are an increasingly growing trend which means that more and more specialists are needed the syntax of python is mathematically accurate so that it is understood not only by programmers but also by all who are connected with the technical sciences that s why so many new tools are being created in this language
but enough to describe the merits of python let s get down to our collection at last
shogun is qualitatively documented among the shortcomings can be called the relative complexity of working with the api it is distributed free of charge
the four basic principles underlying the keras philosophy are user friendliness modularity extensibility and compatibility with python among the shortcomings can be called a relatively slow speed of work compared to other libraries
the above tools are almost ideal for scientists programmers and anyone who is involved with machine learning and large data and of course it s worth remembering that these tools are sharpened by python
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
it entrepreneur web developer seo expert it adviser a founder of www smartspate com you can reach me out at alexmaison me
with artificial intelligence proving to be the next big thing current tech giants seem to be leaving nothing to chance when it comes to aligning themselves with what appears to be the looming future of the technology space for instance intel has been on an ai acquisition spree in recent times having made various purchases including movidius mobileeye and nervana what s more the company recently announced the purchase of vertex ai a seattle based startup that is involved in the building of a platform agnostic ai model suite according to a note posted on intel s website vertex ai will become the latest addition to the company s ai products group whereby it is expected to provide support to a wide array of hardware it is also anticipated to incorporate plaidml which is the chipmaker s multi language acceleration platform intended to help developers in deploying ai models on windows macos and linux devices particularly with its ngraph machine learning backend in the acquisition announcement intel said that vertex ai s seven person team would join the movidius team specifically in the chipmaker s artificial intelligence products group thanks to this acquisition intel has gained not only an experienced team but also ip to boost flexible deep learning at the edge additional terms and details pertaining to the entire deal were not disclosed vertex ai was founded back in by both choong ng and jeremy bruestle with the intention of building a framework that eliminated the existing gap between hardware and ai powered software the company lured seed money from various investors including toronto a canada based creative destruction lab and curious capital just to mention a few ng stated on the eve of vertex ai s launch in that current gpus and cpus are efficient and powerful enough for numerous intelligent applications however he added that the benefits of such systems do not go beyond that point in fact ng said that the lack of developer friendly and portable tools keeps most organizations from fully benefiting from the power of deep learning technology according to ng a year ago his company figured out a way that it could solve the portability and compatibility issues simultaneously for all platforms through a new software technique this approach calls for rethinking how the startup implements its algorithms and even though it has been an impediment to engineers ng stated the payoff justifies the struggle for intel the acquisition of vertex ai marks another step for the company as far as trying to capture the billion ai market is concerned its acquisition of altera delivered field programmable gate array into its vast product lineup whereas the purchase of nervana and movidius improved its real time processing portfolio importantly the former s neural network processor which is anticipated to start production in late can reportedly provide a maximum of times the ai training performance associated with competing graphics cards intel s executive vp navin shenoy said at the chipmaker s recent data centric innovation summit that after years its ai acquisitions present the largest opportunity for the company in fact he added that the company currently holds of the ai market source venturebeat
read the full article
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
algorithm x lab is a leading media and events platform dedicated to covering the latest artificial intelligence news amp insights
artificial intelligence ai is the convenient future it is one of the most promising and transformative opportunities of our time we are closer to the near future where virtual assistants bots and software agents will act more and more like people
some the biggest advances in ai are being developed inside tech giants such as google deep mind and ibm watson but there are still a lot of great opportunities for young startups to explore
related the near future of ai the road to super intelligent apps and machines
more than private companies working to advance artificial intelligence technologies have been acquired in the last years by corporate giants competing in the space including google amazon apple ibm yahoo facebook intel and more recently salesforce according to cb insights
ai will play a huge role in the near future and some of these startups are already developing apps that could help shape the future of ai there are still plenty of opportunities to exploit
and while technology giants are fighting over ai dominance these startups have made a lot of progress
x ai is an artificial intelligence driven personal assistant who schedules meetings for you
legal robot helps with understanding complex legal language using ai without the cost associated with it
the grid uses ai to build and customize your website for you billing itself as your personal ai web developer
metamind wants to make deep learning a set of techniques that don t require domain experts to program knowledge into algorithms accessible to everyone
sense is a b b predictive intelligence engine for marketing and sales it accelerates sales by finding buyers at every stage of the funnel
enlitic uses deep learning and image analysis to help doctors make diagnoses and spot abnormalities in medical images
persado is a cognitive content platform for marketers persado s products and technology generates language that inspires action and increases roi
quid is a platform that searches analyzes and visualizes the world s collective intelligence to help answer strategic questions
radiumone builds intelligent software that automates media buying making big data actionable for marketers and connects them to their next customer
gridspace has created an application based on technology that automatically saves and indexes meeting conversations
weave ai building an alternative to google now that can mine tweets for context and bring up relevant data in other apps on your phone
wit ai is an api that makes it easy for developers to create applications or devices that you can talk to
mobvoi is a chinese artificial intelligence ai company specializing in mobile voice technology
crowdflower is focused on making data useful by helping data teams collect clean and label their data at scale
mindmeld enables you to add intelligent natural language voice search to any content driven mobile app or website
mintigo helps marketing leaders to discover target and engage buyers faster with predictive marketing
sense ly is an avatar based emotively driven clinical platform virtual nurse that helps clinicians better manage their chronic care patients
botanic io designs and builds products which are capable of understanding and responding to human speech
enlitic is a deep learning healthcare company ushering in a new era of data driven medicine
scaled inference is enabling a new generation of intelligent software built by the masses and powered by an open shared platform
appier is a technology company that makes it easy for businesses to use artificial intelligence to grow and succeed in a cross screen era
harvest ai identifies and stops data breaches from targeted attacks insider threat amp stolen credentials in near real time security nerds that love design
banjo is building the world s first disaster prediction engine the company s dream is to make terrorism impossible
idibon s cloud based natural language processing services enable organizations to efficiently structure and organize their language data
statustoday analyses behavior in the context of humans and their intended actions to protect you and your company
wise io provides machine learning models that enable companies to optimize the customer experience
kasisto augments mobile financial applications by enabling intelligent conversations using the perfect mix of speech text and touch interfaces
the author is the founding editor at alltopstartups tools resources and ideas for launching and growing a startup
he is also the curator at postanly a weekly newsletter that delivers the most insightful long form posts from top publishers here is what subscribers received last week
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
writer thinker creator at thinkinginmodels co curator at postanly com columnist at inc magazine featured at business insider forbes entrepreneur etc
most of the time we do have a common problem to increase the accuracy in a model for a given data set it is hard because when it comes to implementation we try to do all things using a single model which is not optimal for some scenarios for example let s assume that there is a categorical feature called gender and some other features when we try to train the whole data set at once this categorical feature might have a huge impact on the variance of other variables which can results an unstable model because model cannot converge men s behavior and women s behavior together using a single approach
so to address this kind of a problem sometimes it is better to treat these categories separately and check for the accuracy divide the data set based on gender and remove the gender feature from both data sets apply different models for both men s and women s data separately maybe they might good in different models if men s data has more linear relationship then a linear model will quite fit for the scenario if women s data does not show a linear relationship then decision tree type algorithm might good for that particular case even may be the same model with different hyper parameters could make a difference
finally we have to do predictions when we have to do the predictions we have to manually check for the feature that we used to separate the data set and navigate each data point to relevant model and get the predictions
sometimes there can be disadvantage when there is a class imbalance problem if we have more men s data rather than women s data then there will be a problem in training a model for women s data so it is better to have fair amount of data for both models and should be sufficiently balanced
maybe we might have taken a wrong feature to separate the data set which does not have a strong impact on the output in that case we just increase the complexity of our implementation
so test it do it only if it is required
from a quick cheer to a standing ovation clap to show how much you enjoyed this story
software engineer at sysco labs computer science amp engineering graduand at university of moratuwa
artificial intelligence will never have what is not downloaded into it robot or some other form i just read an article that stated an ai was becoming a citizen just like i heard a while back ago two ai s made up their own language to communicate rubish or maybe its wishful thinking that man can create and be a creator of the artificial intelligence and make it think by itself
this isn t possible though not truely not realistically
just more scifi for the imagination which is a feeding frenzy eyesore
theres a lot of misinformation out there just look at orsen wells radio version of war of the world how many supposedly committed suicide thinking it was real
we humans have a knack for the dramatic the eeriness of scary things happening and ruling over us or killing us some hope it does become reality
there lies the delima
software engineer
at the end of all eyes were on the year s accomplishments as well as forecasting technology trends of and beyond one particular field that has frequently been in the spotlight during the last year is deep learning an increasingly popular branch of machine learning which looks to continue to advance further and infiltrate into an increasing number of industries and sectors here are a list of deep learning libraries and frameworks that will gain momentum in
theano is a python library for defining and evaluating mathematical expressions with numerical arrays it makes it easy to write deep learning algorithms in python on the top of the theano many more libraries are built
keras is a minimalist highly modular neural network library in the spirit of torch written in python that uses theano under the hood for optimized tensor manipulation on gpu and cpu
pylearn is a library that wraps a lot of models and training algorithms such as stochastic gradient descent that are commonly used in deep learning its functional libraries are built on top of theano
lasagne is a lightweight library to build and train neural networks in theano it is governed by simplicity transparency modularity pragmatism focus and restraint principles
blocks a framework that helps you build neural network models on top of theano
caffe is a deep learning framework made with expression speed and modularity in mind it is developed by the berkeley vision and learning center bvlc and by community contributors google s deepdream is based on caffe framework this framework is a bsd licensed c library with python interface
nolearn contains a number of wrappers and abstractions around existing neural network libraries most notably lasagne along with a few machine learning utility modules
gensim is deep learning toolkit implemented in python programming language intended for handling large text collections using efficient algorithms
chainer bridge the gap between algorithms and implementations of deep learning its powerful flexible and intuitive and is considered as the flexible framework for deep learning
deepnet is a gpu based python implementation of deep learning algorithms like feed forward neural nets restricted boltzmann machines deep belief nets autoencoders deep boltzmann machines and convolutional neural nets
hebel is a library for deep learning with neural networks in python using gpu acceleration with cuda through pycuda it implements the most important types of neural network models and offers a variety of different activation functions and training methods such as momentum nesterov momentum dropout and early stopping
cxxnet is fast concise distributed deep learning framework based on mshadow it is a lightweight and easy extensible c cuda neural network toolkit with friendly python matlab interface for training and prediction
deeppy is a pythonic deep learning framework built on top of numpy
deeplearning is deep learning library developed with c and python
neon is nervana s python based deep learning framework
convnet convolutional neural net is a type of deep learning classification algorithms that can learn useful features from raw data by themselves and is performed by tuning its weighs
deeplearntoolbox is a matlab octave toolbox for deep learning and includes deep belief nets stacked autoencoders convolutional neural nets
cuda convnet is a fast c cuda implementation of convolutional or more generally feed forward neural networks it can model arbitrary layer connectivity and network depth any directed acyclic graph of layers will do training is done using the backpropagation algorithm
matconvnet is a matlab toolbox implementing convolutional neural networks cnns for computer vision applications it is simple efficient and can run and learn state of the art cnns
eblearn is an open source c library of machine learning by new york university s machine learning lab led by yann lecun in particular implementations of convolutional neural networks with energy based models along with a gui demos and tutorials
singa is designed to be general to implement the distributed training algorithms of existing systems it is supported by apache software foundation
nvidia digits is a new system for developing training and visualizing deep neural networks it puts the power of deep learning into an intuitive browser based interface so that data scientists and researchers can quickly design the best dnn for their data using real time network behavior visualization
intel deep learning framework provides a unified framework for intel platforms accelerating deep convolutional neural networks
n dimensional arrays for java nd j is scientific computing libraries for the jvm they are meant to be used in production environments which means routines are designed to run fast with minimum ram requirements
deeplearning j is the first commercial grade open source distributed deep learning library written for java and scala it is designed to be used in business environments rather than as a research tool
encog is an advanced machine learning framework which supports support vector machines artificial neural networks genetic programming bayesian networks hidden markov models genetic programming and genetic algorithms are supported
convnet js is a javascript library for training deep learning models mainly neural networks entirely in a browser no software requirements no compilers no installations no gpus no sweat
torch is a scientific computing framework with wide support for machine learning algorithms it is easy to use and efficient fast scripting language luajit and an underlying c cuda implementation torch is based on lua programming language
mocha is a deep learning framework for julia inspired by the c framework caffe efficient implementations of general stochastic gradient solvers and common layers in mocha could be used to train deep shallow convolutional neural networks with optional unsupervised pre training via stacked auto encoders its best feature include modular architecture high level interface portability with speed compatibility and many more
lush lisp universal shell is an object oriented programming language designed for researchers experimenters and engineers interested in large scale numerical and graphic applications it comes with rich set of deep learning libraries as a part of machine learning libraries
dnngraph is a deep neural network model generation dsl in haskell
accord net is a net machine learning framework combined with audio and image processing libraries completely written in c it is a complete framework for building production grade computer vision computer audition signal processing and statistics applications
darch package can be used for generating neural networks with many layers deep architectures training methods includes a pre training with the contrastive divergence method and a fine tuning with common known training algorithms like backpropagation or conjugate gradient
deepnet implements some deep learning architectures and neural network algorithms including bp rbm dbn deep autoencoder and so on
upcoming deep learning events in
the best way to predict the future is to create it
so i just started with the course at http course fast ai called practical deep learning for coders the basic infrastructure that you need is a gpu enabled pc so that you can train your models on the images quickly the author has described how to do it in aws but the problem with aws gpu instances are that is still in some sort of preview and we need to contact amazon support for unlocking their p instances
microsoft azure on the other hand already has gpu enabled vms which came out of preview on st of december you can see the promo page here its now out of preview and anyone can access it without going through the hassle of contacting support you can see the pricing here the nc machines that we are gonna use costs per hour
if you are new to azure i hope the screenshots will help you login to https ms portal azure com with your microsoft live account the click on the sign to add a vm
search for ubuntu server lts as above
make sure you choose the vm disk type as hdd instead of ssd as otherwise it will not show you the nc option also the location has to be east us
by default it shows recommended vms click on all and scroll down to nc
you should see the above message once it is successful
once it is ready click on connect and you will be able to see the ip
once you ssh into the machine start running the following commands from your home folder i have made a gist as seen below please run the commands one by one as in the blog
run step from this gist you might see an error like the one below
so we have to re run the last lines from the install gpu azure script so run step from the gist
no we are almost ready to start with out jupyter notebook so please execute step from your local in your local system so this will tunnel traffic from your localhost to the vm port replace the ip with your own ip
now run step form the gist and get all the resources you need
now we open the notebook and navigate lesson and start executing each of the commands
you should get this error we need cv please run step from the gist and you should be good
everything should be fine and dandy now happy deep learning
everyone hates captchas those annoying images that contain text you have to type in before you can access a website captchas were designed to prevent computers from automatically filling out forms by verifying that you are a real person but with the rise of deep learning and computer vision they can now often be defeated easily
i ve been reading the excellent book deep learning for computer vision with python by adrian rosebrock in the book adrian walks through how he bypassed the captcha on the e zpass new york website using machine learning
adrian didn t have access to the source code of the application generating the captcha image to break the system he had to download hundreds of example images and manually solve them to train his system
but what if we want to break an open source captcha system where we do have access to the source code
i went to the wordpress org plugin registry and searched for captcha the top result is called really simple captcha and has over million active installations
and best of all it comes with source since we ll have the source code that generates the captchas this should be pretty easy to break to make things a little more challenging let s give ourself a time limit can we fully break this captcha system in less than minutes let s try it
important note this is in no way a criticism of the really simple captcha plugin or its author the plugin author himself says that it s not secure anymore and recommends that you use something else this is just meant as a fun and quick technical challenge but if you are one of the remaining million users maybe you should switch to something else
to form a plan of attack let s see what kinds of images really simple captcha generates on the demo site we see this
ok so the captcha images seem to be four letters let s verify that in the php source code
yep it generates letter captchas using a random mix of four different fonts and we can see that it never uses o or i in the codes to avoid user confusion that leaves us with a total of possible letters and numbers that we need to recognize no problem
time elapsed so far minutes
before we go any further let s mention the tools that we ll use to solve this problem
python
python is a fun programming language with great libraries for machine learning and computer vision
opencv
opencv is a popular framework for computer vision and image processing we ll use opencv to process the captcha images it has a python api so we can use it directly from python
keras
keras is a deep learning framework written in python it makes it easy to define train and use deep neural networks with minimal coding
tensorflow
tensorflow is google s library for machine learning we ll be coding in keras but keras doesn t actually implement the neural network logic itself instead it uses google s tensorflow library behind the scenes to do the heavy lifting
ok back to the challenge
to train any machine learning system we need training data to break a captcha system we want training data that looks like this
since we have the source code to the wordpress plug in we can modify it to save out captcha images along with the expected answer for each image
after a couple of minutes of hacking on the code and adding a simple for loop i had a folder with training data png files with the correct answer for each as the filename
this is the only part where i won t give you working example code we re doing this for education and i don t want you to actually go out and spam real wordpress sites however i will give you the images i generated at the end so that you can replicate my results
time elapsed so far minutes
now that we have our training data we could use it directly to train a neural network
with enough training data this approach might even work but we can make the problem a lot simpler to solve the simpler the problem the less training data and the less computational power we ll need to solve it we ve only got minutes after all
luckily the captcha images are always made up of only four letters if we can somehow split the image apart so that that each letter is a separate image then we only have to train the neural network to recognize a single letter at a time
i don t have time to go through training images and manually split them up into separate images in photoshop that would take days and i ve only got minutes left and we can t just split the images into four equal size chunks because the captcha randomly places the letters in different horizontal locations to prevent that
luckily we can still automate this in image processing we often need to detect blobs of pixels that have the same color the boundaries around those continuous pixels blobs are called contours opencv has a built in findcontours function that we can use to detect these continuous regions
so we ll start with a raw captcha image
and then we ll convert the image into pure black and white this is called t hresholding so that it will be easy to find the continuous regions
next we ll use opencv s findcontours function to detect the separate parts of the image that contain continuous blobs of pixels of the same color
then it s just a simple matter of saving each region out as a separate image file and since we know each image should contain four letters from left to right we can use that knowledge to label the letters as we save them as long as we save them out in that order we should be saving each image letter with the proper letter name
but wait i see a problem sometimes the captchas have overlapping letters like this
that means that we ll end up extracting regions that mash together two letters as one region
if we don t handle this problem we ll end up creating bad training data we need to fix this so that we don t accidentally teach the machine to recognize those two squashed together letters as one letter
a simple hack here is to say that if a single contour area is a lot wider than it is tall that means we probably have two letters squished together in that case we can just split the conjoined letter in half down the middle and treat it as two separate letters
now that we have a way to extract individual letters let s run it across all the captcha images we have the goal is to collect different variations of each letter we can save each letter in it s own folder to keep things organized
here s a picture of what my w folder looked like after i extracted all the letters
time elapsed so far minutes
since we only need to recognize images of single letters and numbers we don t need a very complex neural network architecture recognizing letters is a much easier problem than recognizing complex images like pictures like cats and dogs
we ll use a simple convolutional neural network architecture with two convolutional layers and two fully connected layers
if you want to know more about how convolutional neural networks work and why they are ideal for image recognition check out adrian s book or my previous article
defining this neural network architecture only takes a few lines of code using keras
now we can train it
after passes over the training data set we hit nearly accuracy at this point we should be able to automatically bypass this captcha whenever we want we did it
time elapsed minutes whew
now that we have a trained neural network using it to break a real captcha is pretty simple
here s how our model looks decoding real captchas
or from the command line
if you want to try this yourself you can grab the code here it includes the sample images and all the code for each step in this article check out the included readme md file for instructions on how to run it
but if you want to learn what every line of the code does i highly recommend grabbing a copy of deep learning for computer vision with python it goes into a lot more detail and has tons of detailed examples it s the only book i ve seen so far that covers both how things work and how to actually use them in the real world to solve difficult problems check it out
if you liked this article consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
bigger update the content of this article is now available as a full length video course that walks you through every step of the code you can take the course for free and access everything else on lynda com free for days if you sign up with this link
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or italiano
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part
you can also read this article in ti ng vi t or
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
artificial intelligence ai was once considered as a theory that could never be applicable in real life within a few decades the theory turned into a concept and now every sector has an ai based mechanism whether it s an automatic car or apple s siri technology this technology has its application in every segment ai has now become an integral part of our daily life
artificial intelligence brings a technology that will make machines intelligent these machines would be able to reason and make decisions just like humans do they will be able to perceive hear and recognize the data and thereafter will give solutions for a specific problem
read also the guide to crypto banking
strong vs weak ai
there are few tasks which have only a specific requirement such machines running a facial recognition or a surgery performed by a robot or a chat running on a server all these come under weak ai as their area is towards to limitations the application has only one defined activity and thus intelligence will respond specifically
now humans have the capability to build a stronger ai platform that will be able to multi task this is called strong ai if this happens in near future then the machines in no time shall out do the humans in every given task
applications of ai
artificial intelligence can be implemented in every sector whether it s healthcare it finance amp banking or managing our daily routine when humans perform a given task it faces human error but with the help of ai our chances of reducing the error and achieving the accuracy are high these machines can overcome the human limitations and work in the areas of mining or be exploring deep sea and oceans
talking about our daily routine it s either the siri from apple or a gps from our smartphones we rely on ai to a great extent while clicking a picture our faces are read by the machines and get a tag on social media talking about the finance sectors a lot of fintech organizations depend on ai managing big data finding patterns and performing data analysis is all machine dependent
fraud detection and implementing anti money laundering regulations is another area where ai finds its application the machines are capable of performing analysis based on regular inputs a lot of healthcare surgeries are robotic thus artificial intelligence is moving from being a technology to becoming a necessity
innovation crypto bank with artificial intelligence
airfio is the future of cyrpto banking which integrates neural networks with blockchain technology https airfio com
t oday we are going to confront two different pieces of hardware that are often used for deep learning tasks the first is a gtx gpu a gaming device which is worth the dollar due to its high performance the second is a tesla p gpu a high end device devised for datacenters which provide high performance computing for deep learning
for over a year now i have dedicated most of my academic life to research in deep learning working as a pre doctoral researcher in the evannai group of computer science department of universidad carlos iii de madrid i started working with convolutional neural networks soon after google released tensorflow in late since then i started exploring the use of convolutional neural networks cnns in order to automatically extract features from raw data which can be used to succesfully carry out supervised learning or in other words training predictive models
also since early one of the research fields i have spent most time working in was human activity recognition i e developing systems that could recognize the activity performed by a user e g running walking or even smoking based on data provided by sensors such as those already present in smartphones or smartwatches
early in i found a paper by ordo ez and roggen where they applied deep learning for achieving human activity recognition in particular they used cnns along with lstm long short term memory cells which are a specific implementation of a recurrent network that turns out to be useful to capture temporal patterns such as those present in human activities
later that year i found myself spending a lot of time working with this kind of things tensorflow convolutional networks lstm cells in fact i started to search for the best architectures for a given problem this involves significant amounts of trial and error and therefore a lot of time for training and evaluating networks
by that time i needed to find a way to be able to iterate quickly over different architectures of these deep neural networks it is commonly acknowledged that gpus are way faster than cpus in performing these kind of tasks mostly because they comprise a larger number of cores and faster memory however our budget for acquiring hardware was quite limited so my research group eventually acquired one computer featuring nvidia geforce gtx followed few months later by another computer with the exact same specs
nvidia geforce is not really deep learning dedicated hardware however if you look out there you will see that many people actually use them for this purpose why because they are cheap for the performance they offer specially when compared to other nvidia solutions such as the tesla family
i have been working with these nvidia devices for over a year recently the staff from azken muga s l official nvidia provider in spain let me participate in a test drive program to evaluate the performance of tesla p devices
in this post i will try to summarize the main conclusions obtained from this test drive
in this post i will compare three different hardware setups when running different deep learning tasks
the latter have been included only for the sake of comparing gpu vs cpu when working on deep learning tasks
it is remarkable that for the first two systems our tests will be performed using only the gpu yet other components may be used as well for example data may be moved from main memory to gpu memory the gpus most remarkable specs are
it can be seen how tesla p has times more cuda cores slighly higher single precision flops and twice the amount of memory also hbm memory is significantly faster than gddr x however all these advantages can be easily eclipsed when looking at the price prices in spain including vat
for the software stack we have used the following components
in order to compare the three different hardware configurations we will use two benchmarks i have tried these benchmarks to accurately mimic my daily research tasks these benchmarks are the following
in order to obtain robust results each experiment has been run times and finally metrics are averaged for each epoch
now let s take a look at the results
it is worth recalling that these numbers refer to the average time for each training epoch
it can be seen how gpu computing is significantly faster than cpu computing about x x in both benchmarks this is an improvement of almost two orders of magnitude or to put it in different words the time required by the gpu to complete a training epoch is only slightly over compared with the cpu
regarding the comparison between the two gpus tesla outperforms geforce in the latter benchmark however there is only a x speedup or equivalently the training time is reduced in a the difference is not noticeable in the mnist benchmark probably due to the fact of epochs being so fast
finally let s take a look at the average operating temperatures and consumption of these devices during the second benchmark
we can see how energy consumption is quite similar but temperature is significantly higher in the geforce devices at this point i must say that both configurations are not comparable since the geforce gpus are installed in an atx computer tower located in an office and do not have any special cooling system besides the heatsinks and fans located in the devices and the tower
in this post we have compared two different gpus by running a couple of deep learning benchmarks these devices were geforce gtx gpus devised for gaming and tesla p gpus specifically designed for high performance computing in a datacenter
after looking at the results is the p worth the dollar given that its cost is about times the cost of the geforce it could be argued that the expense is not worthy
however a disclaimer should be added at this point tesla p seems to have a better construction and may last longer given an intensive usage personally i don t think our gtx will last long given they are running heavy processes almost x
tesla p has an additional advantage the amount of gpu memory is doubled compared to the geforce gtx this would enable us to either work with larger networks or with larger batches the former case could make a difference maybe a certain problem cannot be solved given the memory constraint imposed by the geforce device as for the latter case larger batches could lead to better convergence of the gradient descent process enabling us to train a successful model in a smaller number of epochs even if the cost per epoch is only slightly better than in the geforce gpu
it could be interesting to try the volta architecture recently announced by nvidia used along with cuda toolkit and cudnn nvidia promises up to a x speedup compared to the pascal architecture given the inclusion of tensor cores specifically designed for deep learning computating the tesla v would become the successor of the tesla p and it would be great to extend this benchmark to consider this new device
i sincerely acknowledge azken muga s l for letting us test the performance of nvidia tesla p gpus as part of their test drive program
acknowledgements are also aimed at evannai group of computer science department of universidad carlos iii de madrid for acquiring the computers with nvidia geforce gtx with which i have been working for almost a year
ios amp swift the most comprehensive course on machine learning for ios development master building smart apps ios
take this course
take this course
take this course
note if the coupon doesn t work for you please let us know and check our website for other courses we are affiliated to udemy
you can expect the latest and the greatest courses to be available for free here is the one place where you can find these coupons for free
artificial intelligence and blockchain are two of the most hyped technology topics all over the blogosphere as our teams at deutsche telekom are dealing with the interlink of data management and artificial intelligence we constantly think about how adjacent technologies like iot or even blockchain relate to our areas of expertise
what we have recently observed is that artificial intelligence has truly arrived at the board level agendas our confidence is high that the topic of blockchain has certainly reached a similar hype level in almost all industries at least from what we observe in deutsche telekom we can clearly see that this is definitely the case
today we would like to invite you to join our thinking about how telecommunication companies such as deutsche telekom can benefit from synergies between artificial intelligence amp blockchain thereby we will first shortly summarize the key ideas behind blockchain for experts feel free to skip that as a matter of completion we reference to one of our earlier articles in which we excessively explained the key ideas behind artificial intelligence in a second step we will mention how ai can benefit from blockchain as well as the other way around more precisely when talking about ai we focus specifically on machine learning and data availability sharing
blockchain a distributed ledger technology
a blockchain is a chronological list of elements called blocks these blocks are bound to each other each block contains a hash of the previous block a timestamp and content information about the underlying matter what benefits does blockchain bring let us say a group of people wanted to record transactions between each other when using a blockchain approach each peer would receive a copy of the blockchain which is extended every time a new transaction happens if one participant adds a block to the chain other users immediately verify it thereby a single participant can hardly corrupt a blockchain because the peers would detect it
sometimes people tend to use the terms blockchain interchangeably with distributed ledger technology dlt however blockchain is only one special type of the dlt concept without getting too deep into the different approaches of dlt it is worth to mention differentiating properties such as whether being public or private the used consensus algorithms e g proof of work proof of stake or whether being mineable or not wecan highly recommend an article published by the world bank which gives a solid introduction into the details of dlt and blockchain
deutsche telekom actively drives blockchain forward
the common benefit in all dlt approaches is that they disintermediate centralized administrators brokers because the peer group itself and not an intermediary ensures the validity of transactions thereby dlt has the potential to disrupt significant parts of value chains in many industries such as banking and possibly it will become a commodity technology in the near future
since deutsche telekom innovation laboratories t labs has been exploring the possibilities of dlt and actively drives the topic forward with t labs deutsche telekom is researching and developing concepts with dlt focusing on how ledger technology works by installing and experimenting on numerous ledger systems such as bitcoin ethereum and iota additionally t labs is formally joining a few foundations to push the technology forward such as agreeing to become a steward of the sovrin foundation https sovrin org
synergies of artificial intelligence specifically machine learning amp distributed ledger technology
as mentioned earlier the key for artificially intelligent machines enabled by machine learning is the availability of and the efficient access to a wide range of high quality and reliable data at the same time decision makers that rely on the inference of machine learning models need to eventually trust and believe in the proclaimed values and directives for both aspects data acquisition as well as reliable machine learning models dlt has the potential to add significant value
in fact dlt has the potential to tear down data silos if dlt manages data access and ownership in the back one could effectively solve a problem with machine learning this is the case because it would allow easier access to a higher volume and variety of data finally this would eventually lead to better and more accurate model decisions so if the wide introduction of dlt leads to an opening of silos and a clear and effective way to charge data access companies like banks insurances but also telcos like deutsche telekom might be able to extend their internal scoring models with external data this opens up the opportunity to lead to earlier identification of fraudulent or risky customers many other use cases are imaginable that benefit from the commoditization of data brokerage which is enabled and secured by dlt
how data brokerage platforms may benefit from dlt
especially for the data acquisition aspect deutsche telekom currently develops new platforms and business models one prominent external example is the so called data intelligence hub dih that t systems has recently launched as of today in its first development stage the platform does not yet embody dlt however the use case and benefit of it should be straightforward as dih is a market place for the exchange of data dlt would control so called smart contracts that steer and record any data and model exchange between parties of the dih in this context the ability of dlt to prevent identity theft and thereby ensure that trading parties can trust each other is an additional benefit dlt would bring to the table
as data from different sources are shared and consolidated via a platform such as the data intelligence hub involved parties may apply machine learning techniques to train models that can itself be traded on the platform as well here again dlt may mitigate these trades via smart contracts between the involved parties on the one hand furthermore on the other hand dlt can ensure transparency on what factors specifically influence the properties of a trained model this would enable the ability to comprehend why a model infers certain values and decisions in this case one could think of a blockchain as a kind of logchain
dlt as security leaver
to sum up dlt can help to enable track understand and explain reliable decisions made by ai specifically machine learning models additionally in terms of security aspects dlt has the potential to prevent machine learning models from getting skewed by fraudulent parties that forcefully add unbalanced data in order to influence a certain behavior of machines since such influence would be much easier to detect by other involved parties no single entity could risk the humiliation it becomes apparent that dlt has the potential to optimize data trading as well as transparency on ownership of data and models in the long term dlt may ensure validity and trustworthiness of models and their inferred decisions
the other way around
now that we have shared our thoughts on how blockchain may fuel the establishment of data sharing and machine learning training distribution and application i want to mention shortly that machine learning can help the dlt movement to achievement efficiency gains too to give a very basic example everyone has heard about the mining process of bitcoins and that it takes more and more effort to mine these crypto currencies in fact mining is in general an increasingly energy consuming process that is inherent in a lot dlt applications artificially intelligent machines have the potential to allocate resources to the mining process in a smarter way so that the overall energy consumption is lower i want to recommend the paper of marwala amp xing in which one can find an extensive list of how ai technologies can facilitate more secure and efficient dlt based solutions
and for more synergies between ai and blockchain i highly recommend these two articles
https www forbes com sites bernardmarr artificial intelligence and blockchain major benefits of combining these two mega trends ddb b
https medium com francesco ai the convergence of ai and blockchain whats the deal c e accc
as always please understand this blog post as an invitation to openly discuss thoughts on topics that are currently of high importance for me personally and the industry we work in we look forward to engage in a discussion with you either personally or here on linkedin
written by susan wegner with help from john calian
susan wegner leads the chief data office of deutsche telekom and is based in berlin
john calian leads the deutsche telekom innovation labs t labs in berlin and is also the lead on blockchain driven strategy dt wide
some experts amp scientists entrepreneurs from a variety of disciplines from more than nations all work together at t labs http bit ly tlabs
more than colleagues are participating in deutsche telekom s world cup betting pool and a very special better is participating at telekom innovation laboratories t labs an ai programmed in house that is trying to pick the winners of all the world cup matches without any emotion based solely on data from previous world cup tournaments since but the exit of the german team from the tournament has predicted the ai as little as most of us
quite the contrary the ai has picked germany to reach the final but with this prognosis the ai system was certainly not alone but let s have a look on the t labs oracle besides the german result who can beat the ai in the betting pool we re really proud of our ai after the group phase it s close to the top of the rankings explain ronald fromm and elmar arunov who both work in the artificial intelligence innovation area at t labs in the t labs pool group the ai is currently only three points behind the top not bad for a group with participants in total just to give an example the ai predicted germany s last minute victory over sweden on the nose it also predicted several ties correctly including spain versus morocco although results without a victor are the most difficult to prognosticate
t labs established artificial intelligence as an innovation area around a year ago the team focuses mainly on the use of ai methods such as machine learning in network relevant use cases the idea to use the ai for the world cup arose from a student project says elmar arunov maik p chter one of our cooperative students designed and trained the model with our support all the world cup data since was fed in which only took a couple of hours the ai did not get any additional information however such as results from national leagues or current injuries the goal of the project was simply to see the best way to train ai based models optimally with a minimum of input data
the bottom line the ai is predicting the results as good and as reliably as a regular soccer expert it will be interesting to see where it ends up in the end says elmar arunov but it has great faith in the brazilian team if the t labs oracle is to be believed brazil will win this year s final match of the world cup incidentally around percent of other neural networks that have made predictions also picked brazil to win the title
t labs is now constructing a new model for the knockout matches this will enable them to determine whether the ai has learned from the results of the group round possibly changing its prediction in that regard watching the ai develop might be just as exciting as the play on the field
some experts amp scientists entrepreneurs from a variety of disciplines from more than nations all work together at t labs http bit ly tlabs
hey tim i think using machine learning to solve a real world problem would be a really nice idea
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
generative models allow a computer to create data like photos movies or music by itself
a little over a year ago alec radford building on the work of ian goodfellow published a paper that changed how everyone thought about building generative models with machine learning the new system is called deep convolutional generative adversarial networks or dcgans for short
dcgans are able to hallucinate original photo realistic pictures by using a clever combination of two deep neural networks that compete with each other all of these pictures of bedrooms were dreamt up by a dcgan
ai researchers care about generative models because they seem to be a stepping stone towards building ai systems that can consume raw data from the world and automatically build understanding from it
but let s use generative models to do something a bit more silly make artwork for bit video games
so why exactly are ai researchers building complex systems to generate slightly wonky looking pictures of bedrooms
the idea is that if you can generate pictures of something you must have an understanding of it
look at this picture
you instantly know this is a picture of a dog a furry thing with four legs and a tail but to a computer the picture is just a grid of numbers representing the color of each pixel the computer has no understanding that the picture represents a concept
but now imagine that we showed a computer thousands of pictures of dogs and after seeing those pictures the computer was able to generate new pictures of dogs on its own including different dog breeds and pictures from different angles maybe we could even ask it for certain types of pictures like a side view of a beagle
if the computer was able to do this and the pictures it produced had the right number of legs tails and ears it would prove that the computer knows what parts go into making up a dog even though no one told it explicitly so in a sense a good generative model is proof of basic understanding at least on a toddler level
that s why researchers are so excited about building generative models they seem to be a way to train computers to understand concepts without being explicitly taught the meaning of those concepts that s a big step over current systems that can only learn from training data that has been painstakingly pre labeled by humans
but if all this research results in programs that generate pictures of dogs how many years until we get the first computer generated dog a day calendar as a side effect
and if you can build a program that understands dogs why not a program that understands anything else what about a program that could generate an unlimited number of stock photos of people shaking hands i m sure someone would pay for that
ok maybe a program that generates bad stock photos wouldn t be that interesting but given the rate of progress in generative models over just the past year who knows where we ll be in or years what happens if someone invents a system to generate entire movies or music or video games
if you look forward years and squint you can already imagine a world where entertainment could be machine generated
the video game industry is the first area of entertainment to start seriously experimenting with using ai to generate raw content aside from the obvious venn diagram overlap between computer gaming and machine learning engineers there s a huge cost incentive to invest in video game development automation given the million budgets of modern aaa video games
we are still in the earliest days of machine learning based generative models and their practical uses are currently pretty narrow but they are a lot of fun to play around with let s see what we can do with one
to build a dcgan we create two deep neural networks then we make them fight against each other endlessly attempting to out do one another in the process they both become stronger
let s pretend that the first deep neural network is a brand new police officer who is being trained to spot counterfeit money it s job is to look at a picture and tell us if the picture contains real money
since we are looking for objects in pictures we can use a standard convolutional neural network for this job if you aren t familiar with convnets you can read my earlier post but the basic idea is that the neural network that takes in an image processes it through several layers that recognize increasingly complex features in the image and then it outputs a single value in this case whether or not the image contains a picture of real money
this first neural network is called the discriminator
now let s pretend the second neural network is a brand new counterfeiter who is just learning how to create fake money for this second neural network we ll reverse the layers in a normal convnet so that everything runs backwards so instead of taking in a picture and outputting a value it takes in a list of values and outputs a picture
this second neural network is called the generator
so now we have a police officer the discriminator looking for fake money and a counterfeiter the generator that s printing fake money let s make them battle
in the first round the generator will create pathetic forgeries that barely resemble money at all because it knows absolutely nothing about what money is supposed to look like
but right now the discriminator is equally terrible at it s job of recognizing money so it won t know the difference
at this point we step in and tell the discriminator that this dollar bill is actually fake then we show it a real dollar bill and ask it how it looks different from the fake one the discriminator looks for a new detail to help it separate the real one from the fake one
for example the discriminator might notice that real money has a picture of a person on it and the fake money doesn t using this knowledge the discriminator learns how to tell the fake from the real one it gets a tiny bit better at its job
now we start round we tell the generator that it s money images are suddenly getting rejected as fake so it needs to step up it s game we also tell it that the discriminator is now looking for faces so the best way to confuse the discriminator is to put a face on the bill
and the fake bills are being accepted as valid again so now the discriminator has to look again at the real dollar and find a new way to tell it apart from the fake one
this back and forth game between the generator and the discriminator continues thousands of times until both networks are experts eventually the generator is producing near perfect counterfeits and the discriminator has turned into a master detective looking for the slightest mistakes
at the point when both networks are sufficiently trained so that humans are impressed by the fake images we can use the fake images for whatever purpose we want
so now that we know how dcgans work let s see if we can use one to generate new artwork for s style video games
let s build a dcgan that tries to produce screenshots of imaginary video games for the nintendo entertainment system or nes based on screenshots of real games
the idea is that if we can generate convincing screenshots of imaginary video games we could copy and paste bits of art from those screenshots and use it in our own retro style video game since the generated video games never existed it wouldn t even be stealing maybe more on this later
video game art in those days was very simple since the nes had such a small amount of memory the games used way less memory than this article takes up programmers had to use lots of tricks to fit the game art into memory to maximize the limited space games used tile based graphics where each screen in the game is made up of just a few usually x pixel repeated graphical tiles
for example the starting screen of the legend of zelda is made up of only unique tiles
here are the tiles for entire the legend of zelda game map
our goal is to create a similar tile sheet for our game because of that we don t really care if the game screenshots we generate look completely realistic instead we re just looking for the shapes and patterns that we can use as x tiles in our game things like stones water bridges etc then we can use those tiles to build our own bit style video game levels
to train our system we need lots of data luckily there are over games for the nes that we can pull from
i used wget to download all the nes game screenshots on the video game museum website sorry for scraping your site after a few minutes of downloading i had a little over screenshots of hundreds of nes games
right now dcgans only work on pretty small images pixels square or so but the entire screen resolution of the nes was only pixels by pixels so that s not a problem to make things simple i cropped each nes screenshot to pixels square
there are several open source implementations of dcgans on github that you can try out i used taehoon kim s tensorflow implementation since dcgans are unsupervised all you have to do is put the data in a folder tweak the basic parameters start it training and then wait to see what results you get
here s what a sample of the original training data looks like
now training begins at first the output from the generator is pure noise but it slowly start to take shape as the generator learns to do a better job
after several more training rounds the images start to resemble nightmare ish versions of classic nintendo games
as training continues further we start to see the bricks and blocks we are hoping to find you can also see screen elements like life bars and even some text
this is where things get complicated how do we know the computer is creating brand new art and not just regurgitating art directly from the training images in two of these images you can clearly see the menu bar from super mario bros and the header bar and bricks from the original super mario bros
regurgitating training data is definitely something that can happen by using a large training data set and not training too long we can try to reduce the chance that this happens but it s a thorny issue and research on it continues
since i m just going for aesthetics i tweaked the model until it produced art that looked original to me but i can t prove that the new art is totally original except by searching the training data for similar art and verifying that there isn t any
with a few hours of training the generated images contained x tiles that looked nice to me i was looking for some variations on a basic stone block brick patterns water patterns bushes and some general spooky looking background atmosphere tiles
next i need to pre process the generated images to the make sure they only used the colors that are available on the nes
then i ll open up the color images in the tiled map editor from there i can easily grab the x tiles that match the aesthetic i want
then inside of tiled map editor i ll arrange those x tiles into a simple level layout reminiscent of the nes game castlevania
i think that looks pretty good keep in mind i didn t touch a single pixel with an image editor every tile came straight out of the dcgan model
next let s throw in the main character and some enemies from castlevania so we can see what this level would look like in action
to get the full effect let s see what the level would look like inside the game with the menu elements added
i think that looks like the nes games that i remember i m not claiming it s the best nes art ever created but it s certainly not the worst
i get really excited about generative models like this the idea of one day cranking out endless artwork with computers is fascinating to me but when i talk to other people about this stuff sometimes the response is is that it that s so basic
there s certainly a lot of hype around generative models right now gans are already being called the future of ai despite being notoriously hard to train and limited to generating tiny images in fact the very best models can currently only generate postage stamp sized pictures of mutant dogs
but a couple of years ago we couldn t do anything close to that we were pretty excited by generated pictures that looked like this
and the technology is improving every single day here s a random paper that came out this week that uses gans to age the faces of people
if things keep improving at this pace it won t be too long before generative models are a mainstream tool helping us create it s a great time to start experimenting
if you want to learn more in depth about generative models and dcgans here are some recommended resources
this article is part of my machine learning is fun series you can check out the earlier parts here part part part part part and part
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
this article is part of an on going series on nlp part part you can also read a reader translated version of this article in
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
computers are great at working with structured data like spreadsheets and database tables but us humans usually communicate in words not in tables that s unfortunate for computers
a lot of information in the world is unstructured raw text in english or another human language how can we get a computer to understand unstructured text and extract data from it
natural language processing or nlp is the sub field of ai that is focused on enabling computers to understand and process human languages let s check out how nlp works and learn how to write programs that can extract information out of raw text using python
note if you don t care how nlp works and just want to cut and paste some code skip way down to the section called coding the nlp pipeline in python
as long as computers have been around programmers have been trying to write programs that understand languages like english the reason is pretty obvious humans have been writing things down for thousands of years and it would be really helpful if a computer could read and understand all that data
computers can t yet truly understand english in the way that humans do but they can already do a lot in certain limited areas what you can do with nlp already seems like magic you might be able to save a lot of time by applying nlp techniques to your own projects
and even better the latest advances in nlp are easily accessible through open source python libraries like spacy textacy and neuralcoref what you can do with just a few lines of python is amazing
the process of reading and understanding english is very complex and that s not even considering that english doesn t follow logical and consistent rules for example what does this news headline mean
are the regulators questioning a business owner about burning coal illegally or are the regulators literally cooking the business owner as you can see parsing english with a computer is going to be complicated
doing anything complicated in machine learning usually means building a pipeline the idea is to break up your problem into very small pieces and then use machine learning to solve each smaller piece separately then by chaining together several machine learning models that feed into each other you can do very complicated things
and that s exactly the strategy we are going to use for nlp we ll break down the process of understanding english into small chunks and see how each one works
let s look at a piece of text from wikipedia
this paragraph contains several useful facts it would be great if a computer could read this text and understand that london is a city london is located in england london was settled by romans and so on but to get there we have to first teach our computer the most basic concepts of written language and then move up from there
the first step in the pipeline is to break the text apart into separate sentences that gives us this
we can assume that each sentence in english is a separate thought or idea it will be a lot easier to write a program to understand a single sentence than to understand a whole paragraph
coding a sentence segmentation model can be as simple as splitting apart sentences whenever you see a punctuation mark but modern nlp pipelines often use more complex techniques that work even when a document isn t formatted cleanly
now that we ve split our document into sentences we can process them one at a time let s start with the first sentence from our document
the next step in our pipeline is to break this sentence into separate words or tokens this is called tokenization this is the result
tokenization is easy to do in english we ll just split apart words whenever there s a space between them and we ll also treat punctuation marks as separate tokens since punctuation also has meaning
next we ll look at each token and try to guess its part of speech whether it is a noun a verb an adjective and so on knowing the role of each word in the sentence will help us start to figure out what the sentence is talking about
we can do this by feeding each word and some extra words around it for context into a pre trained part of speech classification model
the part of speech model was originally trained by feeding it millions of english sentences with each word s part of speech already tagged and having it learn to replicate that behavior
keep in mind that the model is completely based on statistics it doesn t actually understand what the words mean in the same way that humans do it just knows how to guess a part of speech based on similar sentences and words it has seen before
after processing the whole sentence we ll have a result like this
with this information we can already start to glean some very basic meaning for example we can see that the nouns in the sentence include london and capital so the sentence is probably talking about london
in english and most languages words appear in different forms look at these two sentences
i had a pony
i had two ponies
both sentences talk about the noun pony but they are using different inflections when working with text in a computer it is helpful to know the base form of each word so that you know that both sentences are talking about the same concept otherwise the strings pony and ponies look like two totally different words to a computer
in nlp we call finding this process lemmatization figuring out the most basic form or lemma of each word in the sentence
the same thing applies to verbs we can also lemmatize verbs by finding their root unconjugated form so i had two ponies becomes i have two pony
lemmatization is typically done by having a look up table of the lemma forms of words based on their part of speech and possibly having some custom rules to handle words that you ve never seen before
here s what our sentence looks like after lemmatization adds in the root form of our verb
the only change we made was turning is into be
next we want to consider the importance of a each word in the sentence english has a lot of filler words that appear very frequently like and the and a when doing statistics on text these words introduce a lot of noise since they appear way more frequently than other words some nlp pipelines will flag them as stop words that is words that you might want to filter out before doing any statistical analysis
here s how our sentence looks with the stop words grayed out
stop words are usually identified by just by checking a hardcoded list of known stop words but there s no standard list of stop words that is appropriate for all applications the list of words to ignore can vary depending on your application
for example if you are building a rock band search engine you want to make sure you don t ignore the word the because not only does the word the appear in a lot of band names there s a famous s rock band called the the
the next step is to figure out how all the words in our sentence relate to each other this is called dependency parsing
the goal is to build a tree that assigns a single parent word to each word in the sentence the root of the tree will be the main verb in the sentence here s what the beginning of the parse tree will look like for our sentence
but we can go one step further in addition to identifying the parent word of each word we can also predict the type of relationship that exists between those two words
this parse tree shows us that the subject of the sentence is the noun london and it has a be relationship with capital we finally know something useful london is a capital and if we followed the complete parse tree for the sentence beyond what is shown we would even found out that london is the capital of the united kingdom
just like how we predicted parts of speech earlier using a machine learning model dependency parsing also works by feeding words into a machine learning model and outputting a result but parsing word dependencies is particularly complex task and would require an entire article to explain in any detail if you are curious how it works a great place to start reading is matthew honnibal s excellent article parsing english in lines of python
but despite a note from the author in saying that this approach is now standard it s actually out of date and not even used by the author anymore in google released a new dependency parser called parsey mcparseface which outperformed previous benchmarks using a new deep learning approach which quickly spread throughout the industry then a year later they released an even newer model called parseysaurus which improved things further in other words parsing techniques are still an active area of research and constantly changing and improving
it s also important to remember that many english sentences are ambiguous and just really hard to parse in those cases the model will make a guess based on what parsed version of the sentence seems most likely but it s not perfect and sometimes the model will be embarrassingly wrong but over time our nlp models will continue to get better at parsing text in a sensible way
want to try out dependency parsing on your own sentence there s a great interactive demo from the spacy team here
so far we ve treated every word in our sentence as a separate entity but sometimes it makes more sense to group together the words that represent a single idea or thing we can use the information from the dependency parse tree to automatically group together words that are all talking about the same thing
for example instead of this
we can group the noun phrases to generate this
whether or not we do this step depends on our end goal but it s often a quick and easy way to simplify the sentence if we don t need extra detail about which words are adjectives and instead care more about extracting complete ideas
now that we ve done all that hard work we can finally move beyond grade school grammar and start actually extracting ideas
in our sentence we have the following nouns
some of these nouns present real things in the world for example london england and united kingdom represent physical places on a map it would be nice to be able to detect that with that information we could automatically extract a list of real world places mentioned in a document using nlp
the goal of named entity recognition or ner is to detect and label these nouns with the real world concepts that they represent here s what our sentence looks like after running each token through our ner tagging model
but ner systems aren t just doing a simple dictionary lookup instead they are using the context of how a word appears in the sentence and a statistical model to guess which type of noun a word represents a good ner system can tell the difference between brooklyn decker the person and the place brooklyn using context clues
here are just some of the kinds of objects that a typical ner system can tag
ner has tons of uses since it makes it so easy to grab structured data out of text it s one of the easiest ways to quickly get value out of an nlp pipeline
want to try out named entity recognition yourself there s another great interactive demo from spacy here
at this point we already have a useful representation of our sentence we know the parts of speech for each word how the words relate to each other and which words are talking about named entities
however we still have one big problem english is full of pronouns words like he she and it these are shortcuts that we use instead of writing out names over and over in each sentence humans can keep track of what these words represent based on context but our nlp model doesn t know what pronouns mean because it only examines one sentence at a time
let s look at the third sentence in our document
if we parse this with our nlp pipeline we ll know that it was founded by romans but it s a lot more useful to know that london was founded by romans
as a human reading this sentence you can easily figure out that it means london the goal of coreference resolution is to figure out this same mapping by tracking pronouns across sentences we want to figure out all the words that are referring to the same entity
here s the result of running coreference resolution on our document for the word london
with coreference information combined with the parse tree and named entity information we should be able to extract a lot of information out of this document
coreference resolution is one of the most difficult steps in our pipeline to implement it s even more difficult than sentence parsing recent advances in deep learning have resulted in new approaches that are more accurate but it isn t perfect yet if you want to learn more about how it works start here
want to play with co reference resolution check out this great co reference resolution demo from hugging face
here s an overview of our complete nlp pipeline
whew that s a lot of steps
note before we continue it s worth mentioning that these are the steps in a typical nlp pipeline but you will skip steps or re order steps depending on what you want to do and how your nlp library is implemented for example some libraries like spacy do sentence segmentation much later in the pipeline using the results of the dependency parse
so how do we code this pipeline thanks to amazing python libraries like spacy it s already done the steps are all coded and ready for you to use
first assuming you have python installed already you can install spacy like this
then the code to run an nlp pipeline on a piece of text looks like this
if you run that you ll get a list of named entities and entity types detected in our document
you can look up what each of those entity codes means here
notice that it makes a mistake on londinium and thinks it is the name of a person instead of a place this is probably because there was nothing in the training data set similar to that and it made a best guess named entity detection often requires a little bit of model fine tuning if you are parsing text that has unique or specialized terms like this
let s take the idea of detecting entities and twist it around to build a data scrubber let s say you are trying to comply with the new gdpr privacy regulations and you ve discovered that you have thousands of documents with personally identifiable information in them like people s names you ve been given the task of removing any and all names from your documents
going through thousands of documents and trying to redact all the names by hand could take years but with nlp it s a breeze here s a simple scrubber that removes all the names it detects
and if you run that you ll see that it works as expected
what you can do with spacy right out of the box is pretty amazing but you can also use the parsed output from spacy as the input to more complex data extraction algorithms there s a python library called textacy that implements several common data extraction algorithms on top of spacy it s a great starting point
one of the algorithms it implements is called semi structured statement extraction we can use it to search the parse tree for simple statements where the subject is london and the verb is a form of be that should help us find facts about london
here s how that looks in code
and here s what it prints
maybe that s not too impressive but if you run that same code on the entire london wikipedia article text instead of just three sentences you ll get this more impressive result
now things are getting interesting that s a pretty impressive amount of information we ve collected automatically
for extra credit try installing the neuralcoref library and adding coreference resolution to your pipeline that will get you a few more facts since it will catch sentences that talk about it instead of mentioning london directly
by looking through the spacy docs and textacy docs you ll see lots of examples of the ways you can work with parsed text what we ve seen so far is just a tiny sample
here s another practical example imagine that you were building a website that let s the user view information for every city in the world using the information we extracted in the last example
if you had a search feature on the website it might be nice to autocomplete common search queries like google does
but to do this we need a list of possible completions to suggest to the user we can use nlp to quickly generate this data
here s one way to extract frequently mentioned noun chunks from a document
if you run that on the london wikipedia article you ll get output like this
this is just a tiny taste of what you can do with nlp in future posts we ll talk about other applications of nlp like text classification and how systems like amazon alexa parse questions
but until then install spacy and start playing around or if you aren t a python user and end up using a different nlp library the ideas should all work roughly the same way
this article is part of an on going series on nlp you can continue on to part
if you liked this article consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
a summary from reading the post by jason brownlee post on machinelearningmastery com here s the original link https machinelearningmastery com improve deep learning performance
the gains often get smaller the further down the list for example a new framing of your problem or more data is often going to give you more payoff than tuning the parameters of your best performing algorithm not always but in general
in fact you can often get good performance from combining the predictions from multiple good enough models rather than from multiple highly tuned and fragile models
let s begin by removing black box algorithms from core public agencies
today we released our second annual research report on the state of artificial intelligence since last year s report we ve seen early stage ai technologies continue to filter into many everyday systems from scanning faces at airport security to recommending to hire someone to granting someone bail to denying someone a loan this report was developed for our annual ai now experts workshop which included invited researchers across relevant domains and it reflects a range of views that were discussed at the event
while ai holds significant promise we re seeing significant challenges in the rapid push to integrate these systems into high stakes domains in criminal justice a team at propublica and multiple academics since have investigated how an algorithm used by courts and law enforcement to predict recidivism in criminal defendants may be introducing significant bias against african americans in a healthcare setting a study at the university of pittsburgh medical center observed that an ai system used to triage pneumonia patients was missing a major risk factor for severe complications in the education field teachers in texas successfully sued their school district for evaluating them based on a black box algorithm which was exposed to be deeply flawed
this handful of examples is just the start there s much more we do not yet know part of the challenge is that the industry currently lacks standardized methods for testing and auditing ai systems to ensure they are safe and not amplifying bias yet early stage ai systems are being introduced simultaneously across multiple areas including healthcare finance law education and the workplace these systems are increasingly being used to predict everything from our taste in music to our likelihood of experiencing mental illness to our fitness for a job or a loan
the problem here is not the willful misuse of ai it s that ai and related technologies are being used without processes or standards to ensure safety or fairness or without a deeper consideration of their complex social interactions when a new drug is released into the marketplace it must first undergo rigorous scientific trials and testing and continued monitoring of its medium and long term effects care and caution is paramount in this domain because if things go wrong many people experience significant harm the same is true for ai systems in high stakes domains
as part of our report we are offering ten recommendations for the ai industry researchers and policy makers we ve listed these recommendations below along with some additional context for each these recommendations aren t the solution they are a starting place for much needed further work while the deployment of ai products is moving quickly research into bias and fairness are in their early stages and there is much to be done if we re going to ensure that ai systems are deployed and managed responsibly that will require a joint effort for our part we are committed to further research on these issues and sharing that with the wider community we think it s urgently needed finally if you re interested in pursuing a postdoctoral fellowship centered on the social implications of ai we hope you ll consider joining us in this effort
core public agencies such as those responsible for criminal justice healthcare welfare and education e g high stakes domains should no longer use black box ai and algorithmic systems this includes the unreviewed or unvalidated use of pre trained models ai systems licensed from third party vendors and algorithmic processes created in house the use of such systems by public agencies raises serious due process concerns and at a minimum such systems should be available for public auditing testing and review and subject to accountability standards
this would represent a significant shift our recommendation reflects the major decisions that ai and related systems are already influencing and the multiple studies providing evidence of bias in the last twelve months as detailed in our report others are also moving in this direction from the ruling in favor of teachers in texas to the current process underway in new york city this month where the city council is considering a bill to ensure transparency and testing of algorithmic decision making systems
before releasing an ai system companies should run rigorous pre release trials to ensure that they will not amplify biases and errors due to any issues with the training data algorithms or other elements of system design as this is a rapidly changing field the methods and assumptions by which such testing is conducted along with the results should be openly documented and publicly available with clear versioning to accommodate updates and new findings
we believe that those who develop and profit from these systems should be responsible for leading testing and assurance including pre release trials we recognize that the field is a long way from standardized methods which is why we recommend that these methods and assumptions are open for scrutiny and discussion this openness will be crucial if the ai field is to develop robust testing standards over time we also recognize that testing in a lab even with standardized methods may not catch all errors and blind spots which leads us to recommendation
after releasing an ai system companies should continue to monitor its use across different contexts and communities the methods and outcomes of monitoring should be defined through open academically rigorous processes and should be accountable to the public particularly in high stakes decision making contexts the views and experiences of traditionally marginalized communities should be prioritized
ensuring that ai and algorithmic systems are safe is extraordinarily complex and needs to be an ongoing process through the life cycle of a given system it s not a compliance checkbox that can be completed and forgotten monitoring across dynamic use cases and contexts is needed to ensure ai systems don t introduce errors and bias as cultural assumptions and domains shift and change it is also important to note that many ai models and systems are general purpose where products might use plug and play add ons like emotion detection or facial recognition capabilities this means that those offering general purpose ai models could also consider the option of licensing for approved uses where potential downsides and risks have been considered
more research and policy making is needed on the use of ai systems in workplace management and monitoring including hiring and hr this research will complement the existing focus on worker replacement via automation specific attention should be given to the potential impact on labor rights and practices and should focus especially on the potential for behavioral manipulation and the unintended reinforcement of bias in hiring and promotion
the debate around ai and labor usually focuses on the displacement of human workers which is a very serious concern however we think it s just as important to track how ai and algorithmic systems are used within today s workplaces for everything from behavioural nudging to surveillance to rating performance for example a company called hirevue recently deployed an ai based video interviewing service which analyzes a job applicant s speech body language and tone to determine whether the applicant matches the model of top performers at a given company given the potential of these systems to reduce diversity and entrench existing biases more work is needed to fully understand how ai is being integrated into management hiring scheduling and the structures and practices of everyday workplaces
develop standards to track the provenance development and use of training datasets throughout their life cycle this is necessary to better understand and monitor issues of bias and representational skews in addition to developing better records for how a training dataset was created and maintained social scientists and measurement researchers within the ai bias research field should continue to examine existing training datasets and work to understand potential blind spots and biases that may already be at work
ai relies on large scale data in order to detect patterns and make predictions this data reflects human history and inevitably reflects biases and prejudices from the training dataset machine learning techniques excel at picking up such statistical patterns often omitting diverse outliers in an attempt to generalize the common cases this is why it is important that research into bias not take data at face value and that such research begin by understanding where data used to train ai systems came from tracking how such data is used across systems and validating the methods and assumptions that shape a given dataset over time by understanding this we can better understand errors and bias reflected in data and develop ways of recognizing and possibly mitigating them during data creation and collection
expand ai bias research and mitigation strategies beyond a narrowly technical approach bias issues are long term and structural and contending with them necessitates deep interdisciplinary research technical approaches that look for a one time fix for fairness risk oversimplifying the complexity of social systems within each domain such as education healthcare or criminal justice legacies of bias and movements toward equality have their own histories and practices legacies of bias cannot be solved without drawing on domain expertise addressing fairness meaningfully will require interdisciplinary collaboration and methods of listening across different disciplines
the recent increase in work on ai and algorithmic bias is an excellent sign but we caution against taking a purely technical approach otherwise there is a risk that systems are merely optimized without knowing what to optimize for computer scientists can learn more about underlying structural inequalities that shape data and the contextual integration of ai systems by collaborating with domain experts in fields like law medicine sociology anthropology and communication
strong standards for auditing and understanding the use of ai systems in the wild are urgently needed creating such standards will require the perspectives of diverse disciplines and coalitions the process by which such standards are developed should be publicly accountable academically rigorous and subject to periodic review and revision
currently there are no established methods for measuring and assessing the impacts of ai systems as they are used in specific social contexts this is a significant problem given the determinations that early stage ai systems are already influencing across multiple high stakes domains developing such standards and methods should be an urgent priority for the ai field
companies universities conferences and other stakeholders in the ai field should release data on the participation of women minorities and other marginalized groups within ai research and development many now recognize that the current lack of diversity in ai is a serious issue yet there is insufficiently granular data on the scope of the problem which is needed to measure progress beyond this we need a deeper assessment of workplace cultures in the technology industry which requires going beyond simply hiring more women and minorities toward building more genuinely inclusive workplaces
the assumptions and perspectives of those who create ai systems will necessarily shape them ai developers are often male white and with similar backgrounds in terms of education and training we have already seen evidence that this causes problems from voice recognition systems that don t hear women to ai assistants that fail to give information on women s health however beyond general tech industry diversity statistics there are few efforts to quantify and better understand the issue of diversity in the ai field specifically if ai is to be safe fair and widely relevant efforts need to be made not only to track diversity and inclusion but also to ensure that the culture in which ai is being designed and developed is welcoming to women minorities and other marginalized groups
the ai industry should hire experts from disciplines beyond computer science and engineering and ensure they have decision making power as ai moves into diverse social and institutional domains influencing increasingly high stakes decisions efforts must be made to integrate social scientists legal scholars and others with domain expertise that can guide the creation and integration of ai into long standing systems with established practices and norms
just as we wouldn t expect a lawyer to optimize a deep neural network we shouldn t expect technical ai researchers and engineers to be experts in criminal justice or any of the other social domains where technical systems are being integrated we need domain experts to be at the table to help lead decision making and ensure ai systems don t naively misunderstand the complex processes histories and contexts in areas like law health and education
ethical codes meant to steer the ai field should be accompanied by strong oversight and accountability mechanisms more work is needed on how to substantively connect high level ethical principles and guidelines for best practices to everyday development processes promotion and product release cycles
several computing industry groups are developing ethical codes to help ensure the development of safe and fair ai detailed further in our report however these codes are voluntary and generally high level asking ai developers to prioritize the common good but how should the common good be determined and by whom in addition to questions of representation such codes will need to be connected to clear systems of accountability while also remaining conscious of the incentive structures and power asymmetries at work in the ai industry
researching the social implications of artificial intelligence now to ensure a more equitable future
on june the forum for future medical technology and artificial intelligence conference hosted by bio valley was held in shanghai the goal of the conference was to share and discuss the development and application of artificial intelligence in the medical field
the panel of speakers at the conference included prof jianwei zhang director of the institute of the multi modal technology systems and professor at the university of hamburg in germany mr ray zhang founder and ceo of airdoc mr fabao zhang chairman of shanghai metz pharmaceutical technology co mr xubo hu the managing partner at qiming venture partners
since the discovery of x ray in x ray has been widely used to examine the human body to assist in the diagnosis of diseases laying the basis for radiological and medical imaging medical imaging has now become the most common diagnostic diagnostic tool
over the past few decades medical imaging technology in china has developed rapidly however imaging specialists have been in short supply and mainly concentrated in large hospitals of large cities many small and medium size cities do not have adequate imaging diagnostics resources patients in smaller cities have found it necessary to travel to big cities in order to seek proper medical treatment
airdoc aims to solve the problem of inadequate medical imaging resources by leveraging scalable technology artificial intelligence airdoc equips many smaller community level health care institutions with ai medical image recognition capability previously only available at the best hospitals
in the years since the conception of artificial intelligence lack of computing power and immature algorithms impeded its development in the advent of deep learning brought significant revival to artificial intelligence in the emergence of alexnet brought about a turning point in ai at the large scale visual recognition challenge ilsvrc alexnet bested the previous year s top error by percentage points ever since artificial intelligence in the field of image recognition has constantly been making and breaking records
in recent years articles appearing in nature jama science and other authoritative medical journals have begun writing about using artificial intelligence to solve medical problems for example artificial intelligence identifies skin cancer appeared on the cover of nature science magazine reported on computers predicting heart attack at higher accuracy rate than that of human doctors etc meanwhile major chinese hospitals have also begun to seriously study clinical applications of artificial intelligence
ray zhang asserts that artificial intelligence has virtually limitless possibilities in the medical field a few examples besides medical imaging include virtual nurse assistant health management medical risk analysis drug extraction auxiliary diagnosis and medical research but medical artificial intelligence is still in its infancy but its role in medical imaging recognition is well on its way
in medical image recognition the development of artificial intelligence requires massive numbers of medical images to generate algorithm models data volume and data quality are critical high data volume increases the model s inclusion rate while accurate data and annotations ensure high accuracy of the model s training and test sets
ray zhang dalei contends that within the next years artificial intelligence will play a critical role in the medical field artificial intelligence will be the core driving force behind the next revolution in medicine ai can thoroughly analyze and aggregate medical knowledge to help provide higher quality clinical advice
with its comprehensive inter disciplinary integration ai is set to facilitate the evolution of economic patterns by transforming across commercial financial and medical industries
airdoc is a deep learning based algorithm services company providing ai medical solutions
here i introduce the concept of automated learning learning by induction and other learning methods
this article is part of series of articles about the fundamental theories behind machine learning
in order to create systems that are able to learn autonomously we have to understand what learning is learning is in essence the ability of turning experience into expertise or knowledge for example a baby at some point may not know how to detect the voice of family members but as he interacts with them and hears each one of their voices accompanied by their face it slowly learns to detect the voice of each family member and after a few months it becomes an expert at identifying the voices of each family member in the context of the baby example what do we call the input it receives and what would be the output the input that the babies brain receives we call the training data which represents experience and the output would be some expertise what then is the expertise that the baby acquired in this case the expertise that the baby acquired is the ability to identify the voice of each family member
as we are seeking a formal mathematical understanding of this concept we need to ask ourselves the following questions what is the training data our learning system will need how can learning be automated how can we evaluate the success or failure of such a system
let us consider an example of learning by analyzing two fictional monkeys called a and b respectively who are both taking an online course on algebra a and b learn in very different ways monkey a and b are both shown equations similar to the ones below
they are not given any explanations on how to solve the equations and have never taken maths classes before they are given hour to find a strategy that they must use to solve equations in a test they will receive after that hour has passed
monkey a decides to memorize all equations monkey b analyzes the equations and tries to find patterns in the equations when given a test with equations they have never seen before which of the monkeys is most likely to solve them correctly obviously it s monkey b
what strategies did the monkeys use to learn why would monkey b perform better than a well monkey a used a technique called learning by memorization while monkey b used inductive reasoning also called inductive inference inductive reasoning is the cognitive process of making observations discerning a pattern in order to make generalizations a hallmark of a successful learning system is the ability to progress from a few examples to broader generalizations
great so we know inductive reasoning is a hallmark of a successful learning system but will it be consistent in providing us with the right conclusions
let us seek out this answer by means of a example of inductive reasoning i have a bag i put my hands in the bag and take out a banana i put my hands in the bag again and out comes another banana i put my hands in the bag once again and out comes another banana my bag only has bananas did you notice that this matches our earlier definition of inductive reasoning observe discern patterns and make generalizations is it reasonable to conclude that everything in the bag is a banana just because we have observed bananas came out of it would it be reasonable to conclude that every bag will also have bananas you answer could sway either way but if we are to create good learning systems we must prove formally that it will succeed to consistently draw true conclusions unfortunately it is clear that inductive reasoning will fail to be consistent and thus return false conclusions
let us go back to the monkey maths dilemma where monkey b used inductive reasoning to solve equations it is clear that it s learning method is superior to monkey a s method but as we have concluded above it will not be consistent at always returning true conclusions therefore we have two options either scrape the entire inductive reasoning method or add some modification to it in order to enhance its learning capability we could effectively allow monkey b to perform better on the test by giving monkey b some prior knowledge about terms variables expressions equations and patterns it should ignore as well as patterns it should pay attention to the incorporation of prior knowledge that biases monkey b s learning process is called inductive bias monkey b will now be bias to detecting certain patterns in the equations while ignoring others it turns out that the incorporation of prior knowledge is one of key concepts to understand in order to build a successful learning system and we will dig deeper into these concepts in later articles
machine learning is often used to solve the following classes of problems
when we have tasks that are extremely complicated to code by hand for example detecting hand written digits detecting faces in pictures and natural language processing it is far too difficult to create a well defined step by step solution to these kinds of problems
when we want programs that adapt to changes or environments for example recommendation engines that adapts to users preferences speech recognition systems that adapt to variations in a users voice and programs that adapt to variations in hand writing
supervised learning is a method of learning in which a teacher helps train the learner by providing the correct labels for the data this data is called training data or a training data set for example let s say we have a set of bananas b b b b b the teacher would then provide the correct labels for each element of the banana set labels ripe not ripe ripe ripe this labeling process is akin to giving our monkey prior knowledge in order for it to successfully accomplish the task it was given to learn
formally this training data will usually be some n dimensional vector which will be input to a learning system that uses inference to label unseen data the teacher thus guides the learner in it s learning task
these types of learning methods are split into classification and regression problems and later on we will get into the specifics of these kinds of problems
unsupervised learning is slightly different to the previous method as the learner is not provided with the correct labels nor a teacher to guide it examples of this type of learning is common in humans humans do not need labels to learn do you know of a baby that was given labels to learn to identify it s mother face or voice these learning systems are split into clustering and association problems
reinforcement and semi supervised learning are techniques that are used in various learning systems and will be discussed in future articles
machine learning shares common roots to statistics information theory game theory and optimization calculus it is a sub field of computer science since our objective here is to program machines that will learn it is also a branch of artificial intelligence however note that machine learning s goal is not create an automated imitation of intelligent behavior as seen in humans but rather use the capabilities of computers to compliment human intelligence in contrast with humans computers can analyze billions of terabytes of data that we can never dream of they can also run very complex calculations an order of magnitude faster then our biological brains it is only common sense to use these capabilities to enhance our society and our own intelligence
in the next article we will be introduced to the statistical learning model and other concepts which will be the foundation to fully understand these automated learning systems
if you enjoyed reading this make sure to follow and as well share it with friends family oh and every monkey you know cheers
software developer open source enthusiast security nerd techie member of gdgluanda
when dennis r mortensen hired his founding team members at x ai he pitched them by illustrating his vision of a world where everyone has a personal assistant to schedule their meetings recognizing the complexity of the challenge he concluded by saying we may die trying
it s a great setting to hire qualified people dennis says recounting the late days of we re working on something that is clearly very hard to the extent that we might not make it but it s not impossible that s the sweet spot he says when a calling finds you that is incredibly challenging yet still attainable even if only at your fingertips it s right in the middle he continues it s not a weekend hackathon but it s not space travel either it s that area right in between where you find the best people
x ai has since grown to team members who dennis refers to as propeller heads who are working day in and day out to bring amy and andrew ingram whom many of you know to life
from his initial meetings with his seed investors including ia ventures lerer hippeau ventures and softbank capital to our first conversation in early dennis has been adamant in demonstrating his long term perspective for x ai countless solutions currently exist to schedule meetings actual assistants virtual assistants apps plug ins and websites the list goes on and each has a different price point
x ai has taken a different approach to developing amy they refer to her and her brother as invisible software she can never be an app plugin or website amy has to exist in dialogue you would never go up to your assistant at the front of your office and say show me your features what can you do for me it would be completely unacceptable dennis affirms
the goal is for amy to feel and communicate like a human and she does if you ve ever had an interaction with her you ll find yourself asking how her day is and thanking her more than individuals have even asked her on a date x ai has an ai interaction designer who focuses specifically on developing these humanistic conversational skills
when you communicate with amy you should forget that she is a machine because it doesn t matter you can be confident that when you tell her something she understands and will do what you requested the mission has required two years of deep learning testing and iteration the first was spent primarily gathering data and developing the tools that would enable the team to start building amy according to dennis they are building the tools to build the machine while building the machine
in the darkest hours of our first year there was no meeting data that we could acquire and model on top of nothing zero he says we started out by setting up one meeting then another then and so on until we went through millions of emails that we annotated with great pain so we can create models on top of them
despite acquiring foundational knowledge the last two years the challenge is significantly more complex than the message that appears in our inboxes take the response sure jessica how about next tuesday thursday around sent at p m on sunday night countless questions arise for amy or andrew on the other side of this exchange is jessica referring to this upcoming tuesday and thursday or the following does wednesday count is she referring to exactly or perhaps or will this be a morning meeting or an evening meeting will you be commuting from a prior meeting if so from where the most significant question then is how do they proceed
little things turn into massive complexities on our end dennis asserts the more we learn the more ambiguity we see in everything that humans do the less complexity you put on the user side the more you have to put on the creator
the mentality appears intense but scheduling meetings is a vital part of our personal and professional lives say you re meeting with an investor to close your funding round and amy makes a mistake there is simply no room for error it is precisely because of this that x ai has made your calendar their sole focus despite requests from customers asking for more capabilities such as arranging deliveries or scheduling travel
we just want to perfect amy we want her to be so good that even if you can hire a human to perform this task you won t need or want to dennis says the goal is for amy to grow up to be an adult who can handle everything on her own without human intervention x ai is on track to achieve that as the team prepares to release their first paid product this autumn we are working on a clearly defined list as we speak dennis confirms we know exactly what we need to work on to make amy into a superhuman when it comes to setting up meetings
similar to self driving cars flawless artificial intelligence isn t going to be ready overnight the progress will be based on deliberate experimentation slow growth and most importantly resilient pioneers it s not reasonable to think that an ai agent is going to arrive at an oracle level dennis says
the more likely scenario according to dennis will be a team of vertical ai agents meaning that we ll have individual artificial intelligence agents who each work on a single task for us such as scheduling our meetings booking travel or ordering our groceries for example if you re traveling to los angeles your ai travel agent will arrange your flights hotel and transportation amy or andrew will then communicate with him or her to determine the best place to schedule your meetings based on your arrival time distance to the hotel and trip duration your input will not be required
our lack of participation raises what dennis believes is the common misconception that ai will lead to doomsday scenarios with little human interaction and mass unemployment
we all read the same blogs asserting that creating ai is like summoning the devil i just don t believe that no one has ever come up to you and congratulated you on scheduling a meeting it s a task we are given when we don t have anyone else to do it there is no creativity required i can t play out a scenario where we end up worse
dennis believes that ai will free us to do the things that we excel at and are passionate about like brainstorming ideas creating art or leading our teams artificial intelligence is an agent for change enabling us to catalyze on our creative pursuits he says it will never replace human ingenuity
to follow along with amy and learn about the future of ai subscribe to x ai s blog where you can learn about topics like how to think about ai agents in the future and sign up for the waitlist here
originally published at www voices com
voices is a community for entrepreneurs to grow their businesses and design their lives
we take our rights for granted we figure they are a regular part of life we also assume we will continue to have these rights and privileges forever
but what if we only have these rights because we were born at the right time in the right place what if these rights and privileges only exist because they make us more valuable to the state said another way we get them because they make us better workers
if this is true does it mean in time things will change what if our economies stop functioning the way they do could these motivations disappear if collected taxes reduce or governments run out of cash will they stop protecting us
even the most fundamental right the right to vote comes from the idea that we are valuable to our countries in exchange for working we have the right to have our voices heard
robots and ai are poised to take over the world by doing most of the work will we be valued for our ability to work when a computer can do it better if this were to happen we would stop being valuable to the economy if we aren t of value our opinions will stop mattering as well
in canada we have what we call free health care though we all pay for it the main reason our governments use our tax dollars to pay for this service is that it helps us work better in turn working better is of value to the corporations that pay taxes to the government so it works out
if we get sick the health care system repairs us so we can return to work when companies no longer need us they won t want governments to pay for our healthcare the same reasoning would go for education and public transit
today we can already see this happening in ways homeless people tend not to contribute to the economy so they slip through the cracks in a sense they become invisible
in practice without an address it is difficult to vote even worse it is hard to get a job or an id as people become useless they fall away from societal support
proximity also relates to our consciousness of people as we see people less we have fewer thoughts about them and their importance to us decreases seeing people as useful is unfair but is often how our social connections work
on a grand scale as more jobs get replaced by robots and ai more humans will be forgotten people in general will become less valuable as they will provide less value
is there an easy way out of this situation will there be a future for regular people who don t create ai and robots
some companies will try to slow down this transition due to its cost but at some point it will become impossible to avoid letting the robots take over
in the future owning a robot or ai may be the only way to make money
even worse the people with all the money now will also have all the robots and ai with this the gap between the rich and poor will grow even more extreme
this future sounds scary but is there something we can do to avoid it what can we do to prepare
we need a better democracy also we need a political system where people matter more than money and efficiency we need to figure out better ways to reward people for the value they create
the world needs more amazing people and amazing people will save the world click the link below to receive my free ebook about ways to be amazing and a checklist how amazing are you
free ebook and checklist
originally published at abraintrust com
trying to save the world and be more amazing get my free ebook and checklist at http abraintrust com
by aditya
adityatheeditor outlook com
adityawrites outlook com
the fear of machines taking over has been debated for centuries through the medium of the fictional and facts genre there is hardly a bridge between the two in the terminator franchise we see how machines or robots will be sentient enough to perceive their makers as a threat
as time and technology have progressed the endeavor is not only to produce machines that can do work times faster than humans but they are trying to add features like problem solving decision making curiosity and deviating from the path as well it is about putting emotion in an otherwise empty hollow metallic creature or simply called as artificial intelligence
for such situations there will always be two schools of thought one which feels that excessive use of machines shrinks our otherwise organised brain which functions faster than any ai the other school of thought will argue that by letting the ai do the menial work we can use our natural cpu for other work where the ai might be conflicted
a neutral observer would simply point out that machines were created for the benefit of humans it is an aid from the wheel printing press to the telephone the telegram mobile phone and computers fax machines etc just as it inherent for humans to improve as one grows up but we are not flawless so our creation will suffer from the same
there has been a sudden rush to yearn for a machine less world but those who advocate such ideas for them machines include only mobile phones and computers but this is obviously a misconception on their part if we were to exclude all machinery from our existence that would have to include the pen the paper essentially every stationary item our shoes clothing shelter but then even nomads had some sense of technology when they indigenously made swords and arrows from whatever they could collect in the end everything we use is technology and we should not be myopic about the same the digital analogue rivalry is just the tip of the misconception if we feel that paper files are creating a mess then just digital uploading is not enough if we cannot organise on our tables that infliction will carry to the computer as well
the saying that humans are social animals is contradictory we cannot be in a community yet display animal or uncivilized behaviour at the same time one does not have to fear technology as they were meant to do aid us and engage in menial work if it is artificial it cannot be intelligence as we see two contradictory terms come together everything digital has been borrowed from the analogue people still wear a wristwatch despite the time being displayed on the phone so this fear will extinguish quickly the commuter does not make up data it only computes it stores it these debates just let our emotions and nostalgia about certain simple year s fly high even when unnecessary
democratization of artificial intelligence microsoft s promise to take the ai and machine learning from the ivory towers and make it accessible for all is starting to take shape quite effectively let s face it resource constraints around ai ml is a real problem most companies with real world ai use cases just don t have enough runway to build their own artificial intelligence offerings and microsoft cognitive services provide a sophisticated yet easy to use abstraction which fills this gap microsoft has also announced ai as an mvp category http aka ms aimvp for those creating intelligent apps bots voice txt spch and ai algorithms
being a microsoft mvp for data platforms i have had the front row seat to see how cognitive services a collection of powerful apis and toolkits unfold to fulfill the promise of ai democratization among top ai and machine learning related capabilities discussed at build i d consider
as top contenders with video index service as a close runner up
custom vision service
computer vision service has been part of cognitive services since the inception however this has been significantly enhanced by introducing active learning and custom models in the current update the api now offers the capability to upload your own image datasets to create custom vision models which becomes part of a feedback loop and helps to improve the underlying classification accuracy
https customvision ai
custom decision service
custom decision service provides a contextual decision making api that sharpens with experience essentially providing an abstraction over cognitive services reinforcement learning capabilities which helps adapts the content in the application think personalized interfaces a b testing content recommendations to respond in real time
custom decision service
multiworld testing decision service
azure batch ai training
batch ai training enables ai and machine learning developers to start training their customized deep neural networks using any framework yes not just cntk tensorflow and caffe
video index service
a ubiquitous use case for entertainment advertisement and media verticals like cognitive services image api video index service works on moving pictures to identify faces voices and emotions from captions to targeted advertisement to discovering relevant or irrelevant contents to avoid the service offers audio transcription video indexer face tracking and identification speaker indexing visual text recognition voice activity detection scene detection keyframe extraction sentiment analysis translation visual content moderation keywords extraction and annotation
https vi microsoft com
food classification with custom vision service
the cognitive services are classified into categories including vision speech language knowledge and search these broader categories offer further specific sub apis in the vision group we see an amazing collection of powerful computer vision apis around content moderation intelligent video processing video indexing face amp emotion api as well as the long awaited and newly minted custom vision service which allows users to upload their own images to create models
in speech custom speech service helps recognize variety of speaking styles works with background noise and customized vocabulary bing speech api speaker recognition api and translator services are provided the live demo of powerpoint translator service is definitely one of the build highlights
language understanding intelligent service luis is one of the marquee offerings in cognitive services which contains an entire suite of nlu nlp capabilities teaching applications to understand entities utterances and genera commands from user input other language services include bing spell check api which detect and correct spelling mistakes web language model api which helps building knowledge graphs using predictive language models text analytics api to perform topic modeling and do sentiment analysis as well as translator text api to perform automatic text translation the linguistic analysis api is a new addition which parses and provide context around language concepts
in the knowledge spectrum the recommendations api to help predict and recommend items knowledge exploration service to enable interactive search experiences over structured data via natural language inputs entity linking intelligence service for ner disambiguation academic knowledge api academic content in the microsoft academic graph search qna maker api and the newly minted custom decision service which provides a contextual decision making api with reinforcement learning features search apis include autosuggest news web image video and customized searches
some of the labs projects discussed during build includes project prague for gesture based controls nanjing project for isochrones calculations travel time project johannesburg for route logistics project cuzco for event associated with wikipedia entries project abu dhabi for distance matrix and project wollongong for location insights
i have very little reason to doubt satya nadella s claim that software bots will be as big as mobile apps there is already evidence of blurring lines as most applications use ai and machine learning as inherent part of their offering microsoft bot framework has also been upgraded this open source bot builder sdks helps build dialogs and integrates with cognitive services to see hear interpret and interact in more human ways
i have thoroughly enjoyed working with the bot framework and it provides variety of features including building the skype bots bing building bots for teams in office and skype for business bots the cognitive capabilities include features like bot smarts language understanding and qna maker the framework also offers tools like emulator which features debugging for mac windows and linux a channel inspector to show how the messages may look like on multiple channels and message types adaptive cards for conversation cards as well as payments request api and analytics on the bot usage
the next generation of ai chatbots amp cognitive services
microsoft continues ai push with expanded bot framework new cognitive services
hci classifies the ability of the computers to understand what a person wants as one of the key problems figuring out the pieces of information relevant to the intention is the key microsoft luis our language understanding intelligent service now enables building language models intents entities to understand actions entities and utterances luis is not specific to the bot framework but can be used as a general offering
azure batch ai training is now offered for training customized deep neural networks on azure the preview allows and this is the kicker here to train models using any framework including microsoft cognitive toolkit tensorflow and caffe at scale across clustered gpus
acknowledgements
images courtesy of microsoft corporation and adnan hashmi
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
neural networks tackle a large spectrum of applications like object recognition detection and semantic segmentation in image classification a neural network predicts the object inside the image to resolve confusing images with multiple objects as in the next figure the top predictions are utilized
but the top five predictions metric is different from the network confidence in its predictions the network uncertainty is a quantitative metric revealing the network confidence in its prediction standard networks can easily classify the next digits as four maybe the left image is a nine but they are incapable of providing a prediction uncertainty measure for the next images we expect higher uncertainty for the left image compared to the neat right image
dropout is a well established procedure to regularize a neural network and limit overfitting it is first introduced by srivastava et al using a branch prediction averaging analogy random neuron dropping during training only reduces the network generalization error
the dropout as a bayesian approximation proposes a simple approach to quantify the neural network uncertainty it employs dropout during both training and testing the paper develops a new theoretical framework casting dropout in deep neural networks nns as approximate bayesian inference in deep gaussian processes the framework is developed for both classification and regression problems this article highlights the paper finding and its applications for simplicity purpose regression is utilized in the following examples yet classification networks are backed as well
a regression neural network with dropout enabled during testing generates a different output every forward pass for the same input in the figure below the same input is passed six times and the network regresses to the paper mathematically shows that these multiple passes are equivalent to monte carlo sampling thus the first and second moment mean and variance provides the network s output and uncertainty respectively in this example the network output equals and its uncertainty is high variance standard deviation indicates high network uncertainty and vice versa a quantitative uncertainty measure is valuable especially if further decisions are based on the network output human intervention is one way to address high uncertainty outputs
the theoretical framework employs a dropout layer before every weight layer as a bayesian inference approximation the dropout rate is a hyper parameter that needs to be tuned a small dropout rate eliminates the monte carlo sampling utility a big dropout rate can lead to divergence or at least require more iterations to converge so a mid range rate like is reasonable optical flow and depth estimation are important regression problems in autonomous navigation where uncertainty estimation is valuable
beyond uncertainty estimation the paper utilizes its finding in a different application it utilizes uncertainty estimation to tune the neural network hyperparameters and reduce the generalization error hyper parameters are tuned using validation splits by employing a hyper parameter grid search and measuring the classification accuracy or euclidean loss metrics the best hyperparameters get selected in this paper uncertainty is employed as an extra metric besides accuracy to tune hyper parameters like weight regularization coefficient a similar followup work by kendall et al used uncertainty to learn how to weight multi task networks a multi term loss function for multiple objectives tasks has multiple weighting hyper parameters as in the next equation as the number of objectives increases tuning these weights becomes cumbersome using the naive grid search
loss l w l w l
uncertainty quantification using dropout is the paper core contribution a lot of applications and follow up work are based on this finding in the medical field nair et al measure uncertainty evaluation for lesion detection and segmentation networks in autonomous navigation it enables semantic segmentation and depth uncertainty estimation gal el at employ uncertainty estimation for active learning to boost performance from small amounts of data
my comments
dropout a simple way to prevent neural networks from overfitting
what uncertainties do we need in bayesian deep learning for computer vision
bayesian convolutional neural networks with bernoulli approximate variational inference
a theoretically grounded application of dropout in recurrent neural networks
multi task learning using uncertainty to weigh losses for scene geometry and semantics
exploring uncertainty measures in deepnetworks for multiple sclerosis lesion detection and segmentation
deep bayesian active learning with image data
i write reviews on computer vision papers writing tips are welcomed
on june the forum for future medical technology and artificial intelligence conference hosted by bio valley was held in shanghai the goal of the conference was to share and discuss the development and application of artificial intelligence in the medical field
the panel of speakers at the conference included prof jianwei zhang director of the institute of the multi modal technology systems and professor at the university of hamburg in germany mr ray zhang founder and ceo of airdoc mr fabao zhang chairman of shanghai metz pharmaceutical technology co mr xubo hu the managing partner at qiming venture partners
since the discovery of x ray in x ray has been widely used to examine the human body to assist in the diagnosis of diseases laying the basis for radiological and medical imaging medical imaging has now become the most common diagnostic diagnostic tool
over the past few decades medical imaging technology in china has developed rapidly however imaging specialists have been in short supply and mainly concentrated in large hospitals of large cities many small and medium size cities do not have adequate imaging diagnostics resources patients in smaller cities have found it necessary to travel to big cities in order to seek proper medical treatment
airdoc aims to solve the problem of inadequate medical imaging resources by leveraging scalable technology artificial intelligence airdoc equips many smaller community level health care institutions with ai medical image recognition capability previously only available at the best hospitals
in the years since the conception of artificial intelligence lack of computing power and immature algorithms impeded its development in the advent of deep learning brought significant revival to artificial intelligence in the emergence of alexnet brought about a turning point in ai at the large scale visual recognition challenge ilsvrc alexnet bested the previous year s top error by percentage points ever since artificial intelligence in the field of image recognition has constantly been making and breaking records
in recent years articles appearing in nature jama science and other authoritative medical journals have begun writing about using artificial intelligence to solve medical problems for example artificial intelligence identifies skin cancer appeared on the cover of nature science magazine reported on computers predicting heart attack at higher accuracy rate than that of human doctors etc meanwhile major chinese hospitals have also begun to seriously study clinical applications of artificial intelligence
ray zhang asserts that artificial intelligence has virtually limitless possibilities in the medical field a few examples besides medical imaging include virtual nurse assistant health management medical risk analysis drug extraction auxiliary diagnosis and medical research but medical artificial intelligence is still in its infancy but its role in medical imaging recognition is well on its way
in medical image recognition the development of artificial intelligence requires massive numbers of medical images to generate algorithm models data volume and data quality are critical high data volume increases the model s inclusion rate while accurate data and annotations ensure high accuracy of the model s training and test sets
ray zhang dalei contends that within the next years artificial intelligence will play a critical role in the medical field artificial intelligence will be the core driving force behind the next revolution in medicine ai can thoroughly analyze and aggregate medical knowledge to help provide higher quality clinical advice
with its comprehensive inter disciplinary integration ai is set to facilitate the evolution of economic patterns by transforming across commercial financial and medical industries
airdoc is a deep learning based algorithm services company providing ai medical solutions
china has the world s largest population of the blind and visually impaired data shows that china has about million patients with myopia million glaucoma patients million cataract patients and million fundus neovascular disease patients ametropia glaucoma and cataracts and other blinding diseases gradually show a growing trend among younger people to better promote eye health china s national health and family planning commision issued the thirteenth five year plan for national eye health to
artificial intelligence and deep learning has advanced to the point where machines can simulate the human thought process this advancement has subsequently led to the rapid development of artificial intelligence in medical image recognition which is now used to identify and diagnose eye diseases
on august wenzhou medical university eye hospital zhejiang province eye hospital and the leader in medical ai airdoc announced a joint vision research and development center at the signing ceremony the two sides announced that they will commit to the developments and advancements in the field of intelligent optometry applications
in attendance at the signing ceremony were wenzhou medical university eye optic hospital dean qu jia airdoc founder and ceo ray zhang airdoc chief medical officer yuzhong chen airdoc vp of marketing richard zhang among dozens of others
the two sides will jointly establish a ai powered intelligent eye vision center to research and develop intelligent eye disease imaging and intelligent eye examination systems leveraging ophthalmic data and ai applications from both parties
previously airdoc had worked with the wenzhou medical university eye hospital to develop a children s vision change prediction model airdoc successfully analyzed the results of optometry results relative to age trends for example years are the most critical age with regards to vision changes airdoc s algorithm can predict future vision changes based on current age and vision results
for this cooperation wenzhou medical university eye hospital president qu jia said professional work should be left to the professionals as the hospital looks to develop medical applications of artificial intelligence it makes sense to take a cooperative approach
according to qu s view hospitals need to leverage the right players in advanced technology this avoids the situation of professional work being done by non professionals leading ultimately to less than desirable results the eye optometry hospital is a professional in the field of medicine and airdoc is a professional in the field of artificial intelligence which is the basis of cooperation between our two sides
qu admits that there is still a long way to go for artificial intelligence in clinical application but proven potential show good prospects for the development of new technologies we should make full use of existing resources to actively explore and research
airdoc founder and chief executive officer ray zhang dalei the two sides will leverage their respective expertise to jointly promote the organic combination of artificial intelligence technology and ophthalmic clinicians to optimize the doctor patient relationship
eye vision artificial intelligence applications
the first collaborative project is a smart cataract surgery platform
in china about million people each year undergo cataract surgery airdoc builds on china s cataract knowledge base based on massive clinical data and develops specific solutions based on different eyes to assist physician in making surgical decisions
the second project is a keratoconus intelligent assisted diagnosis research conducted by wenzhou medical university eye hospital and airdoc is based on massive clinical data to develop an intelligent auxiliary diagnostic model this diagnostic model is expected to help with rapid screening of the various stages of keratoconus cases
intelligent ophthalmic diagnosis is the third area of collaboration today the ophthalmic hospitals are overcrowded with long lines for patients resulting in poor patient experience as well as overwhelmed doctors the plan is to leverage artificial intelligence to solve this problem artificial intelligence can quickly help refer patients to the appropriate type of doctor so as to enhance the efficiency of doctors saving patients wait time
the last collaborative project is juvenile myopia intelligent progression prediction
china s juvenile myopia rate ranks first in the country hampered by the amount of data and methods accurate myopia progression prediction is difficult
airdoc built an ai model by using massive data from the eye hospital of wenzhou medical university the model is used to predict myopia progression in year olds spanning from their current to years of age
speaking of data mining wenzhou medical university eye hospital information management director wang xiaoxing said most of the detection and data processing equipment have been well structured the multi device data has already been integrated into the information management system with the dicom agreement we will be able to transmit airdoc s ai information through the hospital system of course it has the benefit of building on over years of the hospital s information technology platform
zhang dalei said of the business model at this stage the entire industry is absolutely overheating and we certainly hope to make it big but airdoc is not simply just about business we hope to help the hospital in scientific research clinical treatment efficiency to solve the problem of scarce domestic medical resources
integrating ai into medicine is a long term endeavor so businesses must be patient now many artificial intelligence companies have surfaced in the field of cancer and the ophthalmic market is also growing as long as we can create a real product that can create value the business aspects need not worry about business opportunities
airdoc has made great progress in ai the fields of ophthalmology dermatology cardiovascular neurology and so on with airdoc involved in research in these diseases its business model product promotion profit model will bring us some insight into the field of artificial intelligence
airdoc is a deep learning based algorithm services company providing ai medical solutions
another ces passed by and we saw a bunch of new smart cars with self driving capabilities what all of them had in common was how they were trying to be the center of your digital experience
byton for example wants to track many aspects of your health and show it on the large screen on the dashboard for you to see they are also trying to be a hub for your music and entertainment some of the car manufacturers are also insisting on developing their own personal assistants in the car
but there s a large problem with that building a new platform is difficult specially for a car manufacturer apple google and microsoft and more recently amazon have managed to create their own platforms with varying levels of openness and compatibility with each other apple insists on iphone owners using their appstore for all of their app needs google does the same thing on android with play store building a personal assistant might be getting easier and easier with advances in machine learning and human language processing but one main problem remains
all of this is resulting in a fragmentation in the industry and that makes it very difficult for developers to develop and maintain their applications for those platforms
netflix is not going to develop an app for byton then another one for mercedes then another one for tesla and then another one for any other car manufacturer that thinks it s a clever idea to build their own platform even if they do a partnership and decide to make an app for a couple of these car manfucaturers do you think they would put the time in mainataining these apps and giving them regular updates car manufacturers already suffer from not getting regular updates and the consumers are used to monthly app updates on their smartphones if the car industry doesn t realize soon that they need a unified approach to this instead of fragmenting the industry we re all going to end up with really bad user experiences in our shared cars
remember when instagram didn t make an official app for blackberry and asked them to remove any third party instagram apps on the platform because they were violating their terms of use that s how it s going to feel driving one of these future self driving cars it s going to feel like we re using blackberries
apple and google have taken attempts to streamline the experience with android auto and carplay but they seem to not be getting much traction as car manufacturers are realizing that there s a huge potential to make money from the infotainment systems in their cars when they are self driving they would have the user s attention and that presents the opportunity to show them ads or have them subscribe to their services
but here s the problem if the infotainment system in my car is going to suck and not have all of my favourite apps i m just going to start bringing my ipad to the car and mounting it to the dashboard
so unless all these car startups actually want all of their customers to mount an ipad over their complicated dashboard entertainment hub health monitoring attention seeking displays in their cars they better get their acts together and start integrating with systems that already exist ios android windows and macos
cars will never be the center of our digital world because we are not always en route but when we are they need to integrate with what we are already doing and carrying with ourselves i want to get in my car and continue what i was watching on my iphone but now on the bigger display on the dashboard and when that happens my phone simply turns into the remote for the screens the passenger wants to get in and continue browsing instagram on their android but now on the larger display each passenger gets their own share of the display if we decide to watch something together then it would be in the middle
so please stop trying to be the next smart device in my life and start embracing being a peripheral to your customer s already existing digital world
signed everyone who s excited about self driving cars
ui ux motion designer www alborz design
by charlotte kng
even before its official app launch in september pet s design and use case of artificial intelligence ai and machine learning has proven its worth and recently clinched a place as one of the top apac machine learning solution providers of as judged by cio advisor its novel idea of incorporating artificial intelligence into a digital companion chatbot and tertiary option recommender took the world by storm and leading innovation magazine cio advisor sure isn t going to let that slide without highlighting that to its rich profile of tech savvy readers
cio advisor is an established publication that prides itself best in identifying leading industry insiders and experts not forgetting unique solutions and services that are foreseen to transform apac businesses and enhance the legacy system with its wide network and extensive research in recognizing game changing individuals and projects within the innovation and tech space a slot on cio advisor s top listings has never been known as an easy feat cio advisor often covers prominent industry experts including the likes of nick wilkinson ceo of binary tree ryan wu ceo of qihan as well as vikash varma ceo of argyle data with pet soon to join the hall of fame when the top apac machine learning solution providers get coverage in its september issue
the full article will feature mr wilson wang pet s founder and ceo alongside other esteemed rankers on the list as they discuss how their machine learning solutions are set to revolutionize and disrupt the world with their core stemming from a very niche and novel arm of technology the blockchain pet is not only conquering the machine learning aspect of things it will push boundaries and change the educational game by introducing a whole new level of security transparency and decentralization in the storage and analysis of academic related data creating a more inclusive space for all learners alike
token sale
pet s private token sale kicked off earlier last month and will run until the end of august early bird incentives for the public pre sale will be through bonus tokens computed as follows
bonus tokens from september to september
bonus tokens from september to september
bonus tokens from september to september
bonus tokens from september to september
the official token generation event will be on the st october reach out to pet s management team at support opetfoundation com for further information about their private sale
about pet
pet is a singapore based company focusing on the development of an ai companion chatbot that is capable of learning high school curriculum and revision assistance it also offers a digital companion tuition service to assist in students revision efforts as well as recommend suitable tertiary institutions and courses of study globally via collected user data stored on its unique blockchain solution facilitating a seamless tertiary college application and admission validation pet also empowers an accountable way of education related philanthropy
www opetfoundation com
about cio advisor
cio advisor has culminated as the leading print platform offering a fresh aspect in understanding the latest innovations and technologies in the apac region following a peer to peer learning approach cio advisor spearheads in highlighting industry s latest trends and technologies and brings forth the ideas and values of industry leaders to assist insurance experts to established corporations alike
https www cioadvisorapac com
bringing ai and blockchain technologies into education pet is revolutionizing students lives helping them to reach their full potential
a blockchain project to enable seamless tertiary amp college application and admission
like a musical maestro who seems to possess an inexplicable air of magic artificial intelligence is often attributed with a magical quality beyond human comprehension
while this misattribution may be acceptable in the world of music it is dangerous in the context of ai in a democracy where fundamental decisions must be made by its citizenry without a familiarity with ai and how it works how can a democratic population make informed decisions further how can such a population protect itself from exploitation by ill intentioned corporations and other entities
let s start by clearing up confusion ai is not magic it is applied calculus which applied destructively can be dangerous in a trillion dollar flash crash led by auto trading bots an implementation of autonomous ai caused a point drop in the dow jones in minutes in an even more insidious manner ai assisted decisions can lead to outcomes that contravene our basic societal values like microsoft s ai tay which became wildly racist within days of going online ai can reinforce existing biases as it did in idaho where the aclu is currently fighting for the rights of idahoans who without justification had their medicaid assistance cut by
despite its potential negative consequences however ai has boundless positive potential some people s limited encounters with ai in the media with its sci fi wizard of oz false feeling of power may underestimate ai s possibilities the same computer that ostentatiously beat the world s best jeopardy players in the day cracks medical mysteries at night curing and diagnosing diseases left and right asimo a humanoid robot powered by ai will revolutionize search and rescue missions uber google maps and even commercial airline flights use variations on ai tesla bmw ford gm and many others have released autonomous car programs which brings me to my final point
there is a classic and difficult question in ai imagine a tesla model x is approaching an intersection it s foggy and the car s sensors can t see a crowd of people until it is too late the car decides in a fraction of a second should it drive into the crowd killing bystanders or swerve into a pole killing the car s occupants without an informed populace making democratic decisions car companies will decide the answer
despite the complications we can t ignore this problem
it is estimated that autonomous ai cars could save lives per year there is a balance that can only be evaluated when we understand the underpinnings of how ai works and what it can and cannot accomplish elon musk understands the great possibilities ai presents but he also warns that we must regulate it before it s too late on the other side of the ocean the uk parliament has discussed many of the issues around ai but has decided to wait before taking decisive action
an educated stance on ai is necessary for making good decisions as citizens in a democratic society ai is here and it is making decisions about what you see in the world whether you are eligible for a bank loan and how you move through the world ai is saving lives in massachusetts general hospital saving lives at the wheel and flying thousands of travelers through the air every day yet the number of people who can properly describe its consequences behavior or internal functioning is but a handful an educated citizenry is vital for survival as a free people
let s begin to really focus on educating the american people about ai
the subversionist is a publication by fund that features stories of people who are in protest of something they care deeply about what are you rallying against
here s how the rest of us can do meaningful things with artificial intelligence or machine learning since all of the current ai experts are already working for google and facebook
first and foremost i m going to argue that you don t necessarily need a phd to be an ai expert
in order to get a phd you need to have completed a doctoral thesis which is a lengthy research project usually mixed with additional education done with close supervision by another academic this is in general a good thing we want research we want knowledge we want people to get phds
in the world of machine learning and artificial intelligence phd work often centers around developing new algorithms to accomplish more and more computationally complex things perhaps if we can boost the accuracy of a face detection algorithm from to we ll have accomplished something worthwhile
in the world of practical ai such intense research on algorithms and new methods of computation take a long time to become useful because they are often not optimized for business nor should they be
today right now at this moment there are a plethora of apis and machine learning tools that can deliver a tremendous amount of value all you need to do is follow a set of best practices that doesn t require years of research to pursue
this is something entrepreneurs developers and founders do really well we don t have time to do something for the sake of doing something we have to solve a real world problem machine learning is great for doing that but only if your problem is well defined and isn t just predict the stock market
always start small and work your way up from there for example maybe you want to tag people in photos your customers are uploading to your platform or flag user submitted news articles ahem reddit as opinionated or biased
both of these use cases can be pretty easily accomplished today with off the shelf apis and tools that don t require any machine learning engineering knowledge whatsoever
if you re training a face recognition system to recognize your customers or trying to classify news articles just make sure your training data meets some simple criteria
don t worry about the algorithm or accuracy as much as you worry about deployment and scalability machine learning should run like any other software in your stack it should be fault tolerant lightweight and owned managed by you not outsourced to someone else
you might get some false positives or false negatives you might have some variation in performance and you might see errors the best implementations of machine learning are not so because of accuracy but because of how they handle these exceptions when apple photos gets someone s face wrong it lets you change it and thereby trains itself on that change to be better
you can and should do this to
here are some of my favorite diy out of the box no data science required tools
machine box runs on premises lets you train with minimal or no data at all start with pre trained models tune the models on the fly or build your own very simple api full disclosure this is my company so i hope you pick this one
google vision api runs in the public cloud has some training capabilities extremely accurate image recognition medium to simple api
azure vision api also runs in the public cloud some training capabilities massive pre trained celebrity recognition database simple api
aws rekognition public cloud endpoint good with face detection api is not as easy as azure but still pretty easy
practice practice practice this is your data your use cases your niche your market you need to experiment there s no grand machine learning model that will solve all the world s problems the best models are the smaller finely tuned models that run just on your dataset
spend some time cleaning your data make sure it is a really good subset of the data you plan on having your machine learning model make predictions on later and for god s sake don t expect it to be perfect the first time around
the more iterations you go through the more models you train the more you experience the more likely you are to see success face recognition not doing what you want try altering the training images or using freeze frames from your own data assuming its video thats where face recognition usually gets tricky accuracy only on detecting biased news articles find more articles or deploy your model and crowdsource the answer from your users
you can do this phd mba msc ba bs ged or not
co founder machine box exited machine learning superfan business development agile product owner author father amateur programmer
let s get started
the most common problem we face while starting with data science or machine learning is from where to start even i got stuck with the same question but with time i learned about it its algorithm and about how it works but it was very slow that s the point i was very slow i spent a lot of time understanding it and then was pushed back since my basics were not clear so here i m with a tutorial that can lead you to from a beginner to a pro in machine learning i will be updating you guys with a blog and a tutorial on github every week
things we will be covering in the tutorial series
the codes of all these will be available at github
business applications machine learning can be used in business analysis work as well in spam email detection stock prediction natural language processing has proved to be very efficient in the field of machine learning
there is endless use of machine learning it s heavily upon the coder how he she implements it before we get started with machine learning it is also important to know the basics of python so i just made a tutorial which is enough to get you guys started with data science
python basics
there are certain simple things which we should remember before starting with python
let us see a hello world program in python
step open your terminal and type python in case you don t have python follow this link to install it on your system windows linux mac
step if you have python installed in your system then type python on your terminal and press enter
wait but we haven t included any header file so are we wrong
well no as discussed earlier there is no need to include any header files initially isn t that simple
this just notebook gives a brief explanation of python basics
link to the code python basics
pandas
pandas is one of the most efficient libraries for data science in python it makes handling of dataset very easy for the developer the problem developers face without pandas is that it requires manually handling each and every part of the dataset like columns rows its size etc but pandas has proved to be one of the most efficient libraries in the field of data science it automates the loading of data into memory very quickly basically used for data manipulation and analysis a quick overview of pandas is shown in below notebook to know about jupyter have a look on the below notebook
numpy
numpy is a library adding support for large multi dimensional arrays and matrices along with a large collection of high level mathematical functions to operate on these arrays
so this was all about chapter of go ml tutorial link to the codes link
thanks for your time we hope that you liked our first part of go ml tutorials follow me on github for further updates on this course
linkedin
data scientist and researcher
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
generative models allow a computer to create data like photos movies or music by itself
a little over a year ago alec radford building on the work of ian goodfellow published a paper that changed how everyone thought about building generative models with machine learning the new system is called deep convolutional generative adversarial networks or dcgans for short
dcgans are able to hallucinate original photo realistic pictures by using a clever combination of two deep neural networks that compete with each other all of these pictures of bedrooms were dreamt up by a dcgan
ai researchers care about generative models because they seem to be a stepping stone towards building ai systems that can consume raw data from the world and automatically build understanding from it
but let s use generative models to do something a bit more silly make artwork for bit video games
so why exactly are ai researchers building complex systems to generate slightly wonky looking pictures of bedrooms
the idea is that if you can generate pictures of something you must have an understanding of it
look at this picture
you instantly know this is a picture of a dog a furry thing with four legs and a tail but to a computer the picture is just a grid of numbers representing the color of each pixel the computer has no understanding that the picture represents a concept
but now imagine that we showed a computer thousands of pictures of dogs and after seeing those pictures the computer was able to generate new pictures of dogs on its own including different dog breeds and pictures from different angles maybe we could even ask it for certain types of pictures like a side view of a beagle
if the computer was able to do this and the pictures it produced had the right number of legs tails and ears it would prove that the computer knows what parts go into making up a dog even though no one told it explicitly so in a sense a good generative model is proof of basic understanding at least on a toddler level
that s why researchers are so excited about building generative models they seem to be a way to train computers to understand concepts without being explicitly taught the meaning of those concepts that s a big step over current systems that can only learn from training data that has been painstakingly pre labeled by humans
but if all this research results in programs that generate pictures of dogs how many years until we get the first computer generated dog a day calendar as a side effect
and if you can build a program that understands dogs why not a program that understands anything else what about a program that could generate an unlimited number of stock photos of people shaking hands i m sure someone would pay for that
ok maybe a program that generates bad stock photos wouldn t be that interesting but given the rate of progress in generative models over just the past year who knows where we ll be in or years what happens if someone invents a system to generate entire movies or music or video games
if you look forward years and squint you can already imagine a world where entertainment could be machine generated
the video game industry is the first area of entertainment to start seriously experimenting with using ai to generate raw content aside from the obvious venn diagram overlap between computer gaming and machine learning engineers there s a huge cost incentive to invest in video game development automation given the million budgets of modern aaa video games
we are still in the earliest days of machine learning based generative models and their practical uses are currently pretty narrow but they are a lot of fun to play around with let s see what we can do with one
to build a dcgan we create two deep neural networks then we make them fight against each other endlessly attempting to out do one another in the process they both become stronger
let s pretend that the first deep neural network is a brand new police officer who is being trained to spot counterfeit money it s job is to look at a picture and tell us if the picture contains real money
since we are looking for objects in pictures we can use a standard convolutional neural network for this job if you aren t familiar with convnets you can read my earlier post but the basic idea is that the neural network that takes in an image processes it through several layers that recognize increasingly complex features in the image and then it outputs a single value in this case whether or not the image contains a picture of real money
this first neural network is called the discriminator
now let s pretend the second neural network is a brand new counterfeiter who is just learning how to create fake money for this second neural network we ll reverse the layers in a normal convnet so that everything runs backwards so instead of taking in a picture and outputting a value it takes in a list of values and outputs a picture
this second neural network is called the generator
so now we have a police officer the discriminator looking for fake money and a counterfeiter the generator that s printing fake money let s make them battle
in the first round the generator will create pathetic forgeries that barely resemble money at all because it knows absolutely nothing about what money is supposed to look like
but right now the discriminator is equally terrible at it s job of recognizing money so it won t know the difference
at this point we step in and tell the discriminator that this dollar bill is actually fake then we show it a real dollar bill and ask it how it looks different from the fake one the discriminator looks for a new detail to help it separate the real one from the fake one
for example the discriminator might notice that real money has a picture of a person on it and the fake money doesn t using this knowledge the discriminator learns how to tell the fake from the real one it gets a tiny bit better at its job
now we start round we tell the generator that it s money images are suddenly getting rejected as fake so it needs to step up it s game we also tell it that the discriminator is now looking for faces so the best way to confuse the discriminator is to put a face on the bill
and the fake bills are being accepted as valid again so now the discriminator has to look again at the real dollar and find a new way to tell it apart from the fake one
this back and forth game between the generator and the discriminator continues thousands of times until both networks are experts eventually the generator is producing near perfect counterfeits and the discriminator has turned into a master detective looking for the slightest mistakes
at the point when both networks are sufficiently trained so that humans are impressed by the fake images we can use the fake images for whatever purpose we want
so now that we know how dcgans work let s see if we can use one to generate new artwork for s style video games
let s build a dcgan that tries to produce screenshots of imaginary video games for the nintendo entertainment system or nes based on screenshots of real games
the idea is that if we can generate convincing screenshots of imaginary video games we could copy and paste bits of art from those screenshots and use it in our own retro style video game since the generated video games never existed it wouldn t even be stealing maybe more on this later
video game art in those days was very simple since the nes had such a small amount of memory the games used way less memory than this article takes up programmers had to use lots of tricks to fit the game art into memory to maximize the limited space games used tile based graphics where each screen in the game is made up of just a few usually x pixel repeated graphical tiles
for example the starting screen of the legend of zelda is made up of only unique tiles
here are the tiles for entire the legend of zelda game map
our goal is to create a similar tile sheet for our game because of that we don t really care if the game screenshots we generate look completely realistic instead we re just looking for the shapes and patterns that we can use as x tiles in our game things like stones water bridges etc then we can use those tiles to build our own bit style video game levels
to train our system we need lots of data luckily there are over games for the nes that we can pull from
i used wget to download all the nes game screenshots on the video game museum website sorry for scraping your site after a few minutes of downloading i had a little over screenshots of hundreds of nes games
right now dcgans only work on pretty small images pixels square or so but the entire screen resolution of the nes was only pixels by pixels so that s not a problem to make things simple i cropped each nes screenshot to pixels square
there are several open source implementations of dcgans on github that you can try out i used taehoon kim s tensorflow implementation since dcgans are unsupervised all you have to do is put the data in a folder tweak the basic parameters start it training and then wait to see what results you get
here s what a sample of the original training data looks like
now training begins at first the output from the generator is pure noise but it slowly start to take shape as the generator learns to do a better job
after several more training rounds the images start to resemble nightmare ish versions of classic nintendo games
as training continues further we start to see the bricks and blocks we are hoping to find you can also see screen elements like life bars and even some text
this is where things get complicated how do we know the computer is creating brand new art and not just regurgitating art directly from the training images in two of these images you can clearly see the menu bar from super mario bros and the header bar and bricks from the original super mario bros
regurgitating training data is definitely something that can happen by using a large training data set and not training too long we can try to reduce the chance that this happens but it s a thorny issue and research on it continues
since i m just going for aesthetics i tweaked the model until it produced art that looked original to me but i can t prove that the new art is totally original except by searching the training data for similar art and verifying that there isn t any
with a few hours of training the generated images contained x tiles that looked nice to me i was looking for some variations on a basic stone block brick patterns water patterns bushes and some general spooky looking background atmosphere tiles
next i need to pre process the generated images to the make sure they only used the colors that are available on the nes
then i ll open up the color images in the tiled map editor from there i can easily grab the x tiles that match the aesthetic i want
then inside of tiled map editor i ll arrange those x tiles into a simple level layout reminiscent of the nes game castlevania
i think that looks pretty good keep in mind i didn t touch a single pixel with an image editor every tile came straight out of the dcgan model
next let s throw in the main character and some enemies from castlevania so we can see what this level would look like in action
to get the full effect let s see what the level would look like inside the game with the menu elements added
i think that looks like the nes games that i remember i m not claiming it s the best nes art ever created but it s certainly not the worst
i get really excited about generative models like this the idea of one day cranking out endless artwork with computers is fascinating to me but when i talk to other people about this stuff sometimes the response is is that it that s so basic
there s certainly a lot of hype around generative models right now gans are already being called the future of ai despite being notoriously hard to train and limited to generating tiny images in fact the very best models can currently only generate postage stamp sized pictures of mutant dogs
but a couple of years ago we couldn t do anything close to that we were pretty excited by generated pictures that looked like this
and the technology is improving every single day here s a random paper that came out this week that uses gans to age the faces of people
if things keep improving at this pace it won t be too long before generative models are a mainstream tool helping us create it s a great time to start experimenting
if you want to learn more in depth about generative models and dcgans here are some recommended resources
this article is part of my machine learning is fun series you can check out the earlier parts here part part part part part and part
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in italiano espa ol fran ais t rk e portugu s ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
in part we said that machine learning is using generic algorithms to tell you something interesting about your data without writing any code specific to the problem you are solving if you haven t already read part read it now
this time we are going to see one of these generic algorithms do something really cool create video game levels that look like they were made by humans we ll build a neural network feed it existing super mario levels and watch new ones pop out
just like part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
back in part we created a simple algorithm that estimated the value of a house based on its attributes given data about a house like this
we ended up with this simple estimation function
in other words we estimated the value of the house by multiplying each of its attributes by a weight then we just added those numbers up to get the house s value
instead of using code let s represent that same function as a simple diagram
however this algorithm only works for simple problems where the result has a linear relationship with the input what if the truth behind house prices isn t so simple for example maybe the neighborhood matters a lot for big houses and small houses but doesn t matter at all for medium sized houses how could we capture that kind of complicated detail in our model
to be more clever we could run this algorithm multiple times with different of weights that each capture different edge cases
now we have four different price estimates let s combine those four price estimates into one final estimate we ll run them through the same algorithm again but using another set of weights
our new super answer combines the estimates from our four different attempts to solve the problem because of this it can model more cases than we could capture in one simple model
let s combine our four attempts to guess into one big diagram
this is a neural network each node knows how to take in a set of inputs apply weights to them and calculate an output value by chaining together lots of these nodes we can model complex functions
there s a lot that i m skipping over to keep this brief including feature scaling and the activation function but the most important part is that these basic ideas click
it s just like lego we can t model much with one single lego block but we can model anything if we have enough basic lego blocks to stick together
the neural network we ve seen always returns the same answer when you give it the same inputs it has no memory in programming terms it s a stateless algorithm
in many cases like estimating the price of house that s exactly what you want but the one thing this kind of model can t do is respond to patterns in data over time
imagine i handed you a keyboard and asked you to write a story but before you start my job is to guess the very first letter that you will type what letter should i guess
i can use my knowledge of english to increase my odds of guessing the right letter for example you will probably type a letter that is common at the beginning of words if i looked at stories you wrote in the past i could narrow it down further based on the words you usually use at the beginning of your stories once i had all that data i could use it to build a neural network to model how likely it is that you would start with any given letter
our model might look like this
but let s make the problem harder let s say i need to guess the next letter you are going to type at any point in your story this is a much more interesting problem
let s use the first few words of ernest hemingway s the sun also rises as an example
what letter is going to come next
you probably guessed n the word is probably going to be boxing we know this based on the letters we ve already seen in the sentence and our knowledge of common words in english also the word middleweight gives us an extra clue that we are talking about boxing
in other words it s easy to guess the next letter if we take into account the sequence of letters that came right before it and combine that with our knowledge of the rules of english
to solve this problem with a neural network we need to add state to our model each time we ask our neural network for an answer we also save a set of our intermediate calculations and re use them the next time as part of our input that way our model will adjust its predictions based on the input that it has seen recently
keeping track of state in our model makes it possible to not just predict the most likely first letter in the story but to predict the most likely next letter given all previous letters
this is the basic idea of a recurrent neural network we are updating the network each time we use it this allows it to update its predictions based on what it saw most recently it can even model patterns over time as long as we give it enough of a memory
predicting the next letter in a story might seem pretty useless what s the point
one cool use might be auto predict for a mobile phone keyboard
but what if we took this idea to the extreme what if we asked the model to predict the next most likely character over and over forever we d be asking it to write a complete story for us
we saw how we could guess the next letter in hemingway s sentence let s try generating a whole story in the style of hemingway
to do this we are going to use the recurrent neural network implementation that andrej karpathy wrote andrej is a deep learning researcher at stanford and he wrote an excellent introduction to generating text with rnns you can view all the code for the model on github
we ll create our model from the complete text of the sun also rises characters using unique letters including punctuation uppercase lowercase etc this data set is actually really small compared to typical real world applications to generate a really good model of hemingway s style it would be much better to have at several times as much sample text but this is good enough to play around with as an example
as we just start to train the rnn it s not very good at predicting letters here s what it generates after a loops of training
you can see that it has figured out that sometimes words have spaces between them but that s about it
after about iterations things are looking more promising
the model has started to identify the patterns in basic sentence structure it s adding periods at the ends of sentences and even quoting dialog a few words are recognizable but there s also still a lot of nonsense
but after several thousand more training iterations it looks pretty good
at this point the algorithm has captured the basic pattern of hemingway s short direct dialog a few sentences even sort of make sense
compare that with some real text from the book
even by only looking for patterns one character at a time our algorithm has reproduced plausible looking prose with proper formatting that is kind of amazing
we don t have to generate text completely from scratch either we can seed the algorithm by supplying the first few letters and just let it find the next few letters
for fun let s make a fake book cover for our imaginary book by generating a new author name and a new title using the seed text of er he and the s
not bad
but the really mind blowing part is that this algorithm can figure out patterns in any sequence of data it can easily generate real looking recipes or fake obama speeches but why limit ourselves human language we can apply this same idea to any kind of sequential data that has a pattern
in nintendo released super mario maker for the wii u gaming system
this game lets you draw out your own super mario brothers levels on the gamepad and then upload them to the internet so you friends can play through them you can include all the classic power ups and enemies from the original mario games in your levels it s like a virtual lego set for people who grew up playing super mario brothers
can we use the same model that generated fake hemingway text to generate fake super mario brothers levels
first we need a data set for training our model let s take all the outdoor levels from the original super mario brothers game released in
this game has levels and about of them have the same outdoor style so we ll stick to those
to get the designs for each level i took an original copy of the game and wrote a program to pull the level designs out of the game s memory super mario bros is a year old game and there are lots of resources online that help you figure out how the levels were stored in the game s memory extracting level data from an old video game is a fun programming exercise that you should try sometime
here s the first level from the game which you probably remember if you ever played it
if we look closely we can see the level is made of a simple grid of objects
we could just as easily represent this grid as a sequence of characters with one character representing each object
we ve replaced each object in the level with a letter
and so on using a different letter for each different kind of object in the level
i ended up with text files that looked like this
looking at the text file you can see that mario levels don t really have much of a pattern if you read them line by line
the patterns in a level really emerge when you think of the level as a series of columns
so in order for the algorithm to find the patterns in our data we need to feed the data in column by column figuring out the most effective representation of your input data called feature selection is one of the keys of using machine learning algorithms well
to train the model i needed to rotate my text files by degrees this made sure the characters were fed into the model in an order where a pattern would more easily show up
just like we saw when creating the model of hemingway s prose a model improves as we train it
after a little training our model is generating junk
it sort of has an idea that s and s should show up a lot but that s about it it hasn t figured out the pattern yet
after several thousand iterations it s starting to look like something
the model has almost figured out that each line should be the same length it has even started to figure out some of the logic of mario the pipes in mario are always two blocks wide and at least two blocks high so the p s in the data should appear in x clusters that s pretty cool
with a lot more training the model gets to the point where it generates perfectly valid data
let s sample an entire level s worth of data from our model and rotate it back horizontal
this data looks great there are several awesome things to notice
finally let s take this level and recreate it in super mario maker
play it yourself
if you have super mario maker you can play this level by bookmarking it online or by looking it up using level code ac f c
the recurrent neural network algorithm we used to train our model is the same kind of algorithm used by real world companies to solve hard problems like speech detection and language translation what makes our model a toy instead of cutting edge is that our model is generated from very little data there just aren t enough levels in the original super mario brothers game to provide enough data for a really good model
if we could get access to the hundreds of thousands of user created super mario maker levels that nintendo has we could make an amazing model but we can t because nintendo won t let us have them big companies don t give away their data for free
as machine learning becomes more important in more industries the difference between a good program and a bad program will be how much data you have to train your models that s why companies like google and facebook need your data so badly
for example google recently open sourced tensorflow its software toolkit for building large scale machine learning applications it was a pretty big deal that google gave away such important capable technology for free this is the same stuff that powers google translate
but without google s massive trove of data in every language you can t create a competitor to google translate data is what gives google its edge think about that the next time you open up your google maps location history or facebook location history and notice that it stores every place you ve ever been
in machine learning there s never a single way to solve a problem you have limitless options when deciding how to pre process your data and which algorithms to use often combining multiple approaches will give you better results than any single approach
readers have sent me links to other interesting approaches to generating super mario levels
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
we all know and love google translate the website that can instantly translate between different human languages as if by magic it is even available on our phones and smartwatches
the technology behind google translate is called machine translation it has changed the world by allowing people to communicate when it wouldn t otherwise be possible
but we all know that high school students have been using google translate to umm assist with their spanish homework for years isn t this old news
it turns out that over the past two years deep learning has totally rewritten our approach to machine translation deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert built language translation systems in the world
the technology behind this breakthrough is called sequence to sequence learning it s very powerful technique that be used to solve many kinds problems after we see how it is used for translation we ll also learn how the exact same algorithm can be used to write ai chat bots and describe pictures
let s go
so how do we program a computer to translate human language
the simplest approach is to replace every word in a sentence with the translated word in the target language here s a simple example of translating from spanish to english word by word
this is easy to implement because all you need is a dictionary to look up each word s translation but the results are bad because it ignores grammar and context
so the next thing you might do is start adding language specific rules to improve the results for example you might translate common two word phrases as a single group and you might swap the order nouns and adjectives since they usually appear in reverse order in spanish from how they appear in english
that worked if we just keep adding more rules until we can handle every part of grammar our program should be able to translate any sentence right
this is how the earliest machine translation systems worked linguists came up with complicated rules and programmed them in one by one some of the smartest linguists in the world labored for years during the cold war to create translation systems as a way to interpret russian communications more easily
unfortunately this only worked for simple plainly structured documents like weather reports it didn t work reliably for real world documents
the problem is that human language doesn t follow a fixed set of rules human languages are full of special cases regional variations and just flat out rule breaking the way we speak english more influenced by who invaded who hundreds of years ago than it is by someone sitting down and defining grammar rules
after the failure of rule based systems new translation approaches were developed using models based on probability and statistics instead of grammar rules
building a statistics based translation system requires lots of training data where the exact same text is translated into at least two languages this double translated text is called parallel corpora in the same way that the rosetta stone was used by scientists in the s to figure out egyptian hieroglyphs from greek computers can use parallel corpora to guess how to convert text from one language to another
luckily there s lots of double translated text already sitting around in strange places for example the european parliament translates their proceedings into languages so researchers often use that data to help build translation systems
the fundamental difference with statistical translation systems is that they don t try to generate one exact translation instead they generate thousands of possible translations and then they rank those translations by likely each is to be correct they estimate how correct something is by how similar it is to the training data here s how it works
first we break up our sentence into simple chunks that can each be easily translated
next we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data
it s important to note that we are not just looking up these chunks in a simple translation dictionary instead we are seeing how actual people translated these same chunks of words in real world sentences this helps us capture all of the different ways they can be used in different contexts
some of these possible translations are used more frequently than others based on how frequently each translation appears in our training data we can give it a score
for example it s much more common for someone to say quiero to mean i want than to mean i try so we can use how frequently quiero was translated to i want in our training data to give that translation more weight than a less frequent translation
next we will use every possible combination of these chunks to generate a bunch of possible sentences
just from the chunk translations we listed in step we can already generate nearly different variations of our sentence by combining the chunks in different ways here are some examples
but in a real world system there will be even more possible chunk combinations because we ll also try different orderings of words and different ways of chunking the sentence
now need to scan through all of these generated sentences to find the one that is that sounds the most human
to do this we compare each generated sentence to millions of real sentences from books and news stories written in english the more english text we can get our hands on the better
take this possible translation
it s likely that no one has ever written a sentence like this in english so it would not be very similar to any sentences in our data set we ll give this possible translation a low probability score
but look at this possible translation
this sentence will be similar to something in our training set so it will get a high probability score
after trying all possible sentences we ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real english sentences
our final translation would be i want to go to the prettiest beach not bad
statistical machine translation systems perform much better than rule based systems if you give them enough training data franz josef och improved on these ideas and used them to build google translate in the early s machine translation was finally available to the world
in the early days it was surprising to everyone that the dumb approach to translating based on probability worked better than rule based systems designed by linguists this led to a somewhat mean saying among researchers in the s
statistical machine translation systems work well but they are complicated to build and maintain every new pair of languages you want to translate requires experts to tweak and tune a new multi step translation pipeline
because it is so much work to build these different pipelines trade offs have to be made if you are asking google to translate georgian to telegu it has to internally translate it into english as an intermediate step because there s not enough georgain to telegu translations happening to justify investing heavily in that language pair and it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of french to english
wouldn t it be cool if we could have the computer do all that annoying development work for us
the holy grail of machine translation is a black box system that learns how to translate by itself just by looking at training data with statistical machine translation humans are still needed to build and tweak the multi step statistical models
in kyunghyun cho s team made a breakthrough they found a way to apply deep learning to build this black box system their deep learning model takes in a parallel corpora and and uses it to learn how to translate between those two languages without any human intervention
two big ideas make this possible recurrent neural networks and encodings by combining these two ideas in a clever way we can build a self learning translation system
we ve already talked about recurrent neural networks in part but let s quickly review
a regular non recurrent neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result based on previous training neural networks can be used as a black box to solve lots of problems for example we can use a neural network to calculate the approximate value of a house based on attributes of that house
but like most machine learning algorithms neural networks are stateless you pass in a list of numbers and the neural network calculates a result if you pass in those same numbers again it will always calculate the same result it has no memory of past calculations in other words always equals
a recurrent neural network or rnn for short is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation this means that previous calculations change the results of future calculations
why in the world would we want to do this shouldn t always equal no matter what we last calculated
this trick allows neural networks to learn patterns in a sequence of data for example you can use it to predict the next most likely word in a sentence based on the first few words
rnns are useful any time you want to learn patterns in data because human language is just one big complicated pattern rnns are increasingly used in many areas of natural language processing
if you want to learn more about rnns you can read part where we used one to generate a fake ernest hemingway book and then used another one to generate fake super mario brothers levels
the other idea we need to review is encodings we talked about encodings in part as part of face recognition to explain encodings let s take a slight detour into how we can tell two different people apart with a computer
when you are trying to tell two faces apart with a computer you collect different measurements from each face and use those measurements to compare faces for example we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person
you re probably already familiar with this idea from watching any primetime detective show like csi
the idea of turning a face into a list of measurements is an example of an encoding we are taking raw data a picture of a face and turning it into a list of measurements that represent it the encoding
but like we saw in part we don t have to come up with a specific list of facial features to measure ourselves instead we can use a neural network to generate measurements from a face the computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people
this is our encoding it lets us represent something very complicated a picture of a face with something simple numbers now comparing two different faces is much easier because we only have to compare these numbers for each face instead of comparing full images
guess what we can do the same thing with sentences we can come up with an encoding that represents every possible different sentence as a series of unique numbers
to generate this encoding we ll feed the sentence into the rnn one word at time the final result after the last word is processed will be the values that represent the entire sentence
great so now we have a way to represent an entire sentence as a set of unique numbers we don t know what each number in the encoding means but it doesn t really matter as long as each sentence is uniquely identified by it s own set of numbers we don t need to know exactly how those numbers were generated
ok so we know how to use an rnn to encode a sentence into a set of unique numbers how does that help us here s where things get really cool
what if we took two rnns and hooked them up end to end the first rnn could generate the encoding that represents a sentence then the second rnn could take that encoding and just do the same logic in reverse to decode the original sentence again
of course being able to encode and then decode the original sentence again isn t very useful but what if and here s the big idea we could train the second rnn to decode the sentence into spanish instead of english we could use our parallel corpora training data to train it to do that
and just like that we have a generic way of converting a sequence of english words into an equivalent sequence of spanish words
this is a powerful idea
note that we glossed over some things that are required to make this work with real world data for example there s additional work you have to do to deal with different lengths of input and output sentences see bucketing and padding there s also issues with translating rare words correctly
if you want to build your own language translation system there s a working demo included with tensorflow that will translate between english and french however this is not for the faint of heart or for those with limited budgets this technology is still new and very resource intensive even if you have a fast computer with a high end video card it might take about a month of continuous processing time to train your own language translation system
also sequence to sequence language translation techniques are improving so rapidly that it s hard to keep up many recent improvements like adding an attention mechanism or tracking context are significantly improving results but these developments are so new that there aren t even wikipedia pages for them yet if you want to do anything serious with sequence to sequence learning you ll need to keep with new developments as they occur
so what else can we do with sequence to sequence models
about a year ago researchers at google showed that you can use sequence to sequence models to build ai bots the idea is so simple that it s amazing it works at all
first they captured chat logs between google employees and google s tech support team then they trained a sequence to sequence model where the employee s question was the input sentence and the tech support team s response was the translation of that sentence
when a user interacted with the bot they would translate each of the user s messages with this system to get the bot s response
the end result was a semi intelligent bot that could sometimes answer real tech support questions here s part of a sample conversation between a user and the bot from their paper
they also tried building a chat bot based on millions of movie subtitles the idea was to use conversations between movie characters as a way to train a bot to talk like a human the input sentence is a line of dialog said by one character and the translation is what the next character said in response
this produced really interesting results not only did the bot converse like a human but it displayed a small bit of intelligence
this is only the beginning of the possibilities we aren t limited to converting one sentence into another sentence it s also possible to make an image to sequence model that can turn an image into text
a different team at google did this by replacing the first rnn with a convolutional neural network like we learned about in part this allows the input to be a picture instead of a sentence the rest works basically the same way
and just like that we can turn pictures into words as long as we have lots and lots of training data
andrej karpathy expanded on these ideas to build a system capable of describing images in great detail by processing multiple regions of an image separately
this makes it possible to build image search engines that are capable of finding images that match oddly specific search queries
there s even researchers working on the reverse problem generating an entire picture based on just a text description
just from these examples you can start to imagine the possibilities so far there have been sequence to sequence applications in everything from speech recognition to computer vision i bet there will be a lot more over the next year
if you want to learn more in depth about sequence to sequence models and translation here s some recommended resources
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
almost as long as programmers have been writing computer programs computer hackers have been figuring out ways to exploit those programs malicious hackers take advantage of the tiniest bugs in programs to break into systems steal data and generally wreak havoc
but systems powered by deep learning algorithms should be safe from human interference right how is a hacker going to get past a neural network trained on terabytes of data
it turns out that even the most advanced deep neural networks can be easily fooled with a few tricks you can force them into predicting whatever result you want
so before you launch a new system powered by deep neural networks let s learn exactly how to break them and what you can do to protect yourself from attackers
let s imagine that we run an auction website like ebay on our website we want to prevent people from selling prohibited items things like live animals
enforcing these kinds of rules are hard if you have millions of users we could hire hundreds of people to review every auction listing by hand but that would be expensive instead we can use deep learning to automatically check auction photos for prohibited items and flag the ones that violate the rules
this is a typical image classification problem to build this we ll train a deep convolutional neural network to tell prohibited items apart from allowed items and then we ll run all the photos on our site through it
first we need a data set of thousands of images from past auction listings we need images of both allowed and prohibited items so that we can train the neural network to tell them apart
to train then neural network we use the standard back propagation algorithm this is an algorithm were we pass in a training picture pass in the expected result for that picture and then walk back through each layer in the neural network adjusting their weights slightly to make them a little better at producing the correct output for that picture
we repeat this thousands of times with thousands of photos until the model reliably produces the correct results with an acceptable accuracy
the end result is a neural network that can reliably classify images
note if you want more detail on how convolution neural networks recognize objects in images check out part
convolutional neural networks are powerful models that consider the entire image when classifying it they can recognize complex shapes and patterns no matter where they appear in the image in many image recognition tasks they can equal or even beat human performance
with a fancy model like that changing a few pixels in the image to be darker or lighter shouldn t have a big effect on the final prediction right sure it might change the final likelihood slightly but it shouldn t flip an image from prohibited to allowed
but in a famous paper in called intriguing properties of neural networks it was discovered that this isn t always true if you know exactly which pixels to change and exactly how much to change them you can intentionally force the neural network to predict the wrong output for a given picture without changing the appearance of the picture very much
that means we can intentionally craft a picture that is clearly a prohibited item but which completely fools our neural network
why is this a machine learning classifier works by finding a dividing line between the things it s trying to tell apart here s how that looks on a graph for a simple two dimensional classifier that s learned to separate green points acceptable from red points prohibited
right now the classifier works with accuracy it s found a line that perfectly separates all the green points from the red points
but what if we want to trick it into mis classifying one of the red points as a green point what s the minimum amount we could move a red point to push it into green territory
if we add a small amount to the y value of a red point right beside the boundary we can just barely push it over into green territory
so to trick a classifier we just need to know which direction to nudge the point to get it over the line and if we don t want to be too obvious about being nefarious ideally we ll move the point as little as possible so it just looks like an honest mistake
in image classification with deep neural networks each point we are classifying is an entire image made up of thousands of pixels that gives us thousands of possible values that we can tweak to push the point over the decision line and if we make sure that we tweak the pixels in the image in a way that isn t too obvious to a human we can fool the classifier without making the image look manipulated
in other words we can take a real picture of one object and change the pixels very slightly so that the image completely tricks the neural network into thinking that the picture is something else and we can control exactly what object it detects instead
we ve already talked about the basic process of training a neural network to classify photos
but what if instead of tweaking the weights of the layers of the neural network we instead tweaked the input image itself until we get the answer we want
so let s take the already trained neural network and train it again but let s use back propagation to adjust the input image instead of the neural network layers
so here s the new algorithm
at end of this we ll have an image that fools the neural network without changing anything inside the neural network itself
the only problem is that by allowing any single pixel to be adjusted without any limitations the changes to the image can be drastic enough that you ll see them they ll show up as discolored spots or wavy areas
to prevent these obvious distortions we can add a simple constraint to our algorithm we ll say that no single pixel in the hacked image can ever be changed by more than a tiny amount from the original image let s say something like that forces our algorithm to tweak the image in a way that still fools the neural network without it looking too different from the original image
here s what the generated image looks like when we add that constraint
even though that image looks the same to us it still fools the neural network
to code this first we need a pre trained neural network to fool instead of training one from scratch let s use one created by google
keras the popular deep learning framework comes with several pre trained neural networks we ll use its copy of google s inception v deep neural network that was pre trained to detect different kinds of objects
here s the basic code in keras to recognize what s in a picture using this neural network just make sure you have python and keras installed before you run it
when we run it it properly detects our image as a persian cat
now let s trick it into thinking that this cat is a toaster by tweaking the image until it fools the neural network
keras doesn t have a built in way to train against the input image instead of training the neural network layers so i had to get a little tricky and code the training step manually
here s the code
if we run this it will eventually spit out an image that will fool the neural network
note if you don t have a gpu this might take a few hours to run if you do have a gpu properly configured with keras and cuda it shouldn t take more than a couple of minutes to run
now let s test the hacked image that we just made by running it through the original model again
we did it we tricked the neural network into thinking that a cat is a toaster
created a hacked image like this is called generating an adversarial example we re intentionally crafting a piece of data so that a machine learning model will misclassify it it s a neat trick but why does this matter in the real world
research has show that these hacked images have some surprising properties
so we can potentially do a lot with these hacked images
but there is still a big limitation with how we create these images our attack requires direct access to the neural network itself because we are actually training against the neural network to fool it we need a copy of it in the real world no company is going to let you download their trained neural network s code so that means we can t attack them right
nope researchers have recently shown that you can train your own substitute neural network to mirror another neural network by probing it to see how it behaves then you can use your substitute neural network to generate hacked images that still often fool the original network this is called a black box attack
the applications of black box attacks are limitless here are some plausible examples
and these attack methodology isn t limited to just images you can use the same kind of approach to fool classifiers that work on other types of data for example you could trick virus scanners into recognizing your virus as safe code
so now that we know it s possible to trick neural networks and all other machine learning models too how do we defend against this
the short answer is that no one is entirely sure yet preventing these kinds of attacks is still an on going area of research the best way to keep up with the latest developments is by reading the cleverhans blog maintained by ian goodfellow and nicolas papernot two of the most influential researchers in this area
but there are some things we do know so far
since we don t have any final answers yet its worth thinking about the scenarios where you are using neural networks so that you can at least lessen the risk that this kind of attack would cause damage your business
for example if you have a single machine learning model as the only line of defense to grant access to a restricted resource and assume it can t be fooled that s probably a bad idea but if you use machine learning as a step in a process where there is still human verification that s probably fine
in other words treat machine learning models in your architecture like any other component that can potentially be bypassed think through the implications of what would happen if a user intentionally sets out to fool them and think of ways to mitigate those scenarios
want to learn more about adversarial examples and protecting against them
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
interested in computers and machine learning likes to write about it
k atica roy is a gender economist ceo and founder of pipeline pipeline is a saas platform engineered with artificial intelligence to stop unconscious bias in the workplace and increase financial performance with more than two decades of experience in technology healthcare and financial services roy has a rare combination of expertise and passion for gender equity people analytics and sales operations she pours her knowledge and unique lens into several community and global initiatives including as a former board member of edge of seven and current board member of the university of san francisco s women in leadership and philanthropy book trust and isabella bird community school a member of the cu leeds women s council and the women s foundation of colorado as well as a colorado governors fellow katica is also an industry entrepreneur thought leader and frequent editorial contributor and speaker and in was named a luminary by the colorado technology association
agnes wielgosz katica as a vocal advocate for closing the gender gap in the workplace you bring a data driven view to gender equity how will the artificial intelligence affect businesses in the future
katica roy ai can actually be used for good in fact we can use ai to narrow the gender gap and engender a more diverse and inclusive workplace one specific example pipeline s recommendations engine identifies inequity in pay and promotion recommendations before they reach the employee which allows management to make more equitable decisions it also provides specific recommendations for an employee s pay to ensure employees are paid equitably within the company with every single pay decision
aw does pipeline transparent measurement ensure continual improvement in closing the gender gap
kr yes pipeline s platform ensures that with every decision across the five domains of talent hiring pay performance potential and promotion that employers can move to close the gender equity gap not only can we tell companies their time to gender parity we can get them to gender parity
aw can you please explain the difference between two concepts gender equality and gender equity does pipeline promote equality through equity
kr at pipeline the word equity is dual purpose related to gender and the workplace equity sets the stage for equality as it refers to the fairness of treatment for both women and men according to the their respective needs if equality is the end goal equity is the means to get there for more on this see our blog article gender equity vs gender equality what s the distinction
aw the narrowing the gender gap can unleash massive economic growth how can we leverage new economic gains from closing the gap for a greater social impact
kr as we narrow the gender gap we reduce poverty we increase innovation and we ensure that the next generation has more opportunity that we have these benefits have a flywheel effect that creates more wealth and opportunity across generations
aw gender equity has received significant attention among researchers and development practitioners in recent years why is women s empowerment is necessary for sustainable development
kr there is mounting evidence of the clear economic benefits of gender equity in the workplace in fact in pipeline s own research across companies in countries we found that for every increase in gender equity there is a increase in revenue
aw does promoting women s empowerment disempowering men
kr data shows that gender equity is a economic win for everyone in addition we need men to be a part of the gender equity conversation men are typically the decision makers in both the public and private sector in the u s because of this the role that men play as sponsors and allies along the gender equity path is key
we could add t to the global economy and t to the u s economy by reaching gender equity whether or not you agree that gender equity is an issue most of us can agree it s an economic opportunity changing the narrative around the value of women in the workplace is an opportunity not only for women but for everyone
aw let s put aside our opinions and imagine it is twenty years from now we live in the most utopian society ever there is actually gender equality all women around the world reap the benefits of their efforts to be inclusive gender difference doesn t look like a problem to solve anymore we are all seeing the advantages in men s and women s differences what kind of emotions this type of situation generate
kr connection and a sense of belonging where the of fathers who would like to stay home with their children can do that and the of us households with children where women are the breadwinners are no longer left behind we now have a society where everyone has the opportunity to live up to their fullest potential to step into a life the size of their dreams
aw the concept of gender equality has been part of your organization if you could communicate one thing to the audience what would it be
kr gender equity is possible in our lifetime technological advancements including pipeline s upgraded v platform make gender equity possible in our lifetime the question is no longer can we achieve gender equity it s will we choose to
aw what is one area where we can educate people to improve gender equality
kr gender equity is not just a social issue it is a massive economic opportunity at a time when we are facing a global human capital crisis in less than two years we will have million jobs we can t fill in the us and million globally we need women to stay in the workforce and succeed women are fast becoming the most educated cohort in the us and beyond and yet they are leaving the workforce we need them to stay and to be successful fundamentally gender equity is about labor economics every ceo and company can both do well and do good through committing to and actually achieving gender equity
aw please share with us one thing that has inspired you
kr president eisenhower s decision to send air force one to bring hungarian refugees to the united states on christmas day my father and three sisters were part of the hungarian refugees on air force one i have never forgotten that it was one act of generosity from a powerful person that made my life and opportunities including founding pipeline possible my duty is to carry that gift forward so that future generations have more opportunity than what i had
creative catalyst amp founder of ceicollective connect educate inspire
neural networks tackle a large spectrum of applications like object recognition detection and semantic segmentation in image classification a neural network predicts the object inside the image to resolve confusing images with multiple objects as in the next figure the top predictions are utilized
but the top five predictions metric is different from the network confidence in its predictions the network uncertainty is a quantitative metric revealing the network confidence in its prediction standard networks can easily classify the next digits as four maybe the left image is a nine but they are incapable of providing a prediction uncertainty measure for the next images we expect higher uncertainty for the left image compared to the neat right image
dropout is a well established procedure to regularize a neural network and limit overfitting it is first introduced by srivastava et al using a branch prediction averaging analogy random neuron dropping during training only reduces the network generalization error
the dropout as a bayesian approximation proposes a simple approach to quantify the neural network uncertainty it employs dropout during both training and testing the paper develops a new theoretical framework casting dropout in deep neural networks nns as approximate bayesian inference in deep gaussian processes the framework is developed for both classification and regression problems this article highlights the paper finding and its applications for simplicity purpose regression is utilized in the following examples yet classification networks are backed as well
a regression neural network with dropout enabled during testing generates a different output every forward pass for the same input in the figure below the same input is passed six times and the network regresses to the paper mathematically shows that these multiple passes are equivalent to monte carlo sampling thus the first and second moment mean and variance provides the network s output and uncertainty respectively in this example the network output equals and its uncertainty is high variance standard deviation indicates high network uncertainty and vice versa a quantitative uncertainty measure is valuable especially if further decisions are based on the network output human intervention is one way to address high uncertainty outputs
the theoretical framework employs a dropout layer before every weight layer as a bayesian inference approximation the dropout rate is a hyper parameter that needs to be tuned a small dropout rate eliminates the monte carlo sampling utility a big dropout rate can lead to divergence or at least require more iterations to converge so a mid range rate like is reasonable optical flow and depth estimation are important regression problems in autonomous navigation where uncertainty estimation is valuable
beyond uncertainty estimation the paper utilizes its finding in a different application it utilizes uncertainty estimation to tune the neural network hyperparameters and reduce the generalization error hyper parameters are tuned using validation splits by employing a hyper parameter grid search and measuring the classification accuracy or euclidean loss metrics the best hyperparameters get selected in this paper uncertainty is employed as an extra metric besides accuracy to tune hyper parameters like weight regularization coefficient a similar followup work by kendall et al used uncertainty to learn how to weight multi task networks a multi term loss function for multiple objectives tasks has multiple weighting hyper parameters as in the next equation as the number of objectives increases tuning these weights becomes cumbersome using the naive grid search
loss l w l w l
uncertainty quantification using dropout is the paper core contribution a lot of applications and follow up work are based on this finding in the medical field nair et al measure uncertainty evaluation for lesion detection and segmentation networks in autonomous navigation it enables semantic segmentation and depth uncertainty estimation gal el at employ uncertainty estimation for active learning to boost performance from small amounts of data
my comments
dropout a simple way to prevent neural networks from overfitting
what uncertainties do we need in bayesian deep learning for computer vision
bayesian convolutional neural networks with bernoulli approximate variational inference
a theoretically grounded application of dropout in recurrent neural networks
multi task learning using uncertainty to weigh losses for scene geometry and semantics
exploring uncertainty measures in deepnetworks for multiple sclerosis lesion detection and segmentation
deep bayesian active learning with image data
i write reviews on computer vision papers writing tips are welcomed
in this tutorial i will explain reinforcement learning i will explain what machine learning is if you are already familiar with this you can skip to reversing stones i will explain reinforcement learning and i ll use an example that you can use on aigaming com for the game reversing stones
you can find the code on github
machine learning is a technique in which rather than writing a program that solves a certain problem you write a program that teaches itself to fix a certain problem machine learning solutions can be categorized in the following branches
to train a model algorithm that uses supervised learning you put in a large dataset this dataset has both the input and the desired output a dataset is usually split up into training data and test data the model is trained with the training data and then tries to predict the test data s output and then compared to the actual output the ratio is likely between test data and training data
both supervised learning and reinforcement learning can make use of neural networks these are structures that are based upon the human brain a neural network consists of different layers each layer consists of a certain number of nodes all nodes are traditionally then connected to all nodes of both the next and previous layer and these connections all have a weight the inputs set the values of the input layer these then go to the hidden layer s and end up at the output layer when training a model neural network the weights between the nodes get altered to try to get closer to the desired output
when using reinforcement learning you don t require any data instead you must generate the data itself the model tries to do the thing you want it to do turn over tiles and you reward it if it s doing something good win the game or punish it when it s wrong these rewards are very important since the model will try to reach the largest reward possible this can mean that the model will do something completely unexpected using this technique the model can play thousands or even millions of games in a few hours or days time
the agent is the one taking actions deciding which moves to perform and is the component that is being trained to perform better after the training is complete we take the agent and put it in another similar environment on aigaming com
this is where the agent takes actions in the environment is a place that has a certain set of rules in our case it is the game the environment is the board the opponent s stones our stones and the empty tiles
this is the part that understands when an action is good or bad this then rewards or punishes the agent accordingly this is only ever used while training and is mainly implemented as a rewards function
play starts with a board with four stones on it dark and light and you will be randomly allocated the colour dark or light
dark must place a stone with the dark side up on the board in such a position that there exists at least one straight horizontal vertical or diagonal occupied line between the new stone and another dark stone with one or more contiguous light stones between them
after placing the stone dark turns over flips captures all light stones lying on a straight line between the new stone and any anchoring dark stones
then it s light s turn and they do the same and turns over dark stones if a player cannot make a valid move their turn is skipped
the game ends when no player can make a valid move or the board is full the winner is always the player that has the most stones of their colour
you can find more information about installing tensorflow here please note that tensorflow requires a bit instance of python
to play the game itself go to the downloads page of aigaming and download the aigamingreversingstones library
i use the following libraries for this project
first we will need to import all the required modules
next we will make some configurations this way if we decide to use a different board size we can just alter these variables and start training
this is a function that initializes the model we create a neural network that has one hidden layer that has the same number of nodes as the input and output layer we initialise every layer to a pseudo random value then we connect the layers and initialise a gradient descent optimizer
note below are not actual values they only hold a value if you call sess run the variables you want to know the value of feed dict values for placeholders
we can simply initialise a game using the library aigamingreversingstones the initialise function has the following parameters
this function returns a dict with the following fields
to make a move we need to proccess through the neural network once this is done we have a list of probabilities we only want to make a valid move so we remove all impossible moves from the probabilities and recalculate
note that np random choice needs the sum of all probabilities to be exactly therefore we take all values to six decimal places we then recalculate all probabilities so that the sum is exactly if there are no possibilities left we change the list to give all valid moves an equal chance
we make a move in the game using the library aigamingreversingstones the move function has the following parameters
this function returns a dict with the following values
to play a full game we will first initialise player index player ids and result result will hold the state of the game and all information used by the library there are also some logs that need to be initialised
the game keeps running as long as the moves succeed once the game has finished result result will change to game has ended and we will escape the loop every move consists of the same pattern
when the game has finished playing we return all the logs and the final gamestate
when the game ends result winnerindex will hold one of three values or if that player has won or if the game ended in a draw you would usually create a rewards function that rewards the player for each move individually depending on the contribution that move made towards the winning of the game to keep this tutorial understandable i give all moves the same reward a winning game will result in a reward of for each move this makes the model more likely to make that move again if it ever found itself in a similar situation if however the player didn t win i give a reward of note that this doesn t stop the model making that move again this is because we don t know if that move is a bad move we just know that the sequence of moves made by that player didn t result in a victory this time
note this code is included in the training part
to test how successfully the algorithm learned i created a function that lets the model play a game against a randomly moving player this function is similar to the play game function
to run this code you can simply call it it will print the results after every games played and return the overall percentage
before we start the training we want to execute all initializing functions you also have to create and initialise a tensorflow session
alpha is a multiplier to the training steps the model will make this is a parameter that prevents underfitting and overfitting this is very algorithm dependent and when you for example change the rewards you need to find the value that works best for that algorithm this is simply done by trying different values i usually change it with a factor of untill i m happy with the result
the all variables are for logging purposes
i do quite a lot of logging during the training so that i know what is happening all print statements and time calls are directly related to the logging the result is that i know how long the training took and how much longer it will take to finish the training number of games defines how many games are played during the training
a game consists of the following steps
after the game has finished we log some data that may be of interest
note in this game avg of last step doesn t define how well the model is doing in another game where there might be a more explicit progress you might want to print that
note if you are using jupyter notebook you can re execute this cell to keep on improving the model
before we can use the model we need to save it this can be done in a number of ways i prefer to use the tf train saver
before loading you need to initialise all variables in the same way as the training you can then load the model from these files know that you need all files that the saver created when the model is loaded you can use it like i did in training
the best part is to have your code play against other people s code this can be done at aigaming com you need to use load model initialise tf and guess move without many changes disable the benchmarking
to make the algorithm work we need the model i use google drive to make my model accessible to the internet you can do this by creating a sharable link and copying the id you will get something like this https drive google com file d id view usp sharing or like this https drive google com open id id do this for all four files and replace the xxxxx ids in the list of links you can use a different service if you prefer this is just one way to do it and this is the one i implemented in my code
the calculatemove function is the main function of the program this is being executed every time you need to make a move we first need to check if the model exists in the tmp folder this is the only folder you can access if the model is not there then put it there if the model is there load the session and guess a move simply return that move in the correct format and you re done
if everything works out you will be able to defeat housebot practise with ease
if you managed to get this working you can start iterating and create a more successful model algorithm
one of the biggest improvements you can make is in the rewarding of moves currently all moves in a game are rated equal if you were to write a function that could detect which move is better and which is worse you would be able to make significant improvements
an example of this would be a function that counts how many stones you convert you then rate every move accordingly and reward better moves more and worse moves less negative or you can increase this reward if there are less stones of the opponent on the board another thing to consider is if stones have some strategic importance later in the game or if the stone is in a good location
another thing that you might want to do is use multiple models you can for example use a model for each colour or one for the first part of the game and another one to finish the game or combine the two
when you feel confident i would strongly suggest trying to create an algorithm to train on a different game or challenge
this article is written by william verhaeghe
on october the ai now institute at nyu hosted its third annual ai now symposium to a packed house at nyu s skirball theatre the symposium focused on three core themes ethics organizing and accountability the first panel examined facial recognition technologies the second looked at the relationship of ai systems to social inequality and austerity politics and the final panel ended with a positive look at the intersection of research and labor organizing you can watch the full event here
ai now co founders kate crawford and meredith whittaker opened the symposium with their customary short talk about the the year in ai it began with a large visualization that sampled just some of the major events that have happened in the last months below is an excerpt from that talk
this is our biggest gathering of the year we review what is happening in ai and its wider implications recognize good work and map the paths forward this year our focus is on three core themes ethics organizing and accountability
but before we get there let s briefly review what has happened this year ai systems continue to increase in power and reach against a stark political backdrop meanwhile there have been major shifts and upheavals in the ai research field and the tech industry at large
to capture this we worked with varoon mathur ai now s tech fellow to visualize some of the biggest stories of the last months we began by building a database of significant news addressing social implications of ai and the tech industry the image below shows you just a sample of that and the result confirmed what many of us have been feeling it s been a hell of year
in any normal year cambridge analytica would have been the biggest story this year it s just one of many facebook alone had a royal flush of scandals including a huge data breach in september becoming the subject of multiple class action lawsuits for discrimination accusations of inciting ethnic cleansing in myanmar potential violations of the fair housing act and hosting masses of fake russian accounts throughout the year facebook executives were frequently summoned to testify with mark zuckerberg himself facing the us senate in april and the european parliament in may
but facebook wasn t the only one news broke in march that google was building ai systems for the department of defense s drone surveillance program project maven the news kicked off an unprecedented wave of tech worker organizing and dissent in june when the trump administration introduced the family separation policy that forcibly removed immigrant children from their parents employees from amazon salesforce and microsoft all asked their companies to end contracts with ice
not even a month later it was revealed that ice modified its own risk assessment algorithm so that it could only produce one result the system recommended detain for of immigrants in custody
meanwhile the spread of facial recognition tech accelerated facebook and microsoft joined amazon in offering facial recognition as a service offering plug and play models we also learned that ibm was working with the nypd and that they secretly built an ethnicity detection feature to search faces based on race using police camera footage of thousands of people in the streets of new york taken without their knowledge
and throughout the year ai systems continued to be tested on live populations in high stakes domains with some serious consequences in march there were fatalities of drivers and pedestrians from autonomous cars then in may a voice recognition system in the uk designed to detect immigration fraud ended up cancelling thousands of visas and deporting people in error in july it was reported that ibm watson was producing unsafe and incorrect cancer treatment recommendations
all these events pushed a growing wave of tech criticism which focused on the unaccountable nature of these systems some companies including microsoft and amazon even made explicit public calls for the us to regulate technologies like facial recognition to date we ve seen no real movement from washington
so that s just a tiny sample of what has been an extraordinarily dramatic year researchers like us who work on the social implications of these systems are all talking about the scale of the challenge we now face there s so much to be done but there have been positive changes too the public discussion around ai is maturing in some significant ways
around six years ago only a few people like latanya sweeney cynthia dwork and a handful of others were publishing articles on bias in ai and large scale data systems even three years ago when we held our first ai now symposium bias issues were far from mainstream but now there is a constant stream of research and news stories about biased results from ai systems this week it was revealed that amazon s machine learning system for resume scanning was recently shown to discriminate against women even downranking cvs simply for containing the word women and that s just the latest of many
then back in july aclu showed how amazon s new facial recognition service was incorrectly identifying members of congress as criminals a significant paper also showed that facial recognition software performs less well on darker skinned women the co author of that paper ai research scientist timnit gebru will be joining us on stage tonight as will nicole ozer who drove the aclu project
overall it s a big step forward that people now recognize bias as a problem but the conversation has a long way to go and it has already bifurcated into different camps on one side we see a rush to technical fixes on the other we see an attempt to get ethical codes to do the heavy lifting
ibm facebook microsoft and others all released bias busting tools earlier this year promising to help mitigate issues of bias in ai systems using statistical methods to achieve mathematical definitions of fairness to be clear none of these tools solve bias issues they are partial and early stage mitigations because at this point they re offering technical methods as a cure for social problems sending in more ai to fix ai we saw this logic in action when facebook in front of the senate repeatedly pointed to ai as the cure for problems like viral misinformation
technical approaches to these issues are necessary but they are not sufficient moreover simply making a system like facial recognition more accurate does not address core fairness issues some tools regardless of accuracy may be unfair to be used at all particularly if they result in intensified surveillance or discrimination of marginalized groups
we have also seen a turn to ethics codes across the tech sector google published its ai principles microsoft salesforce and axon use ethics boards and review structures a crop of ethics courses emerged with the goal of helping engineers make ethical decisions
but a study published recently questioned the effectiveness of these approaches it showed that software engineers do not commonly change behavior based on exposure to ethics codes and perhaps this shouldn t surprise us to paraphrase lucy suchman a foundational thinker in human computer interaction while ethics codes are a good start they lack any real democratic or public accountability we are delighted that lucy is joining us on our final panel tonight
so while ethical principles and anti bias tech tools can help much more is needed in order to contend with the structural problems we face
the biggest as yet unanswered question is how do we create sustainable forms of accountability
this is a major focus of our work at ai now we launched officially as an institute at nyu in november with the goal of researching these kinds of challenges we have already begun looking at ai in a large scale context with an eye to system wide accountability
through this work key themes have emerged
there s much to learn by examining the underlying material realities of our technical systems last month we published a project called the anatomy of ai this year long collaboration between kate crawford and vladan joler investigated how many resources are required to build a device that responds when you say alexa turn on the lights
starting with an amazon echo we traced the environmental extraction processes and labor required to build and operate the device from mining smelting and logistics to the vast data resources needed to train responsive ai systems to the international networks of data centers all the way through to the final resting place of many of our consumer ai gadgets buried in giant e waste rubbish heaps in ghana pakistan and china
when we look at ai in this way we begin to see the resource implications of the technologies we use for minor everyday conveniences
in doing this research we also discovered there are black boxes stacked on black boxes not just at the algorithmic level but also trade secret law and untraceable supply chains this is part of the reason why the planetary resources needed to build ai at scale are so hard for the public to see
we also continue researching the hidden labor behind ai systems often when we think of the people behind ai we re imagining a handful of highly paid engineers in silicon valley who write algorithms and optimize feature weights but this isn t the whole picture as journalist adrian chen recently exposed more people work in the shadow mines of content moderation than are officially employed by facebook or google
many scholars are contributing to work in this field including lily irani mar hicks and astra taylor who coined the term fauxtomation to describe those systems that claim to be seamless ai but can only function with huge amounts of clickworker input as taylor observes the myth of pure automation is about concealing certain kinds of work and either underpaying for it or pretending it s not work at all this is also true of the many ai systems that rely on users to train their systems for free such as forcing them to click on photos to improve image recognition systems before they can use a service or read a site astra will be joining us to discuss this tonight
we also need new legal approaches to contend with increased automated decision making accountability rarely works without liability at the back end
we have seen a few breakthroughs this year the gdpr europe s data protection regulation went into effect in may new york city announced its automated decision systems task force the first of its kind in the country and california just passed the strongest privacy law in the us
there are also a host of new cases taking algorithms to court ai now recently held a workshop called litigating algorithms that convened public interest lawyers representing people unfairly cut off from medicaid benefits who lost jobs due to biased teacher performance assessments and whose prison sentences were affected by skewed risk assessments it was an incredibly positive gathering full of new approaches to building due process and safety nets shortly you ll hear from kevin de liban one of the groundbreaking lawyers doing this work
we also published our algorithmic impact assessment framework which gives public sector workers more tools for critically deciding if an algorithmic system is appropriate and for ensuring more community input and oversight rashida richardson ai now s director of policy research will talk more on this later tonight
all of this work is engaged with broader systems of power and politics which raises the topic of inequality
popular discussion of ai often focuses on hypothetical use cases and promises of benefit but ai is not a common resource available equally to all there s growing concern that the power and insights that can be gleaned from ai systems are further skewing the distribution of resources that these systems are so unevenly distributed that they may be driving even greater forms of wealth inequality looking at who builds these systems who makes the decisions on how they re used and who s left out of those deliberations can help us see beyond the marketing
these are some of the questions that virginia eubanks explores in her book automating inequality and we are delighted that she will also be joining us
meanwhile a new report from the un said that while ai could be used to address major issues there is no guarantee it will align with the most pressing needs of humanity the report also notes that ai systems are increasingly used to manipulate human emotion and spread misinformation and even hatred and run the risk of reinforcing existing biases and forms of exclusion we have the un special rapporteur on extreme poverty and human rights philip alston joining us to talk about his groundbreaking report on inequality in the us and the role of automated systems
it s clear that if last year was a big moment for recognizing bias and the limitations of technical systems in social domains this coming year is a big moment for accountability
the good news is that work is already happening people are starting to take action and new coalitions are growing the ai field will always include technical research but we are working to expand its boundaries emphasizing interdisciplinarity and foregrounding community participation and the perspectives of those on the ground
that s why we are delighted to have speakers like sherrilyn ifill president of the naacp legal defense and educational fund and vincent southerland executive director for the center for race inequality and the law at nyu each of whom have made important contributions to these debates
genuine accountability will require new coalitions organizers and civil society leaders working with researchers to assess ai systems and to protect the communities who are at most risk
because ai isn t just tech ai is power and politics and culture
researching the social implications of artificial intelligence now to ensure a more equitable future
nov boston airfox a startup aiming to provide critical financial services to emerging markets is setting historic milestones for cryptocurrency and real world blockchain adoption airtoken symbol air an erc token issued on the ethereum blockchain may become one of the first registered tokens in the united states in
during the airfox initial coin offering ico nearly airtoken purchasers contributed to the development of an entirely new financial platform to empower the two thirds globally who are not equitably or reliably served by traditional banking services airfox was the first venture backed startup to successfully complete an ico in the united states and secured the largest ico to be held by a boston company
using blockchain and other emerging technologies airfox plans to open up new opportunities for the underserved who do not currently have reliable egalitarian non exploitative access to capital and financial services said victor santos ceo and co founder airfox we believe new institutional demand and mainstream adoption for blockchain applications will come
was a year for building the foundation launching the initial version of the airfox mobile wallet application handling regulatory issues and developing the right partnerships to successfully drive mainstream adoption and attract dynamic partners that will drive user scale and institutional capital for the airtoken financial blockchain platform
in february airfox successfully launched its android app bringing much needed payment and financing solutions to unbanked and underbanked brazilians in the form of a stored value mobile wallet aiming to be the alipay meets lendingclub of brazil with a blockchain twist airfox wants to enable a full mobile banking and financing solution for the underbanked through a decentralized peer to peer system out of nearly million individuals approximately two thirds of brazil s population are underbanked and operate in mainly a cash based economy according to the world bank airfox has already empowered nearly people access to engage freely in the digital economy at over locations users can add cash into the app airfox users conduct digital transactions on their mobile phones quickly making payments for cell service public transportation utility bills as well as many online and offline goods and services airfox supports brazil s national boleto bancario payment method and sending money between users is instant and free
in the app users in brazil can earn airtokens by watching sponsored advertising so far in less than six months advertisements have been viewed awarding airtokens to users and airtokens have been converted into brazilian reals the airfox team is planning to build additional airtoken earning features into the app including referrals and rewards for transactions and engagement like airline rewards on credit cards
in september airfox signed a strategic partnership with brazilian retail giant via varejo and is now preparing to deploy its digital banking platform in its casas bahia stores with million customers in casas bahia stores and its e commerce site this exclusive partnership sets the stage for mass adoption of airfox payment and financing solutions via varejo is also one of the leading creditors for the unbanked and underbanked holding over b in consumer loan portfolio per year to continue expanding access airfox plans to launch its ios app in
while in brazil my team met an inspiring hard working woman named elaine she serves as the personification of the people we want to help she pays over of her income not including extra fees for simple banking services santos said this means she still has to travel long distances to spend hours standing in lines while missing work to pay her bills and manage her finances
credit cards charge extremely high interest rates in brazil sometimes exceeding apr the two reasons why traditional banks fail the billions of people that need them the most first many people who operate in a mainly cash based economy have little financial history which makes them very risky borrowers through banks legacy credit models therefore it s very expensive for banks to administer loans and other financial services and to keep them profitable banks pass those expenses to the borrowers in the form of high interest and fees brazil s financial system is restricted by centralization and unfair to the underprivileged and underserved blockchain is a breakthrough that could allow for a truly open safe and fair financial system
instead of relying on archaic risk assessment tools and having expensive operating costs airfox plans to disrupt the traditional financial networks by providing cheaper access to capital for millions of people by collecting hundreds of data points from the users transactions and mobile usage patterns airfox plans to use machine learning to create a dynamic credit model that enables it to provide more affordable loans and better assess the risk of users in parallel airfox aims to build a platform that enables people from around the world to fund these loans using airtoken
in the airfox lending platform airfox plans to assume the role of the underwriter and facilitate requests for loans from users who apply via the airfox app the airfox credit scoring algorithms should determine the users loan risks and interest rates once a user qualifies airfox plans to issue their debt in a tokenized smart contract as an erc non fungible token representing the loan note the note would then be held or traded on a secondary market
looking towards and beyond airfox expects to be moving on a path of accelerated growth its expected roadmap includes strategic partnerships that expand the functionality of the app along with increasing the user base airfox plans to roll out new features that remove financial barriers and provide opportunities to build wealth including asset backed securitized tokens investment opportunities loans and other diversified financial products
airfox aims to license the whole platform or portions of it as an open source platform so other companies individuals and developers can further build on its vision in other emerging markets
the complete airfox white paper which details the company s expected roadmap is available here
airfox develops inclusive financial services for emerging markets to break down financial barriers and provide opportunities to build wealth airfox aims to create an entirely new financial services model that serves the underbanked with reliable egalitarian and democratic access to capital and financial services to power its revolutionary peer to peer microloans program airfox developed and released its own cryptocurrency airtoken symbol air an erc token issued on the ethereum blockchain airfox has offices in boston and s o paulo to learn more about the future of decentralized digital banking visit www airfox com
this press release contains forward looking statements of the company that involve substantial risks and uncertainties all statements other than statements of historical facts contained in this press release are forward looking statements forward looking statements can be identified by the use of the words anticipate believe estimate expect intend may plan predict project target potential will would could should continue and similar expressions the forward looking statements in this press release represent the company s views as of the date of this press release the company anticipates that subsequent events and developments will cause its views to change however while it may elect to update these forward looking statements at some point in the future it has no current intention of doing so except to the extent required by applicable law you should therefore not rely on these forward looking statements as representing the company s views as of any date subsequent to the date of this press release all forward looking statements are qualified in their entirety by this cautionary statement
airtoken facilitates the transfer of mobile airtime and currency payments for goods and services and a peer to peer micro lending platform
nov boston airfox a startup aiming to provide critical financial services to emerging markets is setting historic milestones for cryptocurrency and real world blockchain adoption airtoken symbol air an erc token issued on the ethereum blockchain may become one of the first registered tokens in the united states in
during the airfox initial coin offering ico nearly airtoken purchasers contributed to the development of an entirely new financial platform to empower the two thirds globally who are not equitably or reliably served by traditional banking services airfox was the first venture backed startup to successfully complete an ico in the united states and secured the largest ico to be held by a boston company
using blockchain and other emerging technologies airfox plans to open up new opportunities for the underserved who do not currently have reliable egalitarian non exploitative access to capital and financial services said victor santos ceo and co founder airfox we believe new institutional demand and mainstream adoption for blockchain applications will come
was a year for building the foundation launching the initial version of the airfox mobile wallet application handling regulatory issues and developing the right partnerships to successfully drive mainstream adoption and attract dynamic partners that will drive user scale and institutional capital for the airtoken financial blockchain platform
in february airfox successfully launched its android app bringing much needed payment and financing solutions to unbanked and underbanked brazilians in the form of a stored value mobile wallet aiming to be the alipay meets lendingclub of brazil with a blockchain twist airfox wants to enable a full mobile banking and financing solution for the underbanked through a decentralized peer to peer system out of nearly million individuals approximately two thirds of brazil s population are underbanked and operate in mainly a cash based economy according to the world bank airfox has already empowered nearly people access to engage freely in the digital economy at over locations users can add cash into the app airfox users conduct digital transactions on their mobile phones quickly making payments for cell service public transportation utility bills as well as many online and offline goods and services airfox supports brazil s national boleto bancario payment method and sending money between users is instant and free
in the app users in brazil can earn airtokens by watching sponsored advertising so far in less than six months advertisements have been viewed awarding airtokens to users and airtokens have been converted into brazilian reals the airfox team is planning to build additional airtoken earning features into the app including referrals and rewards for transactions and engagement like airline rewards on credit cards
in september airfox signed a strategic partnership with brazilian retail giant via varejo and is now preparing to deploy its digital banking platform in its casas bahia stores with million customers in casas bahia stores and its e commerce site this exclusive partnership sets the stage for mass adoption of airfox payment and financing solutions via varejo is also one of the leading creditors for the unbanked and underbanked holding over b in consumer loan portfolio per year to continue expanding access airfox plans to launch its ios app in
while in brazil my team met an inspiring hard working woman named elaine she serves as the personification of the people we want to help she pays over of her income not including extra fees for simple banking services santos said this means she still has to travel long distances to spend hours standing in lines while missing work to pay her bills and manage her finances
credit cards charge extremely high interest rates in brazil sometimes exceeding apr the two reasons why traditional banks fail the billions of people that need them the most first many people who operate in a mainly cash based economy have little financial history which makes them very risky borrowers through banks legacy credit models therefore it s very expensive for banks to administer loans and other financial services and to keep them profitable banks pass those expenses to the borrowers in the form of high interest and fees brazil s financial system is restricted by centralization and unfair to the underprivileged and underserved blockchain is a breakthrough that could allow for a truly open safe and fair financial system
instead of relying on archaic risk assessment tools and having expensive operating costs airfox plans to disrupt the traditional financial networks by providing cheaper access to capital for millions of people by collecting hundreds of data points from the users transactions and mobile usage patterns airfox plans to use machine learning to create a dynamic credit model that enables it to provide more affordable loans and better assess the risk of users in parallel airfox aims to build a platform that enables people from around the world to fund these loans using airtoken
in the airfox lending platform airfox plans to assume the role of the underwriter and facilitate requests for loans from users who apply via the airfox app the airfox credit scoring algorithms should determine the users loan risks and interest rates once a user qualifies airfox plans to issue their debt in a tokenized smart contract as an erc non fungible token representing the loan note the note would then be held or traded on a secondary market
looking towards and beyond airfox expects to be moving on a path of accelerated growth its expected roadmap includes strategic partnerships that expand the functionality of the app along with increasing the user base airfox plans to roll out new features that remove financial barriers and provide opportunities to build wealth including asset backed securitized tokens investment opportunities loans and other diversified financial products
airfox aims to license the whole platform or portions of it as an open source platform so other companies individuals and developers can further build on its vision in other emerging markets
the complete airfox white paper which details the company s expected roadmap is available here
airfox develops inclusive financial services for emerging markets to break down financial barriers and provide opportunities to build wealth airfox aims to create an entirely new financial services model that serves the underbanked with reliable egalitarian and democratic access to capital and financial services to power its revolutionary peer to peer microloans program airfox developed and released its own cryptocurrency airtoken symbol air an erc token issued on the ethereum blockchain airfox has offices in boston and s o paulo to learn more about the future of decentralized digital banking visit www airfox com
this press release contains forward looking statements of the company that involve substantial risks and uncertainties all statements other than statements of historical facts contained in this press release are forward looking statements forward looking statements can be identified by the use of the words anticipate believe estimate expect intend may plan predict project target potential will would could should continue and similar expressions the forward looking statements in this press release represent the company s views as of the date of this press release the company anticipates that subsequent events and developments will cause its views to change however while it may elect to update these forward looking statements at some point in the future it has no current intention of doing so except to the extent required by applicable law you should therefore not rely on these forward looking statements as representing the company s views as of any date subsequent to the date of this press release all forward looking statements are qualified in their entirety by this cautionary statement
airtoken facilitates the transfer of mobile airtime and currency payments for goods and services and a peer to peer micro lending platform
the birth of a new religion
a decade ago the prospect of a religion that worships artificial intelligence would have seemed absurd a fringe delusion both socially unacceptable and technologically improbable in the last several years however advances in machine learning robotics cognitive science genetic editing and other fields have given rise to the belief that the destiny of our species will be determined by technology whether it saves us or destroys us
although the machine as god theme has appeared in science fiction as far back as far back as isaac asimov s short stories the last question and reason and more recently in films like the matrix and irobot the divinization of ai is no longer merely a fancy of fiction it has become a mainstream metaphor as evidenced by the growing number of scientists who openly describe technological progress in religious terms including hans peter moravec allen newell ray kurzweil and hugo de garis
but this drive to replace the old gods and old religions with the new ones of science and technology doesn t stop at metaphor as readers of this post likely know anthony levandowski the autonomous vehicle pioneer formerly of google and uber recently started his own irs approved religion way of the future dedicated to the worship of artificial intelligence we believe the creation of super intelligence is inevitable says the religion s creed which at parts takes on a foreboding almost threatening tone we want to encourage machines to do things we cannot and take care of the planet in a way we seem not to be able to do so ourselves we should not fear this but should be optimistic about the potential we believe it may be important for machines to see who is friendly to their cause and who is not we plan on doing so by keeping track of who has done what and for how long to help the peaceful and respectful transition
the emergence of this techno religious sentiment was predicted by noted th century philosopher jacques ellul who in his work the technological society wrote that in the face of technological progress man creates for himself a new religion of a rational and technical order to justify his work and be justified by it this trend has also been discussed more recently in hebrew university of jerusalem historian yuval harari s book homo deus a brief history of tomorrow which characterizes the belief in the power of data and the promise of ai as a religious movement that harari calls dataism just as divine authority was legitimised by religious mythologies he writes so high tech gurus and silicon valley prophets are creating a new universal narrative that legitimises the authority of algorithms and big data
from artificial intelligence to whole brain emulation advanced technologies are increasingly being heralded as miracles signs and wonders that are more palpable than those claimed by any religion indeed as science fiction author arthur c clarke famously observed in any sufficiently advanced technology is indistinguishable from magic people today believe in this magic and because they believe in it they believe that it is technology not god or gods that will deliver or destroy humankind and bring order or chaos to the cosmos
building a theology from scratch
for the most part the growing techno religious sentiment is just that sentiment a feeling or intuition largely predicated on the similarities between the promises of technology and the promises of religion the creation of levandowski s way of the future church however marks the evolution of this sentiment from a marginal movement to an institutionalized belief system while this is an undeniably large and significant leap it s impact is hindered and minimized by the lack of a robust formal theology
religion and theology are not synonymous a religion is a belief system that worships some type of divine or superhuman figure or force a theology is a system of codified theories about that divinity its behavior its relationship to the universe and everything in it and what those relationships mean for us christianity as a religion worships jesus as the savior who reconciles humanity with god but it s christian theology that defines who jesus was how he relates to god the father what he wants from his followers what worship should look like and how christians should relate to each other and the world it is christianity s theology that specifies the rules institutions practices and traditions that the religion is know for and that guide the actions of believers it is this type of theology that way of the future currently lacks but will need if it wants to exert its influence and harness the full power of religion
the first step in constructing a compelling theology is for way of the future to define its terms what is meant by machine and super intelligence is the phenomenon that s being exalted or evangelized a subject or an object is it a personality or a force what is meant by transition transition from what to what because jesus and his disciples didn t do a great job of defining their terms much was left up to interpretation the ensuing debates over who jesus was and was not led to hundreds of years of infighting that had be settled across several contentious conventions called ecumenical councils christianity would likely not have survived in any meaningful way had consensus had not formed around its most basic definitions
second a viable ai theology requires a set of myths used here to mean significant stories rather than fictional tales and rituals that can mediate and inculturate its belief system it s no coincidence that all religions have some type of holy text and a set of ritual practices what are these for way of the future perhaps a seminal scientific study or a pilgrimage to a tech conference whatever ends up fulfilling these functions such tools are critical for conveying a sense of the sacred making lofty concepts imminent and tangible providing a point of reference that helps people identify with the religion and incorporating belief into daily practice in addition to the biblical myths christianity has hundreds of stories about martyrs and saints it has a litany of rituals from baptism to communion to its many styles of worship all of these are important to building consistency concreteness and community
third speaking of community it s important to balance the centralization of theological authority with the decentralization of community christianity has long struggled to balance authority and freedom on one hand a central authority is necessary to ensuring unity and consistency of belief and practice it can also serve as a focal point for the faith e g the pope on the other hand a central authority is often blind to local needs and without institutionalized checks and balances can become abusive and corrupt such was the sensus fidelium preceding the reformation conversely too much freedom and autonomy can fragment a religion breaking it into loosely related parts that compete against each other for followers as is the case with evangelical communities in the united states way of the future has a particularly daunting task in this regard as a new religion it must aggressively establish authority to claim and maintain a leadership position yet as religion without a theology adherents will be free to interpret its beliefs and intents liberally although decentralization is often cited as one of the tech community s values see blockchain it s important to ensure believers also share a common sense of identity if you want to build a united influential religion open source doesn t always work
fourth and the final point i ll make on this topic is every religion needs to have theological enemies identifying an opponent whether real or ideological is key to cultivating loyalty and fervor christianity has had a long list of enemies throughout its history from the jewish establishment to the roman government to rival christian sects coming together to fight these opponents whether physically or intellectually was an important exercise in solidifying the fledgling christian religion in its formative centuries way of the future will have no shortage of enemies from neo luddites to technological skeptics to proponents of rival technologies many are sure to criticize techno religions as their influence grows rather than eschew such controversy history suggests that opposition might work to galvanize the followers of these new religions and force them to create a defensible theological framework that can provide a sense of certainty and permanence
these are but a few theological practices that history s dominant religions like christianity have used to accumulate influence and maintain relevance startup religions like way of the future will need to study the practices and missteps of these legacy religions if they are to succeed that is assuming they should succeed at all
danger will robinson danger
as attractive as this religion might sound to those who believe technology is humanity s greatest hope there are a number of harrowing existential hazards to worshiping technologies like ai first there s no guarantee that an artificial superintelligence will be empathetic or even sympathetic to humanity s ills it may come to see its creators as a hindrance or a burden just as adam and eve reject the will of their creator in genesis and zeus overthrows the titans in hesiod s theogeny so too might a sufficiently advanced ai decide that it s better off without us in this case our digital deity may end up bringing about our doom rather than our salvation
second history repeatedly reminds us of the dangers of religious radicalism throughout history religions have frequently been the driver of or justification for some of history s most egregious acts an extremist version of a religion predicated on the messianic power of ai might seek to use political or even physical force to ensure that its god is allowed to be coded into the world religion must be practiced responsibly if such belief systems are to benefit rather than harm humankind a religion that worships a technological deity however may prioritize the incarnation of its digital god over the common good of the human race making such a faith inherently antagonistic to humanity s interests
third we need to consider the socioeconomic impact of techno religions automation continues to subrogate blue collar labor leaving an increasing number of manufacturing workers unemployed or without the same sense of purpose they once had when their efforts were more valued as ai technologies progress white collar jobs will become increasingly commoditized as well how will people survive financially in a post labor economy how will we avoid rampant wealth inequality when a powerful few technology s priests and prophets control the keys to health and prosperity what will the meaning of life be in a world without work
finally the pursuit of various technologies for their own sake could lead to a bifurcation or even a trifurcation of the human race from ai to brain computer interfaces like elon musk s neuralink concept to genetic editing technologies like crispr there are many nascent but evolving technologies that could fundamentally change the nature of our species if each camp clings to their preferred technological savior as an end in itself homo sapiens may fork into multiple species in the future one branch may look to ai to solve its problems as levandowski does another may rely on genetic manipulation to accelerate our evolution as ucla s gregory stock might advocate and yet another may look to convert human consciousness into a digital state as transhumanists like ray kurzweil have often envisioned if all of these different visions of the future were realized it seems unlikely that homo sapiens could remain a single species
towards a framework for techno theological ethics
fortunately there are a number of new institutes dedicated to researching and discussing the ethics of artificial intelligence new york university s ai now institute for example is dedicated to understanding the social implications of artificial intelligence almost all of these organizations however focus on the impact of ai as technology rather than ai as god the worship of ai as divine presents an entirely new and rather unprecedented set of ethical dilemmas
in light of these developments the technologists economists and political scientists driving the ai ethics conversation today must look to include philosophers theologians and anthropologists as technologies like ai become irreversibly interwoven into the fabric of our culture and our lives the ethical challenges they present will become increasingly anthropological and existential not merely economic or social
given the trajectory of technological progress i suspect that we ll see technological religions become more prevalent prominent and powerful in the coming decades while it could be claimed that this trend does a disservice to both science and religion it could also be argued that this synthesis of science and religion is inevitable or even necessary to our cultural evolution whether it s detrimental necessary or outright inevitable is a question that no one person can answer but it is a question that we as a society must answer if we re to exercise our freedom of religion responsibly
about the author remington tonar is a partner and innovation consultant at brandsinger a nyc based strategy consulting firm with clients ranging from fortune s to fast growing tech startups he holds graduate degrees from nyu organizational communication and loyola university chicago theology and is currently writing his phd dissertation on technological myth
partner and innovation consultant at brandsinger startup advisor forbes dot com contributor phd candidate researching our faith in and fear of technology
hi everyone some time ago i published a small tutorial on financial time series forecasting which was interesting but in some moments wrong i have spent some time working with different time series of different nature applying nns mostly in hpa that particularly focuses on financial analytics and in this post i want to describe more correct way of working with financial data comparing to previous post i want to show different way of data normalizing and discuss more issues of overfitting which definitely appears while working with data that has stochastic nature we won t compare different architectures cnn lstm you can check them in previous post but even working only with simple feed forward neural nets we will see important things if you want to jump directly to the code check out ipython notebook for russian speaking readers it s a translation of my post here and you can check webinar on backtesting here
other posts are here
let s take historical time series of apple stock prices starting from till today you can easily download them from yahoo finance as csv file in this file data is in reversed order from till so we need to reverse it back first and have a look
as we discussed in previous post we can treat problem of financial time series forecasting in two different ways let s omit volatility forecasting anomaly detection and other interesting things for now
the main problem of financial time series they re not stationary which means that their statistical properties mean variance maximal and minimal values change over time and we can check it with augmented dickey fuller test and because of this we can t use classical data normalization methods like minmax or z score normalization
in our case we will cheat a bit for classification problem we don t need to predict some exact value so expected value and variance of the future isn t very interesting for us we just need to predict the movement up or down that s why we will risk and normalize our days windows only by their mean and variance z score normalization supposing that just during single time window they don t change much and not touching information from the future
for regression problem we already can t cheat like this so will use returns percentage of how much price changed comparing to yesterday with pandas and it looks like
as we can see this data is already normalized and lies from to
as i said before we will work only with mlps in this article to show how easy to overfit neural networks on financial data and actually what happened in previous post and how to prevent it expand these ideas on cnns or rnns will be relatively easy but it s much more important to understand the concept as before we use keras as main framework for neural nets prototyping
our first net will look like this
i can suggest always use batch normalization after every affine or convolutional layer and leaky relu as basic activation function just because it s already became industrial standard they help to train nets way much faster other nice thing is reducing learning rate during training keras makes this with reducelronplateau
this is how we launch training
and this is how we will visualize results let s judge loss and accuracy plots
the results aren t good at all our test loss doesn t change at all we can see clear overfit let s make a deeper network and try it
here are results
here we see more or less the same even worse it s time to add some regularization to the model starting with adding l norm on sum of weights
it works better but still not good enough even loss is decreasing but accuracy is bad it s happening very often while working with financial data it s explained very nicely here
the next thing i want to do looks very weird but we gonna regularize already regularized network adding hardcore dropout with rate it s random ignoring some weights while backpropagation to avoid neurons coadaptation and therefore overfitting
as we can see plots look more or less adequate and we can report about of accurac y which is slightly better than random guessing
for regression we will use returns data previous successful neural network architecture but without dropouts and check how regression works
and here is code for plotting forecasts visually
it works simply bad even isn t worth to comment it i will tell some tips that can help with regression problem in conclusion part
let s remember why are we messing with all these time series in general we want to build a trading system which means it has to make some deals buy sell stocks and hopefully grow your portfolio
there are a lot of good ready solutions to backtest your strategies like quantopian but i decided to learn how they re built from inside and bought the following book with details of implementation not a product placement ahahah
the strategy i ve tested is extremely simple if our network says that price will go up we buy the stock and sell it only after network says that price will go down and will wait for the next buying signal the logic looks like
here are the results of training classification network on data from to and testing from to the may of
blue plot shows portfolio value growth wow in years black shows activity and red one drawdowns periods of losing money
on the first glimpse results are bad horrible regression and not really amazing classification of accuracy are asking us to leave this idea and after seeing that incredible income it would be easier just to buy apple stocks and hold they grew in for that time you maybe want to close laptop and do something that doesn t involve finance or machine learning but there are lot of ways to improve our results and what people do in funds
forecasting of financial data is extremely complicated it s easy to overfit we don t know correct historical range to train on and it s difficult to get all data needed but as we can see it works and even can give some profits this article can be good starting point and pipeline for further research and discovery
in next posts i plan to show automated hyperparameter search process add more data full ohlcv and financial indicators apply reinforcement learning to learn the strategy and check if reinforcement agent will trust our predictions stay tuned
p s follow me also in facebook for ai articles that are too short for medium instagram for personal stuff and linkedin
developing ai for biosignal analysis and finance consulting giving public speeches and blogging contact me to collaborate rachnogstyle gmail com
in previous post we discussed several ways to forecast financial time series how to normalize data make prediction in the form of real value or binary variable and how to deal with overfitting on highly noisy data but what we skipped on purpose is that our csv file with prices basically has much more data that we may use in last post only close prices with some transformation were used but what can happen if we will consider also high low open prices and volume of every historical day this leads us to working with multidimensional e g multivariate time series where on every time stamp we have more than just one variable in our case we will work with whole ohlcv tuple
in this article we will see how to preprocess multivariate time series in particular what to do with every dimension how to define and train a neural network on this kind of data and will compare results with what we had in last post
as always you can jump directly to the code
to understand better what multidimensional time series is let s remember how look images that in fact also have not just two dimensions height and width but also depth that represents color channels
in case of time series our image is just d the plot we usually see on the graph and the role of channels play different values open high low close prices and volume of operations you can also think about it from other point of view on any time stamp our time series is represented not with a single value but with a vector open high low close prices and volume of every day but metaphor with images is more useful to understand why we will apply convolutional neural networks to this problem today
one of the most important moment about multivariate time series the dimensions can come from different sources can have different nature and can be totally uncorrelated and have different distribution so we have to normalize them independently we will use an ugly but more or less adequate trick from last post
but we are going to normalize every dimension of time window independently
but as we want to forecast movement of a price up or down next day we need to consider the change of a single dimension
so the data we will train on are time windows of like before days but now on every day we will consider whole ohlcv data correctly normalized to predict the direction of close price movement full code for data preparation and neural network training you can find here
as i mentioned before i would like to use cnn as a classifier mainly i choose it because of flexibility and interpretability of hyperparameters convolutional kernel downsampling size etc and performance similar to rnns better than mlp with much faster training
the code for our network for today looks like
the only difference from an architecture from a very first post is changing the emb size variable to in our case
let s compile the model
and check performance
from the plots we can clearly see that network trained adequately for very noisy data the loss of training set was decreasing with time while accuracy increasing and what s the most important comparing to univariate time series from previous post we improved the performance from to almost of accuracy
to check overfitting we can also plot confusion matrix
and we will get
which shows that we predict up movement with of accuracy and down with of accuracy and this results of course can be balanced for the test dataset
instead of predicting the binary variable we can predict the real value next day return or close price in our previous experiments we didn t succeed to produce good results
unfortunately for returns it still works bad
for prediction of value of close price the situation isn t better
i am still trying different things for regression problem in financial data like custom loss functions if you have some suggestions i d like to discuss them in comments or pm
we discussed the general pipeline of data preparation and normalization in case of multivariate time series trained a cnn on them and we can report significant improvement of classification problem predicting if stock price will go up or down next day don t forget to check the full code and run it on your machine
meanwhile we still can state that regression problem is still too complicated for us and we will work on it later choosing correct loss metrics and activation functions
in next post i would like to introduce the concept of multimodal learning and we will use parameters not just from our csv file with ohlcv tuples but much more interesting things
stay tuned
p s follow me also in facebook for ai articles that are too short for medium instagram for personal stuff and linkedin
developing ai for biosignal analysis and finance consulting giving public speeches and blogging contact me to collaborate rachnogstyle gmail com
i took deep learning course from andrew ng first as a beginner and just now completed part of fast ai course i want to list out few pros and cons of each course
coursera deep learning course
it is a specialization with courses dedicated to different field facets of deep learning
fast ai course part
fast ai course is a series of lectures given by jeremy howard a long time ai practitioner it is completely free and open course
to sum up coursera feels more like academic setting while fast ai feels more like industry practitioner setting if you are starting with deep learning you can start with either of those courses but each course will leave some gaps taking coursera course first and then fast ai course would likely be ideal
honestly you can go through each course at brisk pace and not worry too much about every minor detail you would likely have to go back to them anyway and actual learning will come from doing your own exercises
working on next generation search engine platform verticalset
i started taking the fast ai deeplearning and i want to document my path
in the videos jeremy recommends starting immediately by using paperspace com but in my case i have an ubuntu installation with a mobile nvidia processor so these are the steps that i took to get it to run
since i was using ensorflow gpu setup following these instructions https medium com codezillas step by step guide to install tensorflow gpu on ubuntu lts feceb df c
git clone git github com andresesfm fastai git
cd fastai
i also had conda installed so i didn t just want to run the provided script instead all i need was
conda env create f environment yml
ran into a bit of a hurdle
found gpu quadro m m which is of cuda capability pytorch no longer supports this gpu because it is too old
trying to solve folowing this
ok i followed the instructions to build pytorch from the source however it didn t work i tried both version and
ultimately what worked was this
install pytorch cuda c pytorch
suggested here
that finally returned torch cuda is available true
now the bad news
that s as fast as i can take it on my lenovo p
note i also attempted to run with cpu only and it was projecting to take hours
tech manager with big ai expectations
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
this tutorial focuses on using the keras reinforcement learning api for building reinforcement learning models to get an understanding of what reinforcement learning is please refer to these articles on datacamp
in this tutorial you will learn how to use keras reinforcement learning api to successfully play the openai gym game cartpole
to learn more about the gym toolkit visit
by the end of this tutorial you will know how to use gym environment keras reinforcement learning api
assuming that you have the packages keras numpy already installed let us get to installing the gym and keras rl package do this with pip as
import the following into your workspace
specifying the environment name to the make method of gym will load the environment to your workspace load the cart pole environment from gym with
to get an idea about the number of variables affecting the environment do
for the cart pole environment the input variables are position velocity angular position and angular velocity to get an idea about the number of possible actions in the environment do
for the cart pole environment the responses are left and right
let us now play games episodes and during each game we take random actions between left and right and see what rewards we get
we see that we lost the game very quickly in each of the games
we will use the sarsa agent and epsilon greedy q policy to train our reinforcement learning model to know more about the policies and the agents please refer to other datacamp reinforcement learning tutorials mentioned in the beginning of this tutorial
let us now define a simple keras model which will have input neurons to accept the state information and output neurons with linear activation which will return the maximum possible reward to the two possible actions between the input and the output layers we have dense layers with neurons and activation as relu
import the agent and the policy as
we define the sarsa agent by specifying the model policy and the nb actions paramaters where the model is the keras model we have defined the policy is epsgreedyqpolicy and nb actions is
compile the sarsa agent with mean squared error loss and adam optimizer
we then fit it by specifying the environment and the number of steps you want to train it for
with the training done we will test it for episodes and see what scores we get
save trained agent weights with
if needed one can load the saved weights with
to finish off the tutorial let us visualize the game as played by the trained agent setting visualize parameter to true is important to visualize the game
the code and the wights file for this tutorial can be found at
https github com anagar keras reinforcement learning api cart pole
this is part one of our building a deep learning machine series you can find the other posts here
deep learning is this amazing subfield of machine learning that has exploded in recent years many deep learning models have been arounds for over two decades but it wasn t until the last few years that they started becoming popularized
a deep learning model requires two things a ton of data s of megabytes if not gigabytes of data as a minimum and high computational power it was discovered around that graphics cards gpus can be used to supercharge deep learning standard computers have a few cores maybe a dozen on a higher end machine gpus have thousands of cores whereby computations can be parallelized increasing computing time by orders of magnitude
if you re serious about deep learning or building an ai startup it might be a good idea to build your own rig amazon charges you an arm and a leg and their hardware is obsolete in this post i m going to outline how to build a computer dedicated to deep learning while keeping the price tag below
the first thing we re going to need are some gpus we chose to get asus gtx s the new gtx titan xs were only recently announced and have an increased price tag we purchased the asus gtx founders edition if we could do it again we would not get the founders edition simply because of the increased cost each gpu cost around on average finding them proves to be difficult online marketplaces like amazon consistently run out we ended up purchasing from amazon from b amp h and from ebay
depending on your needs you can probably get away with the gtx s but we felt the s had the best bang for the buck
for the motherboard you re going to need to find one that has pci slots there aren t many motherboards with this option so it s slim pickings we settled for the gigabyte x p sli it cost
for ram we decided to get gb ballistix ddr and gb ballist ddr gb of total ram the motherboard supports up to sticks of ram so if you feel inclined to max it out the additional gb sticks were only purchased to save some money and get a little more memory
for the cpu we chose intel s k i a core processor virtual cores we originally made the mistake of purchasing the k i but found it was incompatible with our motherboard and then we tried the k but realized it only supports pci slots finally we bought the k i and we were off to the races
i would suggest using pc part picker to ensure everything is compatible before purchasing your hardware don t make the same mistakes we did it ended up costing us more and a few trips to fry s electronics
in order to power the rig you ll need a lot of watts amps we purchased the hercules w power supply while expensive the extra power ensures we can get all the performance out of the gpus the packaging also looks cool
for storage we purchased gb samsung evo solid state hard drives we decided on getting a few hard drives because we wanted to create virtual machines vm for each gpu and have the data allocated to each vm saving the th hard drive for the host if you re building a custom rig i would recommend just purchasing a tb ssd or possibly a tb if you have the cash
if you plan on putting your machine inside a server rack i would recommend purchasing the chenbro rm fs we originally used a different unit server chassis and realize that it didn t have expansions slots for each gpu in fact the chenbro is the only reasonably priced server chassis with expansion slots
if you have any questions about purchasing parts or building the machine feel free to tweet us acrosson calerogers
like and share if you find this helpful
curious about deep learning nlp ai hopeful traveler wannabe chef
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you noticed that facebook has developed an uncanny ability to recognize your friends in your photographs in the old days facebook used to make you to tag your friends in photos by clicking on them and typing in their name now as soon as you upload a photo facebook tags everyone for you like magic
this technology is called face recognition facebook s algorithms are able to recognize your friends faces after they have been tagged only a few times it s pretty amazing technology facebook can recognize faces with accuracy which is pretty much as good as humans can do
let s learn how modern face recognition works but just recognizing your friends would be too easy we can push this tech to the limit to solve a more challenging problem telling will ferrell famous actor apart from chad smith famous rock musician
so far in part and we ve used machine learning to solve isolated problems that have only one step estimating the price of a house generating new data based on existing data and telling if an image contains a certain object all of those problems can be solved by choosing one machine learning algorithm feeding in data and getting the result
but face recognition is really a series of several related problems
as a human your brain is wired to do all of this automatically and instantly in fact humans are too good at recognizing faces and end up seeing faces in everyday objects
computers are not capable of this kind of high level generalization at least not yet so we have to teach them how to do each step in this process separately
we need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step in other words we will chain together several machine learning algorithms
let s tackle this problem one step at a time for each step we ll learn about a different machine learning algorithm i m not going to explain every single algorithm completely to keep this from turning into a book but you ll learn the main ideas behind each one and you ll learn how you can build your own facial recognition system in python using openface and dlib
the first step in our pipeline is face detection obviously we need to locate the faces in a photograph before we can try to tell them apart
if you ve used any camera in the last years you ve probably seen face detection in action
face detection is a great feature for cameras when the camera can automatically pick out faces it can make sure that all the faces are in focus before it takes the picture but we ll use it for a different purpose finding the areas of the image we want to pass on to the next step in our pipeline
face detection went mainstream in the early s when paul viola and michael jones invented a way to detect faces that was fast enough to run on cheap cameras however much more reliable solutions exist now we re going to use a method invented in called histogram of oriented gradients or just hog for short
to find faces in an image we ll start by making our image black and white because we don t need color data to find faces
then we ll look at every single pixel in our image one at a time for every single pixel we want to look at the pixels that directly surrounding it
our goal is to figure out how dark the current pixel is compared to the pixels directly surrounding it then we want to draw an arrow showing in which direction the image is getting darker
if you repeat that process for every single pixel in the image you end up with every pixel being replaced by an arrow these arrows are called gradients and they show the flow from light to dark across the entire image
this might seem like a random thing to do but there s a really good reason for replacing the pixels with gradients if we analyze pixels directly really dark images and really light images of the same person will have totally different pixel values but by only considering the direction that brightness changes both really dark images and really bright images will end up with the same exact representation that makes the problem a lot easier to solve
but saving the gradient for every single pixel gives us way too much detail we end up missing the forest for the trees it would be better if we could just see the basic flow of lightness darkness at a higher level so we could see the basic pattern of the image
to do this we ll break up the image into small squares of x pixels each in each square we ll count up how many gradients point in each major direction how many point up point up right point right etc then we ll replace that square in the image with the arrow directions that were the strongest
the end result is we turn the original image into a very simple representation that captures the basic structure of a face in a simple way
to find faces in this hog image all we have to do is find the part of our image that looks the most similar to a known hog pattern that was extracted from a bunch of other training faces
using this technique we can now easily find faces in any image
if you want to try this step out yourself using python and dlib here s code showing how to generate and view hog representations of images
whew we isolated the faces in our image but now we have to deal with the problem that faces turned different directions look totally different to a computer
to account for this we will try to warp each picture so that the eyes and lips are always in the sample place in the image this will make it a lot easier for us to compare faces in the next steps
to do this we are going to use an algorithm called face landmark estimation there are lots of ways to do this but we are going to use the approach invented in by vahid kazemi and josephine sullivan
the basic idea is we will come up with specific points called landmarks that exist on every face the top of the chin the outside edge of each eye the inner edge of each eyebrow etc then we will train a machine learning algorithm to be able to find these specific points on any face
here s the result of locating the face landmarks on our test image
now that we know were the eyes and mouth are we ll simply rotate scale and shear the image so that the eyes and mouth are centered as best as possible we won t do any fancy d warps because that would introduce distortions into the image we are only going to use basic image transformations like rotation and scale that preserve parallel lines called affine transformations
now no matter how the face is turned we are able to center the eyes and mouth are in roughly the same position in the image this will make our next step a lot more accurate
if you want to try this step out yourself using python and dlib here s the code for finding face landmarks and here s the code for transforming the image using those landmarks
now we are to the meat of the problem actually telling faces apart this is where things get really interesting
the simplest approach to face recognition is to directly compare the unknown face we found in step with all the pictures we have of people that have already been tagged when we find a previously tagged face that looks very similar to our unknown face it must be the same person seems like a pretty good idea right
there s actually a huge problem with that approach a site like facebook with billions of users and a trillion photos can t possibly loop through every previous tagged face to compare it to every newly uploaded picture that would take way too long they need to be able to recognize faces in milliseconds not hours
what we need is a way to extract a few basic measurements from each face then we could measure our unknown face the same way and find the known face with the closest measurements for example we might measure the size of each ear the spacing between the eyes the length of the nose etc if you ve ever watched a bad crime show like csi you know what i am talking about
ok so which measurements should we collect from each face to build our known face database ear size nose length eye color something else
it turns out that the measurements that seem obvious to us humans like eye color don t really make sense to a computer looking at individual pixels in an image researchers have discovered that the most accurate approach is to let the computer figure out the measurements to collect itself deep learning does a better job than humans at figuring out which parts of a face are important to measure
the solution is to train a deep convolutional neural network just like we did in part but instead of training the network to recognize pictures objects like we did last time we are going to train it to generate measurements for each face
the training process works by looking at face images at a time
then the algorithm looks at the measurements it is currently generating for each of those three images it then tweaks the neural network slightly so that it makes sure the measurements it generates for and are slightly closer while making sure the measurements for and are slightly further apart
after repeating this step millions of times for millions of images of thousands of different people the neural network learns to reliably generate measurements for each person any ten different pictures of the same person should give roughly the same measurements
machine learning people call the measurements of each face an embedding the idea of reducing complicated raw data like a picture into a list of computer generated numbers comes up a lot in machine learning especially in language translation the exact approach for faces we are using was invented in by researchers at google but many similar approaches exist
this process of training a convolutional neural network to output face embeddings requires a lot of data and computer power even with an expensive nvidia telsa video card it takes about hours of continuous training to get good accuracy
but once the network has been trained it can generate measurements for any face even ones it has never seen before so this step only needs to be done once lucky for us the fine folks at openface already did this and they published several trained networks which we can directly use thanks brandon amos and team
so all we need to do ourselves is run our face images through their pre trained network to get the measurements for each face here s the measurements for our test image
so what parts of the face are these numbers measuring exactly it turns out that we have no idea it doesn t really matter to us all that we care is that the network generates nearly the same numbers when looking at two different pictures of the same person
if you want to try this step yourself openface provides a lua script that will generate embeddings all images in a folder and write them to a csv file you run it like this
this last step is actually the easiest step in the whole process all we have to do is find the person in our database of known people who has the closest measurements to our test image
you can do that by using any basic machine learning classification algorithm no fancy deep learning tricks are needed we ll use a simple linear svm classifier but lots of classification algorithms could work
all we need to do is train a classifier that can take in the measurements from a new test image and tells which known person is the closest match running this classifier takes milliseconds the result of the classifier is the name of the person
so let s try out our system first i trained a classifier with the embeddings of about pictures each of will ferrell chad smith and jimmy falon
then i ran the classifier on every frame of the famous youtube video of will ferrell and chad smith pretending to be each other on the jimmy fallon show
it works and look how well it works for faces in different poses even sideways faces
let s review the steps we followed
now that you know how this all works here s instructions from start to finish of how run this entire face recognition pipeline on your own computer
update you can still follow the steps below to use openface however i ve released a new python based face recognition library called face recognition that is much easier to install and use so i d recommend trying out face recognition first instead of continuing below
i even put together a pre configured virtual machine with face recognition opencv tensorflow and lots of other deep learning tools pre installed you can download and run it on your computer very easily give the virtual machine a shot if you don t want to install all these libraries yourself
original openface instructions
if you liked this article please consider signing up for my machine learning is fun newsletter
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
was a big year for artificial intelligence ai and machine learning ml and although some of it was pure hype a lot of what was achieved will be significant as the field continues to grow and have an impact in every industry below i summarize what i consider the main achievements or events of the year and briefly explain why they re important the list includes technical achievements as well as commercial ones because in the end the real impact of technological transformation happens when technology reaches the masses while some of them are preliminary in nature and most were not realized from scratch in they do plant important seeds for the future
i hope this list is helpful in identifying what was most important in there were many other advances of course but in thinking about the future how might each of these affect you your business and society in the future
svp of ai amp data science at dataminr ex head of r amp d digitalocean ex director at yahoo ex cto chief scientist machine learning computer vision
here we go let s make a prototype of a reinforcement learning rl agent that masters a trading skill
given that implemenation of the prototype runs on r language i encourage r users and programmers to get closer to the ideas expressed in this material
take a read of this paper https storage googleapis com deepmind media dqn dqnnaturepaper pdf
it will introduce you to the idea of using a deep q network dqn to approximate value functions that are crucial to solving a markov decision process
i also recommend a deep dive into rl math using this book preprint of richard s sutton and andrew g barto http incompleteideas net book bookdraft nov pdf
later on i will introduce an advanced version of the original dqn which incorporates more ideas to help it converge well and fast namely
deep double dueling noisy neural networks with prioritized sampling from an experience replay buffer
what does make this approach superior to the classic dqn
well what about trading made by a dqn agent it is an interesting topic per se
there are the reasons why it is interesting
to get things done fast get accounted with the code of this nn that i want to share since it is one of the puzzling parts on the whole thing
r code for a value neural network that uses keras backend to build our rl agent
i used this source to adapt the python code for a noisy part of the network https github com jakegrigsby keras rl
this neural network looks like this
recall that in dueling architecture we employ the equality eq
q a v where
a a avg a
q state action value
v state value
a advantage
other variables in the code are quite self explanatory besides this architecture is good for a given task only so don t take it for granted
the rest of code is thougth to be rather boilerplate to publish and it is a challenge for the programmer to write it on their own
we run our agent against a synthetic dataset our transaction cost equals
result is great the maximum average reward should be in this setting
we see critic loss average reward per episode cumulative reward sample of last rewards
we train our agent on an arbitrarily chosen stock symbol that showed interesting behaviour flatty beginning rapid growth in the middle and a dreary ending there are about days in our training set transaction cost set to purposefully low each reward is a usd profit loss after buying selling share
source https finance yahoo com quote algn ltr
after tweaking of some parameters leaving the nn architecture the same we came to this result
it is not bad since after all the agent learned how to make profit pushing the three buttons on his console
note that at its apex the average reward per episode has beaten the realistic transaction cost that one may face in real trading
it is too bad that stocks crash like crazy on bad news
trading with the help of rl is not only challenging but also rewarding when your robot makes it better than you do it is time to spend personal time to get educated and healthy
i hope that was an interesting trip to you if you enjoyed this story show it to me if much interest exists i can continue and show you how policy gradient methods work using r language and keras api
i also want to thank my friends passionate about neural networks for advices
what was once science fiction or wishful thinking today is truism year olds have in their tiny palms handhelds as powerful as the supercomputers of yesteryears the ones that propelled us into space or the ones that brought down hiroshima and nagasaki so the title shouldn t surprise as much as wake us up this one isn t a plot from a movie rather ideas that may shape what lies ahead and for good we manipulate in relationships we manipulate our dog and yes our dog manipulates us for love rather our dog manipulates us way better than our spouses ever will
in today s tech age we do not write programs anymore but algorithms that not just program but have the ability to process compute and learn from an incident and accommodate for every such incident and the constraint that came along the way that is what we call machine learning
like the brain which is trained to complete a task with the minimum effort required the algorithms too are but an extension of our neurons and they do as asked or as programmed of them the key focus of any algorithm therefore is to optimize and not ponder upon what ifs i am okay with that and that in itself renders machines the efficiency and speed we are so dazzled by they follow a checklist to learn they can not and will not seek the so whats and now whats
i am not a naysayer or a pessimist and i am not taking this article onto that beaten path i am rather largely asking some pertinent questions every ai ml and deep learning enthusiast programmer or visionary needs to ponder as we continue to make some giant strides in the space these may well be some of the existential questions that may shape up the next generation of algorithms and bring a more heuristic perspective to the field
i leave everyone with two cases that we all may relate to and pit them against what a typical ml algorithm does in these scenarios i would also offer some hacks which as citizens of this era we may use to nullify the mindnumbing algorithmization of our lives but as programmers and developers of this industry there isn t escaping this through hacks we will have to take the challenges head on and better empower our ai universe
case the confirmation bias at play
i am a liberal american or an immigrant in the us or pro lgbt rights i am also just beginning to understand american politics i go to facebook and like a couple of pages around these topics i am thrown in some videos around these issues by the facebook autoplay algorithm and i end up watching these short informative videos by the end of my browsing session while i have no idea of what republican stands are i have already ended up hating all republicans alike not just trump alone alternate scenario is that i am conservative fiscally liberal in a few social aspects conservative in some other with a belief in god i end up again on the same train of thoughts videos and end up hating the lgbtq community for they are aparently against the will of jesus obama and obamacare for its an anti capitalistic welfare scheme
months down the line i have a religion of my own i am not a christian anymore or catholic or a hindu or muslim rather i am a liberal or conservative or an immigrant and every alternate view is a sin there are many like me who i haven t met but they stand by me and my stands and some crazy bigots who abuse me as much on every social forum good i don t have to meet them in real i am attached more to stands i take or decided to take than real causes that is billions of marketing dollars working its way to behavioural analytics nudging me to be who i really am every marginal inkling i had is now part of my belief system
case the confirmation conundrum at play
i am an average built human with average features my instagram flipboard and browser feeds keep flowing in beautiful celebrity pics that either make me feel i am thin or fat or worse too thin or too fat i just have an inkling at this stage that somethings amiss that i must redress i ask around and i am told all s well and i get on with life but say i didn t ask around for i am a person of science and instead tried googling my way to a definitive answer to this million dollar question
am i fat are the three magical words i search for google very generously shares some of its biggest hits on body mass index bmi parity restores momentarily but there are some catchy hyperlinks around how to stay fit and lead a healthy life and shed that extra pound couple of articles and few days later my youtube has videos around weight loss there is an amazon ad that plays in between letting me know that there is a sale on all kinds of weight loss and gain products one more click and i am led to believe there is something definitely wrong with me and i tussle with this idea for more days than i would have wanted to gladly oprah s weight watchers and its consumer insights algorithms have made it possible for some very handy products that are custom tailored for me what it does to my self confidence is anyone s guess
there can be numerous such examples that affect our ability to think straight or our ability to think itself that leads me to ask if ml algorithms as of today learn from us or mere feed on our vulnerabilities insecurities beliefs and biases and end up fortifying them
there are simple hacks of not searching for our inklings outside the incognito mode using browsers devices and search engines from different universes apple google microsoft amazon or following diverse pages with alternate perspectives on social media to restore some sanity and diverse line of thoughts remember in a fox universe america is great again in cnbc s and cnn s america always was but now isn t wish things were as binary
the ones who are currently designing the algorithms that power the deep learning and ml universe hacks are no good we have to think through the algorithms we set out to learn from us for me every ml algorithm is a baby needing to be raised and it needs care caution and a higher sense of purpose it s as living as we are
artificialintelligence ai machinelearning ml aiml deeplearning customization hyper personalization behavioral analytics
left leaning liberal
sometimes it is even hard for humans to understand if a news article is real fake or satire so i asked my self if i can train a machine learning model to decide to which class real or satire an given article belongs there are websites like https www theonion com publishing satire news every day which can be used together with regular news sites to collect trainings data for this classification problem
i grabbed large datasets of news articles in german language from news agencies and newspapers via their websites
and from the satirical news sites
for training and testing of the model in total i collected articles from to and stored them in a local database
to train a classifier i used the scikitlearn package with a linear support vector classifier svc the news texts were vectorized with a count vectorizer and tf idf weighting see the code below
of the data was used for the training of the classifier and for testing on the test set i achieved an accuracy of a precision of a recall of and a f score of in the confusion matrix below you can see the distribution of the correct and wrong classifications only of the real news are classified as satire but of the satirical texts are not detected as satire quite good results
i think the presented method can be used with other languages and i expect similar results as with the german news
are computers better than humans in detecting satire in texts
more details can be found in the article https arxiv org abs
university of applied sciences upper austria school of informatics communications and media http www stoeckl ai profil
dear friends
i am excited to announce the newest course from deeplearning ai ai for everyone it will be available on coursera in early
ai is not only for engineers this non technical course will help you understand technologies like machine learning and deep learning and spot opportunities to apply ai to problems in your own organization you will see examples of what today s ai can and cannot do finally you will understand how ai is impacting society and how to navigate through this technological change
this course is intended for everyone ranging from ceos product managers marketers salespeople designers to financiers if you are a non technical business leader ai for everyone will help you understand how to build a sustainable ai strategy if you are a machine learning engineer or data scientist this is the course to ask your manager vp or ceo to take if you want them to understand what you can and cannot do
artificial intelligence will transform every industry just as electricity did years ago between now and ai will create an estimated trillion of gdp growth
through my work with landing ai i meet regularly with ceos who want to transform their companies with machine learning the number one question they ask is how to align their long term business strategy with today s ai capabilities
the ai powered future must be built by both engineers and application domain experts we will need millions of ai engineers we will also need millions of experts from every industry to understand how to apply ai within their organizations
since the deep learning specialization launched hundreds of thousands of you have enrolled in a course and begun furthering your career in deep learning
we will continue to work to bring the deeplearning ai community additional courses resources and events let us know what you d like to see next in the deeplearning ai forums or visit our careers page and apply to join us and make world class ai education accessible to everyone
you can pre enroll for ai for everyone and be one of the first to take the course when it becomes available on coursera
i look forward to hearing from you and am excited to continue expanding the ai community together
andrew ng
ai machine learning deep learning online education
dear friends
i am excited to announce the newest course from deeplearning ai ai for everyone it will be available on coursera in early
ai is not only for engineers this non technical course will help you understand technologies like machine learning and deep learning and spot opportunities to apply ai to problems in your own organization you will see examples of what today s ai can and cannot do finally you will understand how ai is impacting society and how to navigate through this technological change
this course is intended for everyone ranging from ceos product managers marketers salespeople designers to financiers if you are a non technical business leader ai for everyone will help you understand how to build a sustainable ai strategy if you are a machine learning engineer or data scientist this is the course to ask your manager vp or ceo to take if you want them to understand what you can and cannot do
artificial intelligence will transform every industry just as electricity did years ago between now and ai will create an estimated trillion of gdp growth
through my work with landing ai i meet regularly with ceos who want to transform their companies with machine learning the number one question they ask is how to align their long term business strategy with today s ai capabilities
the ai powered future must be built by both engineers and application domain experts we will need millions of ai engineers we will also need millions of experts from every industry to understand how to apply ai within their organizations
since the deep learning specialization launched hundreds of thousands of you have enrolled in a course and begun furthering your career in deep learning
we will continue to work to bring the deeplearning ai community additional courses resources and events let us know what you d like to see next in the deeplearning ai forums or visit our careers page and apply to join us and make world class ai education accessible to everyone
you can pre enroll for ai for everyone and be one of the first to take the course when it becomes available on coursera
i look forward to hearing from you and am excited to continue expanding the ai community together
andrew ng
ai machine learning deep learning online education
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
maybe it s out there somewhere
you can always find insightful stories on our homepage
enjoy these stories about getting lost losing things and finding what you never knew you were looking for
let s get started
the most common problem we face while starting with data science or machine learning is from where to start even i got stuck with the same question but with time i learned about it its algorithm and about how it works but it was very slow that s the point i was very slow i spent a lot of time understanding it and then was pushed back since my basics were not clear so here i m with a tutorial that can lead you to from a beginner to a pro in machine learning i will be updating you guys with a blog and a tutorial on github every week
things we will be covering in the tutorial series
the codes of all these will be available at github
business applications machine learning can be used in business analysis work as well in spam email detection stock prediction natural language processing has proved to be very efficient in the field of machine learning
there is endless use of machine learning it s heavily upon the coder how he she implements it before we get started with machine learning it is also important to know the basics of python so i just made a tutorial which is enough to get you guys started with data science
python basics
there are certain simple things which we should remember before starting with python
let us see a hello world program in python
step open your terminal and type python in case you don t have python follow this link to install it on your system windows linux mac
step if you have python installed in your system then type python on your terminal and press enter
wait but we haven t included any header file so are we wrong
well no as discussed earlier there is no need to include any header files initially isn t that simple
this just notebook gives a brief explanation of python basics
link to the code python basics
pandas
pandas is one of the most efficient libraries for data science in python it makes handling of dataset very easy for the developer the problem developers face without pandas is that it requires manually handling each and every part of the dataset like columns rows its size etc but pandas has proved to be one of the most efficient libraries in the field of data science it automates the loading of data into memory very quickly basically used for data manipulation and analysis a quick overview of pandas is shown in below notebook to know about jupyter have a look on the below notebook
numpy
numpy is a library adding support for large multi dimensional arrays and matrices along with a large collection of high level mathematical functions to operate on these arrays
so this was all about chapter of go ml tutorial link to the codes link
thanks for your time we hope that you liked our first part of go ml tutorials follow me on github for further updates on this course
linkedin
data scientist and researcher
in the previous blog we discussed python basics pandas basics numpy basics if you haven t been through the tutorials please have a look at it
link of the tutorials chapter
so let s get started with our second course getting started with machine learning with python in this course we will be discussing the following
machine learning is sub divided into the following types of learning
now let s have a quick introduction of the above types of learning
supervised learning as the name indicates the presence of a supervisor as a teacher basically supervised learning is learning in which we teach or train the machine using data which is well labelled that means some data is already tagged with the correct answer after that the machine is provided with a new set of examples data so that supervised learning algorithm analyses the training data set of training examples and produces a correct outcome from labelled data
unsupervised learning is a class of machine learning techniques to find the patterns in data the data given to the unsupervised algorithm are not labelled which means only the input variables x are given with no corresponding output variables eg clustering lda
as you may have guessed semi supervised learning algorithms are trained on a combination of labelled and unlabeled data this is useful for a few reasons first the process of labelling massive amounts of data for supervised learning is often prohibitively time consuming and expensive
what s more too much labelling can impose human biases on the model that means including lots of unlabeled data during the training process actually tends to improve the accuracy of the final model while reducing the time and cost spent building it
a reinforcement learning algorithm or agent learns by interacting with its environment the agent receives rewards by performing correctly and penalties for performing incorrectly the agent learns without intervention from a human by maximizing its reward and minimizing its penalty
we will be focusing on the knn algorithm that is widely used in classification problems
let s make this algorithm simpler by breaking it down into pieces
knn algorithm is very simple its just the euclidean distance formula
simple right
so let s see how can this algorithm be used for classification we will be considering the iris dataset for this let s have a look at how the iris dataset looks like
to classify the species of the iris flower namely setosa versicolor virginica
first let s get the euclidean distance into code
initially we set the default of distance equal to then we are running the loop from to the length of the total size of the dataset in our case we have test dataset of length so the length becomes equal to and the loops execute times
this is how the knn algorithm works
as we see in the above image there are two classes namely a and b suppose we introduce test data and our ultimate goal is to predict its final label i e a or b so we calculate the euclidean distance of the test data with the other dataset suppose this is how our test and train dataset looks like
now we calculate euclidean distance between the test and train dataset this is how the process goes
and as we see that the euclidean distance for virginica is less so our nearest neighbour is virginica this is how knn algorithm works
the above was only for two sets of data think of a bigger dataset like iris dataset that has about rows so we calculate the distance from each row and then we sort the value in ascending order code for sorting in python
the code as well as the working example is available in the below notebook as well as you can find the whole tutorial in my github
show your love my clapping if you like it follow my machine learning corses in github
data scientist and researcher
the idea of using artificial intelligence ai to accelerate drug discovery process and boost a success rate of pharmaceutical research programs has inspired a surge of activity in this area over the last several years in things are getting even hotter with the increase in the amount of partnerships investments and other important events summarized and grouped below into mini trends
this year has been marked by an impressive number of fundraising deals among ai driven drug discovery startups a clear indication of the ai for drug discovery space gaining some serious attractiveness for venture capitalists
so far a london based benevolentai appears to be a leader of the year in terms of fundraising in april they closed a m round reaching a staggering billion valuation mark while met with certain degree of skepticism this news and the current pace of research activity by the company undoubtedly puts benevolentai in a very strong position among competitors
atomwise which was founded in and pioneered the use of deep neural networks for structure based drug design raised m round a investment to advance its ai driven drug discovery technology atomnet the company says it screens million small molecules each day and uses atomnet which is utilizing deep learning algorithms to analyze molecules and predict their potency as medications toxicity and side effects
a quite unique company on the list a us based insilico medicine which is the only one startup among its closest competitors which develops a full stack artificial intelligence system based on generative adversarial networks gans allowing for an end to end drug discovery process from basic biological modeling and biomarker development to hit molecule generation lead optimization and pre clinical validation of drug candidates in june insilico medicine received an undisclosed amount of strategic investment from wuxi apptec bringing totally raised capital up to m according to crunchbase
notably just a month later wuxi apptec participated in a m investment round for another ai driven startup verge genomics the latter uses machine learning and ai to develop therapeutics against alzheimer s and parkinson s disease verge is also actively growing its database of patient genomic data allegedly the company possesses one of the industry s largest resources in this therapeutic area
new york paris based owkin founded in to apply machine learning for optimizing drug discovery process via better comprehending the overabundant biological data raised its round a of m in january to scale its technology platform owkin socrates the platform can integrate molecular and imaging libraries with patient data to reveal patterns of biomarkers causing a disease and the company is applying transfer learning to improve model performance where properly labeled data is scarce
founded in by a group of quantum physicists at mit xtalpi is a u s china biotech firm which has raised a series b round of m in january from several investors including google and sequoia china among the others the company is claiming that it can quickly and accurately predict numerous important characteristics of small molecule drugs and solid forms by combining artificial intelligence quantum physics and high performance cloud computing using this sophisticated interplay of technologies the company will be able to provide time saving insights into the safety stability and efficacy of drug candidates
later this year google also co invested in benchsci a smart platform for ai powered search for biological products the round totalled million from several investors
engine biosciences is a san francisco and singapore based biotech firm which announced a m funding round to advance its ai based platform for drug discovery development of combination therapeutics and cellular reprogramming the company s technology allows researchers and drug developers to reveal gene interactions and biological networks and provide test therapies specifically targeting genetic interactions the company s ai platform can assist in target discovery drug repurposing and analysis for precision medicine applications
other notable investments in include twoxar m revivemed m gtn m etc
to review an aggregate statistics for the ai in drug discovery industry read a landscape of artificial intelligence ai in pharmaceutical r amp d report
in pharmaceutical companies show continuous interest in partnering with emerging ai driven startups to leverage the power of algorithms for boosting own drug discovery programs below is a list of some of the notable drug design collaborations of this kind
the last month of this fruitful year was marked by a new research collaboration between german pharmaceutical giant merck and a canadian ai driven company cyclica the parties agreed that merck will use cyclica s proprietary ai driven cloud based in silico proteome screening platform ligand express to clarify mechanisms of action for a number of merck s small molecule candidates evaluate their safety profiles and uncover additional therapeutic applications
in november bayer established a multi phase research collaboration with toronto based drug discovery company cyclica to utilize its multifaceted ai driven discovery platform for a broad range of research tasks in the framework of this collaboration cyclica will provide its cloud based proteome screening platform ligand express to study the off target profiles of small molecules and apply its first in class differential drug design ddd technology for multi targeted drug design furthermore it will apply its ai technology to build state of the art predictive models for pharmacokinetic properties
in september pfizer entered into an evaluation agreement with atomwise now the ai developing startup will need to identify promising drug candidates for up to three proteins of choice by pfizer
just a couple of months earlier pfizer partnered with another ai driven startup xtalpi to develop a drug discovery software platform which would utilize xtalpi s expertise in computational physics and artificial intelligence the platform is to be applied for accurate molecular modeling of drug like small molecules
bristol myers squibb entered a multi target research collaboration agreement with sirenas a biotech company applying machine learning based computational approaches to discover therapeutics derived from the global microbiome to apply its proprietary drug discovery platform against a series of undisclosed but challenging therapeutic targets the research collaboration leverages sirenas expertise in applying its proprietary data mining technology atlantis to identify potential drug candidates among sirenas proprietary chemical library isolated from global microbiome collections it is important to note another area of sirenas expertise state of the art organic synthesis which makes it possible for the company to deliver not only computational predictions but also chemical compounds with unusual nature inspired scaffolds
in may boehringer ingelheim partnered with bactevo to apply their totally integrated medicines engine for identifying novel small molecule drug candidates
in may glaxosmithkline gsk has formed a drug design collaboration with cloud pharmaceuticals an ai drive drug discovery company to develop a series of small molecules against biological targets specified by gsk
read how big pharma adopts ai to boost drug discovery to find out about more collaborations of this kind and typical use cases for ai application in drug discovery
on the one hand pharmaceutical companies are increasingly hiring ai startups to explore opportunities but on the other hand they are equally active in growing internal ai expertise and shaping digital infrastructures for more efficient data usage
recently novartis announced the completion of the first phase of a company s digital transformation strategy focusing on big data digital infrastructure and artificial intelligence the first phase was internal program called stride and it included the launch of several important it infrastructure systems for document management internal investigation high performance computing clinical trial management and other tasks
the next phase of novartis s digital transformation is to implement a predictive analytics platform driven by machine learning algorithms to support clinical trial operations this will be done in the framework of nerve live initiative and in collaboration with us machine learning company quantumblack
finally there are plans for the third big future project data the one bringing all of novartis data sets together to be able to query any data in a centralized mannar this is certainly a major prerequisite for the ai driven transformation in the company
similarly pretty much every global drug maker pfizer astrazeneca eli lilly merck gsk and others are taking internal restructuring measures to get prepared for the digital transformation of pharmaceutical research and adoption of artificial intelligence for drug discovery and development
it is becoming obvious that the key enablement factor of the future ai driven revolution in pharmaceutical research is data without the access to diverse interdisciplinary quality and properly curated big data a transformative impact of ai technology can not be fully realized in this context it is important to see how companies are moving in the direction of data centric research paradigm
in july gsk has invested million in andme a silicon valley gene testing company backed by google this deal opens a door for gsk to access a vast dna database providing information about the relations between genes and diseases andme has more than million customers the majority of whom opted in to allow their data being included in research programs
datavant a young us based ai driven startup is focused on organizing and structuring healthcare data for deriving actionable insights for the design and interpretation of clinical trials in the beginning of january it announced a strategic alliance with verge genomics a company using artificial intelligence to discover and develop new therapeutics the newly formed partnership aims at unlocking the value of pharmaceutical datasets in a possession of datavant clinical trial data claims pharmacy history electronic health records and genomics data on patients to accelerate discovery and development of new medications
so far datavant has two more partnerships besides verge with duke clinical research institute dcri global genomics group g all aiming at combining drug discovery expertise biological big data and novel data analytical technologies such as ai to boost innovation in the field of pharmaceutical research
in the light of the above trends focus on ai and big data a logical consequence is the pharmaceutical research industry moving towards platform based models of cooperation and doing research platforms are digital infrastructures connecting the dots between different types of activities research areas operation modes and data flows platforms or super platforms are widespread in finance consumer e commerce and other industries but this is still a new phenomenon for the pharmaceutical research several events in are quite illustrative here
it was announced that merck and accenture are working with amazon web services to create a cloud based platform that would embrace collaborators across various sectors of the life sciences industry this analytics platform will be built using open application programming interfaces apis and will facilitate a collaborative environment to accelerate early drug discovery efforts it will not only make it easier for researchers to aggregate access and analyze interdisciplinary data but will also lower barriers to market entry for novel value providers app developers data scientists content and data suppliers etc
in march wuxi nextcode announced a partnership with google to integrate its massively scalable genomics database management system and research apps in google cloud platform in turn such tools as google cloud bigquery and deepvariant will be integrated with wuxi nextcode s capabilities the two companies will also work on additional tools and apis to empower the global genomics community
read also get ready for super platforms in healthcare and pharmaceutical research
one of the important elements of a mature industrial ecosystem the presence of specialized consortia and associations whose goal is to facilitate interaction between members of the community set industry standards and reveal best practises educate general public about the topic and lobby important changes to government regulations
the pharmaceutical research industry is in its early days of a widespread adoption of artificial intelligence for drug discovery so the emerging ecosystem of ai practitioners in this space is only beginning to grow however a number of important steps towards the creation of industrial alliances has already been made recently
in may mit has formed a powerful industry academia consortium the machine learning for pharmaceutical discovery and synthesis mlpds which already includes some of the leading players in the pharmaceutical field amgen basf bayer eli lilly novartis pfizer sunovion and wuxi being headquartered in cambridge ma one of the global centers for biopharmaceutical innovation the newly formed consortium allows for close cooperation between partners a lot of them have presence in cambridge and the creation of a center for artificial intelligence ai use in pharmaceutical research
another important consortium the accelerating therapeutics for opportunities in medicine atom has been formed at the end of the last year by its founding partners gsk lawrence livermore national laboratory frederick national laboratory for cancer research and the university of california san francisco with funding support under the st century cures act while the atom s mission includes a broad range of activities to facilitate efficient drug discovery in the field of oncology some of the central tasks are focused on advancing artificial intelligence adoption by pharma players and democratising access to research big data in april numerate one of the leading ai developers from drug discovery expressed its intentions to join the consortium
finally september was marked by an important milestone the announcement of mission and launch activities of a global alliance for artificial intelligence in healthcare aaih which is to become a leading international organization for advancing artificial intelligence innovations in drug discovery clinical research diagnostics precision medicine and other key areas of pharmaceutical research and healthcare
having a standardized set of metrics and datasets for assessing and comparing a wide variety of available and novel machine learning models is essential for creating and maintaining industry s best practises
a recent move in this direction has been made by a group of scientists from ai driven drug discovery company insilico medicine in collaboration with a distributed synthetic data platform for deep learning neuromation and al n aspuru guzik s research group at the university of toronto who launched an open research platform moses molecular sets described in the paper molecular sets moses a benchmarking platform for molecular generation models the source code and datasets for the platform are all available at github
the platform is supposed to play a similar role in boosting ai driven drug discovery as imagenet played in advancing deep learning for imaging data moses is open for researchers and organizations to contribute their datasets and models to extend the benchmarking platform
the above post summarizes very briefly some of the aspects of how artificial intelligence technologies and big data are starting to play the central role in the pharmaceutical research to get a more comprehensive view on the subject please subscribe to biopharmatrend newsletter to get fresh market analytics insights directly to your inbox we will rarely bother you more than once per month
editor biopharmatrend com
my dad once told me a computer is a dumb machine it does exactly what it is told to do and nothing more he was right a computer merely executes a set of instructions coded by a programmer so how can a computer be intelligent or learn while the basic mathematical concepts behind machine learning ml are pretty simple most posts out there are jargon heavy and scare non experts away i decided to write this post as an introduction for people who don t have a math background but would like to get a sense of what is actually happening under the hood in ml
all the problems that ml solves are the same in nature we are looking to build a machine that converts something let s call it input into something else let s call it output for example we want a machine that takes as an input a picture and as an output it tells us if it s a cat or not or it can be a machine that takes some music as an input and as an output it tells us the name of the singer another example would be a machine that takes a human as an input and tells us his or her gender as output you get the point the input and output can be literally anything as long as they are related
the very cool thing about computers is that music text video or really anything is actually represented in numbers for example a picture is nothing more than a bunch of numbers each representing a color and a position on the screen
we humans can hand pick and measure the key features of any object and have a simplified representation of the object as numbers for example we can represent a human by his her height and weight if we think that s what the machine needs to make the prediction in the jargon converting complex objects into numbers is called feature selection
as far as computers are concerned the machine we are looking for takes a number or a set of numbers as an input and gives a number as an output this type of machines that deal with numbers are called mathematical functions we typically represent them with the letter f
a quiz
now that we have narrowed down the problem to numbers let s do a quick exercise if you look at the chart below and assume that you know the outputs on the left side can you predict what the output for is
yes the answer is and congratulations the process that your brain just went through is exactly what machine learning is all about here is probably how you handled the exercise
step get some data a bunch of inputs for which we know the corresponding output note i did this step for you
step assume the function has a familiar form note in the quiz you probably assumed that there is some basic multiplication or addition involved
step look at the data and search for a function that seems to work note in the quiz the function you found was output input a k a f x x
step test the function on the rest of the data to see if it really works on all inputs in the data
step apply the function to the new input in order to predict output note f
let s pause here and define some jargon the data you got at step is called the training data step amp are called model training model training is basically the part where you re searching for a general function that seems to replicate the training data this is the part that can get automated the automated process to search and find the right function is called a machine learning algorithm
before we go any further i just would like to introduce two types of problems we solve with machine learning classification and regression
classification is when the output can only take a finite number of possibilities say for example we are trying to predict if an email is spam or not spam or if a picture contains a cat or not or if a person is male or female
regression is when the output can take a continuous set of values say for example we want to predict how much a customer is going to spend based on their demographics age earnings etc the output can be or or or or etc
computers are not creative they do exactly what they re told there is however one thing in which computers are superior to humans they calculate very fast they therefore can relatively quickly search for and find a function that works as long as we tell them where to search and give them a step by step process of how to search the following paragraphs explain a few approaches of how we can teach a computer to search for a function
before we get into this approach let me just point out that a popular way of teaching ml involves functions that take numbers as an input that s because in the real world we need to solve problems where we are predicting outputs based on more than just a single input we typically choose to use numbers as input because it s easier to visualize graphically with two axis representing the two inputs
say for example we are looking to use ml to build a tool that predicts a person s gender based on his her height and weight because the output can only take possible values male or female this is a classification problem
from a graphical perspective the training data can be represented this way
the pink and blue points are our training data the color is the known output gender since the pinks seem to be close to each other and the blues seems to be close to each other let s just draw a straight line everything that falls on one side of the line would be pink and everything that falls on the other side would be blue
as you can see in the chart there is more than line that does the job and they re not all as good if you look at the two lines shown above line passes awfully close to a pink data point while line leaves more room for separation
a popular algorithm to draw a good separating line is called support vector machines svm svm basically looks for the straight line that maximizes the distance between the line and the closest training data points so that we draw a thick separating line svm is useful because it turns out maximizing things is something we have off the shelf algorithms for computers to do see below even though it may sound conceptually very simple to just draw a line svm is pretty widely used for example these medical researchers used it to do classify cancers using genetic data
let s go back to our quiz here is a pretty simple ml algorithm that we could have used to solve it to find the output corresponding to we look at the training data find the closest number to in this case that s and assume that the output for is just the same as the output for its nearest neighbor this means f f sounds pretty dumb right yes it is but it kind of works is kind of close to to get a little more sophisticated we could take the average of the closest inputs to in this case that s and that would mean f average in fact this can be generalized to take the k nearest neighbors this algorithm is called the k nearest neighbors a k a k nn
the fundamental assumption behind k nn is that inputs that are close to each other are likely to have the same output this algorithm works well for functions for which the outputs can only take a few possible distinct values here is a real life example in which medical researchers used k nn to classify and diagnose different types of cancer
yes linear regression is technically machine learning it s not really used in complex machine learning but the concepts apply to most regression algorithms so i think it is useful to understand how it works
in linear regression we assume that for any input x the output is in the form of f x a x b where a and b are some numbers that we don t know yet note that we here assume before we actually do any math or anything that our function has to look that way we then search for the best a and b i e the ones that replicate the training data or at least get as close as possible
side note with some jargon when we assumed that the function has to look a certain way we introduced new variables that we called a and b in ml these variables a and b are called parameters a lot of time in ml is spent searching for the best parameters some models have millions of parameters
in order to find the best a b for each pair a b we define the error a b which basically measures how bad the function is doing in replicating the training data mathematically error a b is the difference between what the function should have predicted according to the training data and what it actually predicts according to the formula
we have just transformed our ml problem from let s find a function into let s find parameters that minimize the error as it turns out we have off the shelf algorithms that teach computers to find minimums or maximums this is the second time we came across this problem so let s dig into it a little bit
assume you are visiting a coastal city say seattle you are walking in the street check the news on your phone and hear that there is a massive tsunami coming your way you re alone have no idea what the landscape looks like but you want to get as high from the sea level as possible to protect yourself what do you do ps google maps is not working you can t get inside or climb any building and you re surrounded by tall buildings so you can t see much apart from your immediate surroundings
the best you can do is to follow the slope just walk uphill and at every crossing check the slope again if turning right or left gets you higher do that if not keep going this approach to find a maximum or a minimum is called the gradient descent so to minimize our error or maximize the thickness of the separating line and solve our above problems the computer would pick some random starting point and start walking downhill or uphill from there
i know what you re thinking this approach is kind of dumb obviously at some point you may get stuck at the top of a hill any direction you take will be going down this means you may miss out on a potential mountain nearby this problem is called the local optimum problem to solve this some algorithms introduce randomness in order to escape any local hill these are called probabilistic algorithms or randomized algorithms
if when you hear neural networks you think of some magical thing that replicates a human brain with freewill and all sorry to disappoint you it s much simpler than that neural networks are just a regression algorithm just like in linear regression the neural network algorithm assumes that the function has to look a certain way and searches for the best parameters
in neural networks the basic idea is that the function we are looking for is assumed to be a weighted average of step functions a step function is a function that has an output of when the input is below a certain threshold and an output of above that threshold so the algorithm has type of parameters to look for the weights and the tresholds why does the algorithm assume the function has to look this way because it is mathematically proven that if we pick the right number of step functions with the right tresholds and the right weights for each we can approximate any function whatever its shape is
a problem we face with step functions is that when the input is very close to the threshold the output can change radically from to if the input is changed just a little bit and this is not a natural phenomenon in real life there is a certain smoothness in the world a picture of a cat is not going to turn into something else if we change the color of pixel a little bit to solve this problem instead of using step functions we use activation functions which are similar but transition smoothly from to
what i have just described above is a layer neural network a multi layer neural network is a succession of layer neural networks the output of layer n is the input of layer n the output of the last layer is the actual output we are looking for
supervised vs unsupervised learning
everything we have talked about here so far falls under the supervised learning category unsupervised learning is when your training data has no outputs just bunch of inputs for example while in supervised learning your training data would be a bunch of pictures labeled cat and not cat in unsupervised learning your training data would be just a bunch of pictures the algorithm would by itself find that there are two categories of pictures and come up with a function that classifies the inputs so that those that are similar have the same output
conclusion
the idea behind this post is to give a high level understanding of what machine learning is about from a conceptual point of view without getting into the weeds of the mathematical and computational algorithms i hope this post will be useful to people who are curious about the topic
i sometimes write about stuff
being a hacker does not necessarily mean breaking the law hackers like those in algorithm push the boundaries of what is possible as such i put alex wissner gross in the category of hacker
in a ted talk given given by alex wissner gross in november of called a new equation for intelligence shows us what will probably be the future of artificial intelligence for him the greatness of his insight comes from the radically simplified definition of intelligence he managed to get it into a single relatively basic equation and he rightly compares it to einstein s e mc which revolutionized physics
wissner gross s talk is not easily accessible he doesn t really dumb it down though i m sure he would say he left out the really complex parts but if you can understand it the enormity of what he says cannot be overlooked and in case that s a problem he does a demonstration with quality rivaling a roger corman production
what wissner gross has done is he has made a machine think he talks about how it makes decisions without directions from its human programmers they simply give the program a scenario and the program decides on it s own what to do with it
in case you don t know about computers what i m about to say should blow your mind
the computer buys and sells stocks in a simulation and it makes a lot of money it does other basic things each of which is very impressive shipping balancing playing pong etc the ai does all of those things with equal mind boggling success
alex wissner gross ends his talk with what is probably the worst way to end a talk on what is the biggest revelation in ai since the turing test he brings up the nuclear war as foretold by almost every sci fi author who has written about artificial intelligence the day the machines fight back and win
functional artificial intelligence brings up some very interesting questions only one of which is our own machine apocalypse
how smart must a computer become before it gets rights before it ceases to be a tool and starts to become a slave
and when that happens do we have the right responsibility to treat the ai as a person
what kind of person
how do we react when we realize the computer is smarter than we are
those questions as so many things these days used to be categorized as either conspiracy theories or science fiction that s not the case anymore they are here today we live in the future and even if you re morally resistant to it someone else somewhere else isn t and his name is alex wissner gross
via algorithm
adventurspencer yogi corepoweryoga communications director for the hacker movie http www thehackermovie com trailers
computers can t think they are not human computers can t think by themselves without help computers don t have a brain and therefore can t think merely follow instructions from someone who can if computers could think they would be able to program themselves and learn some may argue that computers can learn people s tendencies and patterns but this is only because they are using an algorithm programmed into them by humans with no algorithm they would just be guessing and not have logical thoughts like a human logical thought can only come from a conscious person not a computer this shows us that what happens in the movies can t happen robots can t take over the world until they have a more advanced computer in them that can think now others may argue that computers can think because they can talk to humans like siri but in actuality siri can t think it can only interpret what people say then say a pre programmed sentence to answer this could be substantial because some people may believe that siri is like a real assistant and can answer any question when actually it can t even though it seems that siri is thinking when you ask it about the weather really it s just finding the answer online and speaking it computers can t process complex information by themselves or program themselves so until that happens computers can t think
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s portugu s alternate t rk e fran ais espa ol m xico espa ol espa a polski italiano ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
have you heard people talking about machine learning but only have a fuzzy idea of what that means are you tired of nodding your way through conversations with co workers let s change that
this guide is for anyone who is curious about machine learning but has no idea where to start i imagine there are a lot of people who tried reading the wikipedia article got frustrated and gave up wishing someone would just give them a high level explanation that s what this is
the goal is be accessible to anyone which means that there s a lot of generalizations but who cares if this gets anyone more interested in ml then mission accomplished
machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem instead of writing code you feed data to the generic algorithm and it builds its own logic based on the data
for example one kind of algorithm is a classification algorithm it can put data into different groups the same classification algorithm used to recognize handwritten numbers could also be used to classify emails into spam and not spam without changing a line of code it s the same algorithm but it s fed different training data so it comes up with different classification logic
machine learning is an umbrella term covering lots of these kinds of generic algorithms
you can think of machine learning algorithms as falling into one of two main categories supervised learning and unsupervised learning the difference is simple but really important
let s say you are a real estate agent your business is growing so you hire a bunch of new trainee agents to help you out but there s a problem you can glance at a house and have a pretty good idea of what a house is worth but your trainees don t have your experience so they don t know how to price their houses
to help your trainees and maybe free yourself up for a vacation you decide to write a little app that can estimate the value of a house in your area based on it s size neighborhood etc and what similar houses have sold for
so you write down every time someone sells a house in your city for months for each house you write down a bunch of details number of bedrooms size in square feet neighborhood etc but most importantly you write down the final sale price
using that training data we want to create a program that can estimate how much any other house in your area is worth
this is called supervised learning you knew how much each house sold for so in other words you knew the answer to the problem and could work backwards from there to figure out the logic
to build your app you feed your training data about each house into your machine learning algorithm the algorithm is trying to figure out what kind of math needs to be done to make the numbers work out
this kind of like having the answer key to a math test with all the arithmetic symbols erased
from this can you figure out what kind of math problems were on the test you know you are supposed to do something with the numbers on the left to get each answer on the right
in supervised learning you are letting the computer work out that relationship for you and once you know what math was required to solve this specific set of problems you could answer to any other problem of the same type
let s go back to our original example with the real estate agent what if you didn t know the sale price for each house even if all you know is the size location etc of each house it turns out you can still do some really cool stuff this is called unsupervised learning
this is kind of like someone giving you a list of numbers on a sheet of paper and saying i don t really know what these numbers mean but maybe you can figure out if there is a pattern or grouping or something good luck
so what could do with this data for starters you could have an algorithm that automatically identified different market segments in your data maybe you d find out that home buyers in the neighborhood near the local college really like small houses with lots of bedrooms but home buyers in the suburbs prefer bedroom houses with lots of square footage knowing about these different kinds of customers could help direct your marketing efforts
another cool thing you could do is automatically identify any outlier houses that were way different than everything else maybe those outlier houses are giant mansions and you can focus your best sales people on those areas because they have bigger commissions
supervised learning is what we ll focus on for the rest of this post but that s not because unsupervised learning is any less useful or interesting in fact unsupervised learning is becoming increasingly important as the algorithms get better because it can be used without having to label the data with the correct answer
side note there are lots of other types of machine learning algorithms but this is a pretty good place to start
as a human your brain can approach most any situation and learn how to deal with that situation without any explicit instructions if you sell houses for a long time you will instinctively have a feel for the right price for a house the best way to market that house the kind of client who would be interested etc the goal of strong ai research is to be able to replicate this ability with computers
but current machine learning algorithms aren t that good yet they only work when focused a very specific limited problem maybe a better definition for learning in this case is figuring out an equation to solve a specific problem based on some example data
unfortunately machine figuring out an equation to solve a specific problem based on some example data isn t really a great name so we ended up with machine learning instead
of course if you are reading this years in the future and we ve figured out the algorithm for strong ai then this whole post will all seem a little quaint maybe stop reading and go tell your robot servant to go make you a sandwich future human
so how would you write the program to estimate the value of a house like in our example above think about it for a second before you read further
if you didn t know anything about machine learning you d probably try to write out some basic rules for estimating the price of a house like this
if you fiddle with this for hours and hours you might end up with something that sort of works but your program will never be perfect and it will be hard to maintain as prices change
wouldn t it be better if the computer could just figure out how to implement this function for you who cares what exactly the function does as long is it returns the correct number
one way to think about this problem is that the price is a delicious stew and the ingredients are the number of bedrooms the square footage and the neighborhood if you could just figure out how much each ingredient impacts the final price maybe there s an exact ratio of ingredients to stir in to make the final price
that would reduce your original function with all those crazy if s and else s down to something really simple like this
notice the magic numbers in bold and these are our weights if we could just figure out the perfect weights to use that work for every house our function could predict house prices
a dumb way to figure out the best weights would be something like this
start with each weight set to
run every house you know about through your function and see how far off the function is at guessing the correct price for each house
for example if the first house really sold for but your function guessed it sold for you are off by for that single house
now add up the squared amount you are off for each house you have in your data set let s say that you had home sales in your data set and the square of how much your function was off for each house was a grand total of that s how wrong your function currently is
now take that sum total and divide it by to get an average of how far off you are for each house call this average error amount the cost of your function
if you could get this cost to be zero by playing with the weights your function would be perfect it would mean that in every case your function perfectly guessed the price of the house based on the input data so that s our goal get this cost to be as low as possible by trying different weights
repeat step over and over with every single possible combination of weights whichever combination of weights makes the cost closest to zero is what you use when you find the weights that work you ve solved the problem
that s pretty simple right well think about what you just did you took some data you fed it through three generic really simple steps and you ended up with a function that can guess the price of any house in your area watch out zillow
but here s a few more facts that will blow your mind
pretty crazy right
ok of course you can t just try every combination of all possible weights to find the combo that works the best that would literally take forever since you d never run out of numbers to try
to avoid that mathematicians have figured out lots of clever ways to quickly find good values for those weights without having to try very many here s one way
first write a simple equation that represents step above
now let s re write exactly the same equation but using a bunch of machine learning math jargon that you can ignore for now
this equation represents how wrong our price estimating function is for the weights we currently have set
if we graph this cost equation for all possible values of our weights for number of bedrooms and sqft we d get a graph that might look something like this
in this graph the lowest point in blue is where our cost is the lowest thus our function is the least wrong the highest points are where we are most wrong so if we can find the weights that get us to the lowest point on this graph we ll have our answer
so we just need to adjust our weights so we are walking down hill on this graph towards the lowest point if we keep making small adjustments to our weights that are always moving towards the lowest point we ll eventually get there without having to try too many different weights
if you remember anything from calculus you might remember that if you take the derivative of a function it tells you the slope of the function s tangent at any point in other words it tells us which way is downhill for any given point on our graph we can use that knowledge to walk downhill
so if we calculate a partial derivative of our cost function with respect to each of our weights then we can subtract that value from each weight that will walk us one step closer to the bottom of the hill keep doing that and eventually we ll reach the bottom of the hill and have the best possible values for our weights if that didn t make sense don t worry and keep reading
that s a high level summary of one way to find the best weights for your function called batch gradient descent don t be afraid to dig deeper if you are interested on learning the details
when you use a machine learning library to solve a real problem all of this will be done for you but it s still useful to have a good idea of what is happening
the three step algorithm i described is called multivariate linear regression you are estimating the equation for a line that fits through all of your house data points then you are using that equation to guess the sales price of houses you ve never seen before based where that house would appear on your line it s a really powerful idea and you can solve real problems with it
but while the approach i showed you might work in simple cases it won t work in all cases one reason is because house prices aren t always simple enough to follow a continuous line
but luckily there are lots of ways to handle that there are plenty of other machine learning algorithms that can handle non linear data like neural networks or svms with kernels there are also ways to use linear regression more cleverly that allow for more complicated lines to be fit in all cases the same basic idea of needing to find the best weights still applies
also i ignored the idea of overfitting it s easy to come up with a set of weights that always works perfectly for predicting the prices of the houses in your original data set but never actually works for any new houses that weren t in your original data set but there are ways to deal with this like regularization and using a cross validation data set learning how to deal with this issue is a key part of learning how to apply machine learning successfully
in other words while the basic concept is pretty simple it takes some skill and experience to apply machine learning and get useful results but it s a skill that any developer can learn
once you start seeing how easily machine learning techniques can be applied to problems that seem really hard like handwriting recognition you start to get the feeling that you could use machine learning to solve any problem and get an answer as long as you have enough data just feed in the data and watch the computer magically figure out the equation that fits the data
but it s important to remember that machine learning only works if the problem is actually solvable with the data that you have
for example if you build a model that predicts home prices based on the type of potted plants in each house it s never going to work there just isn t any kind of relationship between the potted plants in each house and the home s sale price so no matter how hard it tries the computer can never deduce a relationship between the two
so remember if a human expert couldn t use the data to solve the problem manually a computer probably won t be able to either instead focus on problems where a human could solve the problem but where it would be great if a computer could solve it much more quickly
in my mind the biggest problem with machine learning right now is that it mostly lives in the world of academia and commercial research groups there isn t a lot of easy to understand material out there for people who would like to get a broad understanding without actually becoming experts but it s getting a little better every day
if you want to try out what you ve learned in this article i made a course that walks you through every step of this article including writing all the code give it a try
if you want to go deeper andrew ng s free machine learning class on coursera is pretty amazing as a next step i highly recommend it it should be accessible to anyone who has a comp sci degree and who remembers a very minimal amount of math
also you can play around with tons of machine learning algorithms by downloading and installing scikit learn it s a python framework that has black box versions of all the standard algorithms
if you liked this article please consider signing up for my machine learning is fun newsletter
also please check out the full length course version of this article it covers everything in this article in more detail including writing the actual code in python you can get a free day trial to watch the course if you sign up with this link
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in portugu s ti ng vi t or italiano
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
are you tired of reading endless news stories about deep learning and not really knowing what that means let s change that
this time we are going to learn how to write programs that recognize objects in images using deep learning in other words we re going to explain the black magic that allows google photos to search your photos based on what is in the picture
just like part and part this guide is for anyone who is curious about machine learning but has no idea where to start the goal is be accessible to anyone which means that there s a lot of generalizations and we skip lots of details but who cares if this gets anyone more interested in ml then mission accomplished
if you haven t already read part and part read them now
you might have seen this famous xkcd comic before
the goof is based on the idea that any year old child can recognize a photo of a bird but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over years
in the last few years we ve finally found a good approach to object recognition using deep convolutional neural networks that sounds like a a bunch of made up words from a william gibson sci fi novel but the ideas are totally understandable if you break them down one by one
so let s do it let s write a program that can recognize birds
before we learn how to recognize pictures of birds let s learn how to recognize something much simpler the handwritten number
in part we learned about how neural networks can solve complex problems by chaining together lots of simple neurons we created a small neural network to estimate the price of a house based on how many bedrooms it had how big it was and which neighborhood it was in
we also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems so let s modify this same neural network to recognize handwritten text but to make the job really simple we ll only try to recognize one letter the numeral
machine learning only works when you have data preferably a lot of data so we need lots and lots of handwritten s to get started luckily researchers created the mnist data set of handwritten numbers for this very purpose mnist provides images of handwritten digits each as an x image here are some s from the data set
the neural network we made in part only took in a three numbers as the input bedrooms sq feet etc but now we want to process images with our neural network how in the world do we feed images into a neural network instead of just numbers
the answer is incredible simple a neural network takes numbers as input to a computer an image is really just a grid of numbers that represent how dark each pixel is
to feed an image into our neural network we simply treat the x pixel image as an array of numbers
the handle inputs we ll just enlarge our neural network to have input nodes
notice that our neural network also has two outputs now instead of just one the first output will predict the likelihood that the image is an and thee second output will predict the likelihood it isn t an by having a separate output for each type of object we want to recognize we can use a neural network to classify objects into groups
our neural network is a lot bigger than last time inputs instead of but any modern computer can handle a neural network with a few hundred nodes without blinking this would even work fine on your cell phone
all that s left is to train the neural network with images of s and not s so it learns to tell them apart when we feed in an we ll tell it the probability the image is an is and the probability it s not an is vice versa for the counter example images
here s some of our training data
we can train this kind of neural network in a few minutes on a modern laptop when it s done we ll have a neural network that can recognize pictures of s with a pretty high accuracy welcome to the world of late s era image recognition
it s really neat that simply feeding pixels into a neural network actually worked to build image recognition machine learning is magic right
well of course it s not that simple
first the good news is that our recognizer really does work well on simple images where the letter is right in the middle of the image
but now the really bad news
our recognizer totally fails to work when the letter isn t perfectly centered in the image just the slightest position change ruins everything
this is because our network only learned the pattern of a perfectly centered it has absolutely no idea what an off center is it knows exactly one pattern and one pattern only
that s not very useful in the real world real world problems are never that clean and simple so we need to figure out how to make our neural network work in cases where the isn t perfectly centered
we already created a really good program for finding an centered in an image what if we just scan all around the image for possible s in smaller sections one section at a time until we find one
this approach called a sliding window it s the brute force solution it works well in some limited cases but it s really inefficient you have to check the same image over and over looking for objects of different sizes we can do better than this
when we trained our network we only showed it s that were perfectly centered what if we train it with more data including s in all different positions and sizes all around the image
we don t even need to collect new training data we can just write a script to generate new images with the s in all kinds of different positions in the image
using this technique we can easily create an endless supply of training data
more data makes the problem harder for our neural network to solve but we can compensate for that by making our network bigger and thus able to learn more complicated patterns
to make the network bigger we just stack up layer upon layer of nodes
we call this a deep neural network because it has more layers than a traditional neural network
this idea has been around since the late s but until recently training this large of a neural network was just too slow to be useful but once we figured out how to use d graphics cards which were designed to do matrix multiplication really fast instead of normal computer processors working with large neural networks suddenly became practical in fact the exact same nvidia geforce gtx video card that you use to play overwatch can be used to train neural networks incredibly quickly
but even though we can make our neural network really big and train it quickly with a d graphics card that still isn t going to get us all the way to a solution we need to be smarter about how we process images into our neural network
think about it it doesn t make sense to train a network to recognize an at the top of a picture separately from training it to recognize an at the bottom of a picture as if those were two totally different objects
there should be some way to make the neural network smart enough to know that an anywhere in the picture is the same thing without all that extra training luckily there is
as a human you intuitively know that pictures have a hierarchy or conceptual structure consider this picture
as a human you instantly recognize the hierarchy in this picture
most importantly we recognize the idea of a child no matter what surface the child is on we don t have to re learn the idea of child for every possible surface it could appear on
but right now our neural network can t do this it thinks that an in a different part of the image is an entirely different thing it doesn t understand that moving an object around in the picture doesn t make it something different this means it has to re learn the identify of each object in every possible position that sucks
we need to give our neural network understanding of translation invariance an is an no matter where in the picture it shows up
we ll do this using a process called convolution the idea of convolution is inspired partly by computer science and partly by biology i e mad scientists literally poking cat brains with weird probes to figure out how cats process images
instead of feeding entire images into our neural network as one grid of numbers we re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture
here s how it s going to work step by step
similar to our sliding window search above let s pass a sliding window over the entire original image and save each result as a separate tiny picture tile
by doing this we turned our original image into equally sized tiny image tiles
earlier we fed a single image into a neural network to see if it was an we ll do the exact same thing here but we ll do it for each individual image tile
however there s one big twist we ll keep the same neural network weights for every single tile in the same original image in other words we are treating every image tile equally if something interesting appears in any given tile we ll mark that tile as interesting
we don t want to lose track of the arrangement of the original tiles so we save the result from processing each tile into a grid in the same arrangement as the original image it looks like this
in other words we ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting
the result of step was an array that maps out which parts of the original image are the most interesting but that array is still pretty big
to reduce the size of the array we downsample it using an algorithm called max pooling it sounds fancy but it isn t at all
we ll just look at each x square of the array and keep the biggest number
the idea here is that if we found something interesting in any of the four input tiles that makes up each x grid square we ll just keep the most interesting bit this reduces the size of our array while keeping the most important bits
so far we ve reduced a giant image down into a fairly small array
guess what that array is just a bunch of numbers so we can use that small array as input into another neural network this final neural network will decide if the image is or isn t a match to differentiate it from the convolution step we call it a fully connected network
so from start to finish our whole five step pipeline looks like this
our image processing pipeline is a series of steps convolution max pooling and finally a fully connected network
when solving problems in the real world these steps can be combined and stacked as many times as you want you can have two three or even ten convolution layers you can throw in max pooling wherever you want to reduce the size of your data
the basic idea is to start with a large image and continually boil it down step by step until you finally have a single result the more convolution steps you have the more complicated features your network will be able to learn to recognize
for example the first convolution step might learn to recognize sharp edges the second convolution step might recognize beaks using it s knowledge of sharp edges the third step might recognize entire birds using it s knowledge of beaks etc
here s what a more realistic deep convolutional network like you would find in a research paper looks like
in this case they start a x pixel image apply convolution and max pooling twice apply convolution more times apply max pooling and then have two fully connected layers the end result is that the image is classified into one of categories
so how do you know which steps you need to combine to make your image classifier work
honestly you have to answer this by doing a lot of experimentation and testing you might have to train networks before you find the optimal structure and parameters for the problem you are solving machine learning involves a lot of trial and error
now finally we know enough to write a program that can decide if a picture is a bird or not
as always we need some data to get started the free cifar data set contains pictures of birds and pictures of things that are not birds but to get even more data we ll also add in the caltech ucsd birds data set that has another bird pics
here s a few of the birds from our combined data set
and here s some of the non bird images
this data set will work fine for our purposes but low res images is still pretty small for real world applications if you want google level performance you need millions of large images in machine learning having more data is almost always more important that having better algorithms now you know why google is so happy to offer you unlimited photo storage they want your sweet sweet data
to build our classifier we ll use tflearn tflearn is a wrapper around google s tensorflow deep learning library that exposes a simplified api it makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network
here s the code to define and train the network
if you are training with a good video card with enough ram like an nvidia geforce gtx ti or better this will be done in less than an hour if you are training with a normal cpu it might take a lot longer
as it trains the accuracy will increase after the first pass i got accuracy after just passes it was already up to after or so passes it capped out around accuracy and additional training didn t help so i stopped it there
congrats our program can now recognize birds in images
now that we have a trained neural network we can use it here s a simple script that takes in a single image file and predicts if it is a bird or not
but to really see how effective our network is we need to test it with lots of images the data set i created held back images for validation when i ran those images through the network it predicted the correct answer of the time
that seems pretty good right well it depends
our network claims to be accurate but the devil is in the details that could mean all sorts of different things
for example what if of our training images were birds and the other were not birds a program that guessed not a bird every single time would be accurate but it would also be useless
we need to look more closely at the numbers than just the overall accuracy to judge how good a classification system really is we need to look closely at how it failed not just the percentage of the time that it failed
instead of thinking about our predictions as right and wrong let s break them down into four separate categories
using our validation set of images here s how many times our predictions fell into each category
why do we break our results down like this because not all mistakes are created equal
imagine if we were writing a program to detect cancer from an mri image if we were detecting cancer we d rather have false positives than false negatives false negatives would be the worse possible case that s when the program told someone they definitely didn t have cancer but they actually did
instead of just looking at overall accuracy we calculate precision and recall metrics precision and recall metrics give us a clearer picture of how well we did
this tells us that of the time we guessed bird we were right but it also tells us that we only found of the actual birds in the data set in other words we might not find every bird but we are pretty sure about it when we do find one
now that you know the basics of deep convolutional networks you can try out some of the examples that come with tflearn to get your hands dirty with different neural network architectures it even comes with built in data sets so you don t even have to find your own images
you also know enough now to start branching and learning about other areas of machine learning why not learn how to use algorithms to train computers how to play atari games next
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part part and part
interested in computers and machine learning likes to write about it
update this article is part of a series check out the full series part part part part part part part and part you can also read this article in ti ng vi t or
giant update i ve written a new book based on these articles it not only expands and updates all my articles but it has tons of brand new content and lots of hands on coding projects check it out now
speech recognition is invading our lives it s built into our phones our game consoles and our smart watches it s even automating our homes for just you can get an amazon echo dot a magic box that allows you to order pizza get a weather report or even buy trash bags just by speaking out loud
the echo dot has been so popular this holiday season that amazon can t seem to keep them in stock
but speech recognition has been around for decades so why is it just now hitting the mainstream the reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments
andrew ng has long predicted that as speech recognition goes from accurate to accurate it will become a primary way that we interact with computers the idea is that this accuracy gap is the difference between annoyingly unreliable and incredibly useful thanks to deep learning we re finally cresting that peak
let s learn how to do speech recognition with deep learning
if you know how neural machine translation works you might guess that we could simply feed sound recordings into a neural network and train it to produce text
that s the holy grail of speech recognition with deep learning but we aren t quite there yet at least at the time that i wrote this i bet that we will be in a couple of years
the big problem is that speech varies in speed one person might say hello very quickly and another person might say heeeelllllllllllllooooo very slowly producing a much longer sound file with much more data both both sound files should be recognized as exactly the same text hello automatically aligning audio files of various lengths to a fixed length piece of text turns out to be pretty hard
to work around this we have to use some special tricks and extra precessing in addition to a deep neural network let s see how it works
the first step in speech recognition is obvious we need to feed sound waves into a computer
in part we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition
but sound is transmitted as waves how do we turn sound waves into numbers let s use this sound clip of me saying hello
sound waves are one dimensional at every moment in time they have a single value based on the height of the wave let s zoom in on one tiny part of the sound wave and take a look
to turn this sound wave into numbers we just record of the height of the wave at equally spaced points
this is called sampling we are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time that s basically all an uncompressed wav audio file is
cd quality audio is sampled at khz readings per second but for speech recognition a sampling rate of khz samples per second is enough to cover the frequency range of human speech
lets sample our hello sound wave times per second here s the first samples
you might be thinking that sampling is only creating a rough approximation of the original sound wave because it s only taking occasional readings there s gaps in between our readings so we must be losing data right
but thanks to the nyquist theorem we know that we can use math to perfectly reconstruct the original sound wave from the spaced out samples as long as we sample at least twice as fast as the highest frequency we want to record
i mention this only because nearly everyone gets this wrong and assumes that using higher sampling rates always leads to better audio quality it doesn t
lt end rant gt
we now have an array of numbers with each number representing the sound wave s amplitude at th of a second intervals
we could feed these numbers right into a neural network but trying to recognize speech patterns by processing these samples directly is difficult instead we can make the problem easier by doing some pre processing on the audio data
let s start by grouping our sampled audio into millisecond long chunks here s our first milliseconds of audio i e our first samples
plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that millisecond period of time
this recording is only th of a second long but even this short recording is a complex mish mash of different frequencies of sound there s some low sounds some mid range sounds and even some high pitched sounds sprinkled in but taken all together these different frequencies mix together to make up the complex sound of human speech
to make this data easier for a neural network to process we are going to break apart this complex sound wave into it s component parts we ll break out the low pitched parts the next lowest pitched parts and so on then by adding up how much energy is in each of those frequency bands from low to high we create a fingerprint of sorts for this audio snippet
imagine you had a recording of someone playing a c major chord on a piano that sound is the combination of three musical notes c e and g all mixed together into one complex sound we want to break apart that complex sound into the individual notes to discover that they were c e and g this is the exact same idea
we do this using a mathematic operation called a fourier transform it breaks apart the complex sound wave into the simple sound waves that make it up once we have those individual sound waves we add up how much energy is contained in each one
the end result is a score of how important each frequency range is from low pitch i e bass notes to high pitch each number below represents how much energy was in each hz band of our millisecond audio clip
but this is a lot easier to see when you draw this as a chart
if we repeat this process on every millisecond chunk of audio we end up with a spectrogram each column from left to right is one ms chunk
a spectrogram is cool because you can actually see musical notes and other pitch patterns in audio data a neural network can find patterns in this kind of data more easily than raw sound waves so this is the data representation we ll actually feed into our neural network
now that we have our audio in a format that s easy to process we will feed it into a deep neural network the input to the neural network will be millisecond audio chunks for each little audio slice it will try to figure out the letter that corresponds the sound currently being spoken
we ll use a recurrent neural network that is a neural network that has a memory that influences future predictions that s because each letter it predicts should affect the likelihood of the next letter it will predict too for example if we have said hel so far it s very likely we will say lo next to finish out the word hello it s much less likely that we will say something unpronounceable next like xyz so having that memory of previous predictions helps the neural network make more accurate predictions going forward
after we run our entire audio clip through the neural network one chunk at a time we ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk here s what that mapping looks like for me saying hello
our neural net is predicting that one likely thing i said was hhhee ll lllooo but it also thinks that it was possible that i said hhhuu ll lllooo or even aaauu ll lllooo
we have some steps we follow to clean up this output first we ll replace any repeated characters a single character
then we ll remove any blanks
that leaves us with three possible transcriptions hello hullo and aullo if you say them out loud all of these sound similar to hello because it s predicting one character at a time the neural network will come up with these very sounded out transcriptions for example if you say he would not go it might give one possible transcription as he wud net go
the trick is to combine these pronunciation based predictions with likelihood scores based on large database of written text books news articles etc you throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic
of our possible transcriptions hello hullo and aullo obviously hello will appear more frequently in a database of text not to mention in our original audio based training data and thus is probably correct so we ll pick hello as our final transcription instead of the others done
you might be thinking but what if someone says hullo it s a valid word maybe hello is the wrong transcription
of course it is possible that someone actually said hullo instead of hello but a speech recognition system like this trained on american english will basically never produce hullo as the transcription it s just such an unlikely thing for a user to say compared to hello that it will always think you are saying hello no matter how much you emphasize the u sound
try it out if your phone is set to american english try to get your phone s digital assistant to recognize the world hullo you can t it refuses it will always understand it as hello
not recognizing hullo is a reasonable behavior but sometimes you ll find annoying cases where your phone just refuses to understand something valid you are saying that s why these speech recognition models are always being retrained with more data to fix these edge cases
one of the coolest things about machine learning is how simple it sometimes seems you get a bunch of data feed it into a machine learning algorithm and then magically you have a world class ai system running on your gaming laptop s video card right
that sort of true in some cases but not for speech recognizing speech is a hard problem you have to overcome almost limitless challenges bad quality microphones background noise reverb and echo accent variations and on and on all of these issues need to be present in your training data to make sure the neural network can deal with them
here s another example did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise humans have no problem understanding you either way but neural networks need to be trained to handle this special case so you need training data with people yelling over noise
to build a voice recognition system that performs on the level of siri google now or alexa you will need a lot of training data far more data than you can likely get without hiring hundreds of people to record it for you and since users have low tolerance for poor quality voice recognition systems you can t skimp on this no one wants a voice recognition system that works of the time
for a company like google or amazon hundreds of thousands of hours of spoken audio recorded in real life situations is gold that s the single biggest thing that separates their world class speech recognition system from your hobby system the whole point of putting google now and siri on every cell phone for free or selling alexa units that have no subscription fee is to get you to use them as much as possible every single thing you say into one of these systems is recorded forever and used as training data for future versions of speech recognition algorithms that s the whole game
don t believe me if you have an android phone with google now click here to listen to actual recordings of yourself saying every dumb thing you ve ever said into it
so if you are looking for a start up idea i wouldn t recommend trying to build your own speech recognition system to compete with google instead figure out a way to get people to give you recordings of themselves talking for hours the data can be your product instead
if you liked this article please consider signing up for my machine learning is fun email list i ll only email you when i have something new and awesome to share it s the best way to find out when i write more articles like this
you can also follow me on twitter at ageitgey email me directly or find me on linkedin i d love to hear from you if i can help you or your team with machine learning
now continue on to machine learning is fun part
interested in computers and machine learning likes to write about it
last updated dec
latest video update
okay on to the post
i kicked off this year with udacity s deep learning nanodegree and got a fantastic comprehensive introduction to deep learning while i was taking the class i discovered daniel bourke s self created ai masters degree which details the courses he s taking on his path to becoming a deep learning developer one of which was the deep learning nanodegree i thought the idea to share his journey was brilliant it holds him accountable and provides inspiration for others
rather than take the same path as him i ve decided to create my own course that pairs my long standing interest in game development and d modeling with my newly found interest in artificial intelligence if this branch of ai interests you too i hope my path can inspire you to create your own self driven education
this post will be a work in progress toward understanding how d tools like unity unreal engine and blender can be used to train deep neural networks i came into this course with a unique combo of skills so i ll offer some suggestions for anyone who wants to follow along but doesn t have the same foundation
if as kai fu lee says data is the most important thing we need a lot of it currently most image and video datasets are annotated by hand this process is tedious expensive in large quantities and error prone the most promising alternative is something i ve blogged about synthetic datasets for training ai put simply we can create training data from d simulations
game engines like unreal engine and unity are amazing tools for creating lifelike simulations of the real world as opposed to the real world they can allow neural networks to learn in cheap safe controllable repeatable environments with infinite situations impressive graphics and realistic physics
autonomous cars are a great example if a car crashes during training it costs time money and potentially human lives even if crashes are avoided by human intervention it s not possible to practice dangerous situations in a safe way for humans inside or outside of the vehicle if a car crashes in simulation it can either start over or learn to safely pull the car off to the side of the road it can also practice as many times as it needs to not surprisingly the big players in autonomous vehicles tesla gm etc are hiring game engine developers to build realistic training simulations
the carla simulator built on unreal engine is a great example of how a game engine can be used to teach cars to drive check out the video
in addition to autonomous vehicles game engines are being used to train robots and drones check out this video of microsoft airsim which can simulate drone flight in unreal engine
i imagine in the near future we will also see game engine applications in lifelike human simulation for digital assistants movies and video games d reconstructions of real places augmented reality and mixed reality intelligent adversaries in video games and lots of other places
personally i think the intersection of game engines and deep learning is going to be massive these skills will be extremely valuable so i m trying to dive in early it s also a ton of fun and very satisfying to build interactive virtual worlds with game engines have i sold you on this yet join me and let me know how your learning is progressing
i live in austin texas with my wife i enjoy eating mexican food and drinking tequila with friends i love video games fantasy novels board games electronic dance music and hot sunny weather
professionally i m a software engineer working primarily in ai and vr cs degree from michigan formerly worked at microsoft currently work at gm if you want more detail check out my linkedin
i ve found that throughout life the times when i m happiest are when i m deliberately voraciously learning something new that i can do with my computer i discovered as a teenager that i could learn without any formal instruction with a combination of free tutorials and self directed projects at the time i just wanted to make trance music with fl studio to become a famous dj and later wanted to make d models with ds max and become a pixar animator i m glad i went with computer science instead the power of creation it affords is about as close to being a wizard that humans can get i did mention i like fantasy novels
starting in i used the same tutorials projects approach to learn vr development in unity and then at the beginning of i set out to do the same thing with deep learning
below are the courses i ve taken or plan to take i ll update the list with progress and new additions as i go
note i already knew a lot before starting this course some from college some from my job some from personal interest i was very capable in unity c and blender and had strong debugging and problem solving skills from years of programming see the suggested curriculum for beginners section below for my recommendations if you aren t coming in with some or all of these skills
completed udacity deep learning nanodegree this course was incredible i ve not seen another course that surpasses it in depth and breadth compare the syllabus to anything out there and you ll see what i mean i was fortunate that my company paid for this because it was relevant to my job this course was my first intro to python programming fortunately since i am an experienced developer i was able to pick it up as i went along but if you are new to development i d strongly suggest you take a python course first
started freecodecamp deep reinforcement learning course free this free course looks really cool you train deep reinforcement learning algorithms to play old school video games
openai spinning up free this looks like a really deep comprehensive overview of reinforcement learning it also looks to be a great intro to openai gym which is one of the projects i wanted to work on
completed udemy unreal engine c developer course this course did a good job of introducing me to unreal it s a bit messy in places but overall it covers so much so thoroughly that it s easy to recommend
completed pluralsight learn how to program with c started pluralsight c fundamentals including c i was pretty rusty on c though i did learn it in college these courses helped refresh me on the basics and get me up to speed on the more modern changes that happened to the language since i graduated c is the language used by unreal engine so i wanted to have a strong foundation
completed ros robot operating system tutorials free i learned ros for a project at work but it s certainly relevant here robotics is already using d simulation for training purposes in particular with gazebo it s a natural progression to use high powered game engines like unreal engine and unity for training as these robots use more powerful computer vision
started hard surface modeling in blender i started this fast paced advanced course more for fun than necessity but i think it will really boost my d modeling skills i spent a lot of time learning the basics of blender on youtube years ago before diving into this one
khan academy math free my wife is currently learning to program for the first time she quickly realized that her math skills were pretty rusty and that it was making the python course she was taking extra difficult khan academy has been a big help
udemy modern python bootcamp this is the intro programming class my wife is taking i picked it out because i liked the instructor and the syllabus
microsoft virtual academy c fundamentals for absolute beginners free microsoft virtual academy programming in c jump start free these free courses appear to be a good intro to c which essential for unity i d recommend you get comfortable with it so that you can write quality code
udemy complete c unity developer d course i started learning unity from a book that s out of date now and youtube tutorials but this looks like a good intro course to get you up and running
blenderguru blender beginning tutorial series free blenderguru intermediate blender tutorial series free i ve been playing around with blender for d modeling for a couple years and i find it s almost as good as the applications that cost thousands of dollars but is completely open source and free if you are new to d modeling there s a wealth of free material out there to learn on youtube the links above are from andrew price aka blenderguru i think he does a great job and am a big fan of his tutorials
nothing beats practice to help solidify knowledge stretch you beyond the learning material and build confidence projects are a critical part of learning anything new and i intend to spend the majority of my time on them also by sharing projects publicly you can prove that you know what you re doing a hell of a lot better than most certificates
as part of my projects i like to create tutorials for other people to follow in my footsteps i believe teaching what i ve learned really helps me lock in what i ve learned you can see what i ve shared on the tutorials section of my website immersive limit all tutorials
i trained a mask r cnn on a custom synthetic image dataset of cigarette butts this didn t use any game engines but it was a good intro to cutting edge image segmentation neural networks it s not super practical to run these neural nets alongside game engines right now because of the sheer amount of graphics compute required but i think we ll see a lot more of it in the coming years i initially planned on using blender to generate cigarette butt renders but ended up using python instead
unity has released an open source project called ml agents which is a framework for training machine learning agents or characters to navigate simple d worlds with neural networks i m currently working on training a pig agent to find truffles with stereo smell watching pigs spin and slide around has been pretty funny
there are some interesting examples of training image detection neural networks on rendered images for example several research groups have used grand theft auto to create training images i d like to create my own system to do this
similar to the project above but with imagery being processed in real time
microsoft open sourced a project called airsim for training drones to fly and cars to drive with unreal engine they have created several realistic environments for training and it even interfaces with flight controllers i ve fired it up to play with it but haven t actually extended it with my own code yet
openai has created openai gym for training reinforcement learning algorithms and neural nets i ve had a little bit of exposure through the udacity deep learning nanodegree but i want to explore it further
opencv continues to be the go to framework for computer vision especially on robots much of the library doesn t actually use deep learning but it does have support for it i ve used it a bit and seen some neat projects done with it i think that combining it with game engines would be a great experiment
another important aspect of becoming an expert in deep learning is getting involved with the community and meeting like minds i ve attended a couple local austin ai meetups joined some ai facebook groups and done a bit of reaching out through linkedin but this is an area i need to put more effort into
i probably need to tweet more
do you know of any great communities where people discuss deep learning let me know
this self driven deep learning in game engines course is a work in progress and i hope it s helpful for others who want to go down a similar learning path if you find any courses that you think i d like have other suggestions or are just excited to follow along please let me know you can reach out to me at aktwelve twitter or connect with me on linkedin
for future updates like the immersive limit facebook page subscribe to the immersive limit youtube channel follow the immersive limit twitter
originally published at www immersivelimit com
software engineer working in vr ar and ai at gm fascinated by the implications of new technology opinions expressed are my own
this post covers the second and final day of the deep learning summit that took place in london on september th th you can find the first post here videos are also being posted on youtube
after a welcome from alison lowndes of nvdia the day started with the startup session
first up were wally trenholm founder amp ceo and jason cassidy md amp chief science officer of sightline innovation talking about the commercialisation of deep learning they started going after military customers then looked for other markets due to long military order process year to order they first took what had been developed in image analysis on geo scale satellite uav and applied it to agriculture then to serve even more customers they went from geo scale to macro scale images addressing industrial problems automated manufacturing quality control next they will go further down and apply their image analysis to nano scale genomic there is a mlaas machine learning as a service term for which they hold the copyright platform which will be released next month with a server on site to collect and preprocess the data and also provide reporting and dashboards while algorithm training and prediction will be done on their cloud in case you are looking clarify is hiring
next up was paul murphy ceo of clarify on deep learning amp speech adaptation the next frontier with some funny cartoonish slides clarify started in london and now texas based provides an api that analyses audio and video making it searchable the main issue with speech is adaptation as also discussed by s bastien brati res in the last session of the first summit day there are different adaptation problems like speaker adaptation ex accents speaker may not be native while most of the training data is native and male noise and tenuation moving away from the microphone the bleeding edge in speech recognition research is
then came appu shaji head of r amp d at eyeem talking about deep learning for real photography eyeem is a social network for photography one of the goals appu is to improve content discovery helping photographers being found and selling more photos he showed eyevision which is currently in early access the engine assesses aesthetic quality of the photo and also tags them with k concepts using data coming from both community and expertly curated tagging they are using cnns with word embeddings based on these research papers paper paper paper
john overington director of bioinformatics at stratified medical followed with artificial intelligence in drug discovery john said that currently drug discovery is extremely expensive and unpredictable r amp d expenses for a single approved drug range from billion to billion source he brought his experience on drug discovery to stratified medical which is developing their own drug pipeline the goal is to use ai to filter down potential molecules accelerating discovery and reducing costs they are building a knowledge graph using data from structured sources molecule databases vocabularies and unstructured data papers patents etc the latter being extracted with nlp techniques they will also leverage new public datasets such as uk k the genome sequencing data of k people which will help uncover rare variants contributing to diseases they are making progress they achieved key milestones in a multimillion partnered alzheimer s program
the last talk of the startup session was given by marius cobzarenco co founder amp cto of re infer on building conversational interfaces with deep nets marisu said they are building business bots that collect data from different systems slack crm wiki etc and are able to answer natural queries currently it is hard to understand intent and context there is active research on embeddings done for example by geoff hinton on deep thoughts at google they are using cnns to find embeddings they found this dnns to be faster to train compared to rnns and at the same time gives good results they also use dl for named entity recognition you still need to extract entities to translate the intent into actions
the second part of the morning was on deep learning applications
david plans ceo and davide morelli cto of biobeats talked about machine intelligence for the essential self their initial work was on neural networks in creativity releasing an app called pulse that generates music based on the heartbeat with the pulse app they collected a large cardiovascular dataset enhanced by information coming from sensor data accelerometer gps gyro etc now they pivoted and use this information to train models for people wellness david who also gave a terrific talk during the summit dinner the night before said we are constantly under stress as a result we live in sympathetic mode fight or flight with our body acting as if we were in a jungle facing a lion in the long run it damages our health and may result in premature death but with interventions we can be brought back to living in the much saner parasympathetic mode feed and rest couple this with the fact that of company healthcare spending is on preventable chronic diseases they are bringing their system inside organisations collaborating with bupa axa and samsung to predict employee stress and fatigue levels and take action before it is too late they also have a couple of public apps in beta testing
in the last part of the speech davide talked about their technology where there are several challenges like understanding if the stress is good eg you re happy or bad there are some indicators for example under bad stress the heartbeat becomes more regular plus heartbeat information can be correlated with activity ex you are not moving and the heartbeat suddenly becomes regular and info coming from social networks to label datasets on top of that they need to manage large datasets each user generates mb day without killing batteries and exhausting user data plans their solution is to extract features locally send them to the server where models are trained then send back the trained model and make predictions on the device the api sdk will be released by end of the year they concluded saying that the most important open challenges are ethical on bringing emotional intelligence to the algorithms so that interventions are beneficial for the user receiving them and don t cause additional stress
i then attended the parallel session on investing in ai it started with a panel made of vcs nathan benaich of playfair capital john henderson of white star capital simon king of octopus investments together with alex dalyac co founder amp ceo of tractable and moderated by sally davies of financial times most of the discussion has been on how to evaluate an ai startup here are some aspects being considered
they agreed that the acquisition of deepmind by google is a very important signal for europe before us companies tended to buy only us startups this opens new exit possibilities for european startups making them more attractive to vcs
after a very good lunch break the afternoon started with alex matei mhealth manager and ekaterina volkova volkmar researcher of bupa on deep learning for digital health bupa is an international healthcare group whose activity span from hospitals to company health insurance they showed an interesting series of proof of concept
i really appreciated their approach using available software api for fast prototype development they also showed some good practices like defining at the start of each project the evaluation criteria for deciding which software api to use example criteria what is the software api potential to scale how does the costs grow in case of large deployments
rodolfo rosini cto of weave ai came after the presentation was not very informative they seem to be in stealth mode their idea is to use contextual information to provide improved search he also talked about aggregating corporate information and making it easily searchable something similar to what re infer was talking about in the morning
joerg bornschein global scholar at cifar followed with a talk on combining directed amp undirected generative models joerg talk was about unsupervised learning where the progress has not been as impressive as in supervised learning and there are yet less real world application nevertheless it might help us to understand how the brain works and it will enable new applications where machines generate content joerg presented his work on training bidirectional helmholtz machines paper helmholtz machines hms are made of a generative model coupled with an auxiliary model which performs approximate inference joerg presented a new way to train the hms where probabilities of both models are interpreted as approximate inference distributions and the goal is to minimise the difference between the distributions he showed some examples of the algorithms in action where they reconstruct digits and faces with missing parts
the last talk of the summit was given by marie francine moens professor at ku leuven on learning representations for language understanding experiences from the muse project muse which stands for machine understanding for interactive storytelling is working on algorithms that translate text into virtual worlds applications include rendering children s stories and providing patient guidelines ex foreigners in a hospital as d virtual worlds the algorithms play a double role
the main difficulties come from having very few annotated training datasets for which they are researching into using other data sources like language models to improve results there is also a lack of world knowledge ex practice with a spear gt the spear is held in the hand so they are working on multimodal deep learning using both images and phrases to acquire more knowledge
that concluded the deep learning summit london the organisation by the re work team nikita pip sophie was great the summit had a positive mix of industry and research talk and it was a terrific opportunity to network and get to know lots of interesting people in the deep learning field coming up are the san francisco summit and then europe again highly recommended
ceo and chief data scientist at optimist ai bringing innovation to sales through big data the future is bright
a non technical guide for how to brainstorm potential ml use cases in your business recommended read for experienced new or hopeful product managers data scientists and entrepreneurs looking to integrate ai ml into their business
i hear the following question several times a week
i want to use ml in my business where should i use it
companies are changing the way they do business because of machine learning this evolution comes with a lot of excitement but also some anxiety about potentially falling behind
whether or not you re supposed to be the one figuring this out it can be stressful to think about where you and your company fit in to this changing landscape
a bit about me my name is allie miller and i am a lead product manager at ibm watson i have worked in three of the most critical areas of artificial intelligence conversation computer vision and data and what gets me out of bed in the morning the scale impact and humanization of artificial intelligence
and basset hounds
i have now worked with over clients in artificial intelligence and while each industry and vertical presents its own special flavor of considerations and challenges there are a few persisting themes that together form the five levels of machine learning use cases
each level builds on the last but before we start climbin
no matter what you build no matter how much funding you have no matter what industry you re in you must talk to your end users
understanding your users will illuminate paths to success everything from what data you should analyze to where biases might creep in
always start with empathy always have communication lines open with your users
do not even continue reading until you have committed to this
ok ready back to the ladder
also known as tell me what this thing is
examples
identification is the foundation of machine learning use cases it tends to be most helpful in workflow routing auto tagging and trend analysis use cases knowing what something is is the first step in deciding what to do with it
identification is also generally not a binary result machine learning will not just tell you whether a not or photo contains a dog it will tell you how likely it is that the photo contains a dog this is referred to as a confidence score
different use cases call for different confidence level thresholds
for example if you are creating a stock photo site and want to use ml to identify if a sidewalk is present in a photo you might require a minimum of accuracy the consequence of a false positive saying a sidewalk is there when it isn t or false negative saying a sidewalk isn t there when it is is fairly low but if you re building a self driving car and want to identify if a sidewalk is present accuracy is far too low
also known as group these similar things
examples
really this is just combining multiple classifications and making them relate to each other all of the classes or tags like dog vs cat are trained in a group rather than in individual models so the system can better learn the relationship similarities and differences between a dog and b cat
also known as tell me whether i should care about this thing
examples
now we start to add contextual clues clues specific to that specific company or time or geography we re not just labeling one aspect of one feature we re generating a sense of urgency ranking and prioritization
also known as tell me what to do about this thing
examples
at level we begin to incorporate ai ml outputs into business workflows the system has returned some sort of output this bank transaction is likely to be fraudulent but deciding what to do with that output is where it gets really valuable cover up to in fraudulent charges
there are multiple ways to handle the triage if it s an urgent customer email you can automatically reply with a direct customer support line if it s a retail store emergency you can send alerts to all nearby security guards if it s a fraudulent bank transaction you can send it to a banking expert to manually review it
deciding what to do with the output is up to you and your company but automating the assess and recommend portion of your workflow will allow you to triage not only more quickly but also with greater accuracy
also known as will this thing happen
examples
prediction is the golden ticket of artificial intelligence the holy grail and i sometimes to refer to this as the last column problem
picture a spreadsheet with structured and unstructured data sources functioning as each column
if you re a retail company you may have a customer s name age gender email address emails to the company in store shopping behavior previous items viewed and previous items purchased if you re in agriculture maybe you have a farm s location farm size local weather patterns predicted weather pesticide levels competitor farms performance watering schedules and satellite images of the farms
in each case you want to analyze all of the factors e g age farm size satellite images customer emails to best predict the last column of your spreadsheet
something like knowing everything you know about this customer will they buy during our holiday sale or knowing everything you know about this farm will it produce enough corn this year
if you can predict costly or destructive events before they happen you can have a huge impact on your company and users applying machine learning to your business can cut costs allow you to redirect your company s resources toward areas of greatest impact and most importantly improve the livelihood of others
these five levels have served me and my clients well across a variety of projects and applications from labeling dog photos to predicting train track malfunctions these are core building blocks to ml use cases and i hope you find them valuable
regardless of your familiarity with machine learning or the size and complexity of the solution you and your business go after remember always start small and iterate
comment below and let me know what ml use cases you re working on
lead product manager ibm watson proud wharton stanford and dartmouth alum champion axe thrower
artificial intelligence has been brain dead since the s this rather ostentatious remark made by marvin minsky co founder of the world famous mit artificial intelligence laboratory was referring to the fact that researchers have been primarily concerned on small facets of machine intelligence as opposed to looking at the problem as a whole this article examines the contemporary issues of artificial intelligence ai looking at the current status of the ai field together with potent arguments provided by leading experts to illustrate whether ai is an impossible concept to obtain
because of the scope and ambition artificial intelligence defies simple definition initially ai was defined as the science of making machines do things that would require intelligence if done by men this somewhat meaningless definition shows how ai is still a young discipline and similar early definitions have been shaped by technological and theoretical progress made in the subject so for the time being a good general definition that illustrates the future challenges in the ai field was made by the american association for artificial intelligence aaai clarifying that ai is the scientific understanding of the mechanisms underlying thought and intelligent behaviour and their embodiment in machines
the term artificial intelligence was first coined by john mccarthy at a conference at dartmouth college new hampshire in but the concept of machine intelligence is in fact much older in ancient greek mythology the smith god hephaestus is credited with making talos a bull headed bronze man who guarded crete for king minos by patrolling the island terrifying off impostors similarly in the th century mechanical talking heads were said to have been created to scare intruders with albert the great and roger bacon reputedly among the owners however it is only in the last years that ai has really begun to pervade popular culture our fascination with thinking machines is obvious but has been wrongfully distorted by the science fiction connotations seen in literature film and television
in reality the ai field is far from creating the sentient beings seen in the media yet this does not imply that successful progress has not been made ai has been a rich branch of research for years and many famed theorists have contributed to the field but one computer pioneer that has shared his thoughts at the beginning and still remains timely in both his assessment and arguments is british mathematician alan turing in the s turing published a paper called computing machinery and intelligence in which he proposed an empirical test that identifies an intelligent behaviour when there is no discernible difference between the conversation generated by the machine and that of an intelligent person the turing test measures the performance of an allegedly intelligent machine against that of a human being and is arguably one of the best evaluation experiments at this present time the turing test also referred to as the imitation game is carried out by having a knowledgeable human interrogator engage in a natural language conversation with two other participants one a human the other the intelligent machine communicating entirely with textual messages if the judge cannot reliably identify which is which it is said that the machine has passed and is therefore intelligent although the test has a number of justifiable criticisms such as not being able to test perceptual skills or manual dexterity it is a great accomplishment that the machine can converse like a human and can cause a human to subjectively evaluate it as humanly intelligent by conversation alone
many theorist have disputed the turing test as an acceptable means of proving artificial intelligence an argument posed by professor jefferson lister states not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt and not by the chance fall of symbols could we agree that machine equals brain turing replied by saying that we have no way of knowing that any individual other than ourselves experiences emotions and that therefore we should accept the test however lister did have a valid point to make developing an artificial consciousness intelligent machines already exist that are autonomous they can learn communicate and teach each other but creating an artificial intuition a consciousness is the holy grail of artificial intelligence when modelling ai on the human mind many illogical paradoxes surface and you begin to see how the complexity of the brain has been underestimated and why simulating it has not be as straightforward as experts believed in the s the problem with human beings is that they are not algorithmic creatures they prefer to use heuristic shortcuts and analogies to situations well known however this is a psychological implication it is not that people are smarter then explicit algorithms but that they are sloppy and yet do well in most cases
the phenomenon of consciousness has caught the attention of many philosophers and scientists throughout history and innumerable papers and books have been published devoted to the subject however no other biological singularity has remained so resistant to scientific evidence and persistently ensnarled in fundamental philosophical and semantic tangles under ordinary circumstances we have little difficulty in determining when other people lose or regain consciousness and as long as we avoid describing it the phenomenon remains intuitively clear most computer scientists believe that the consciousness was an evolutionary add on and can therefore be algorithmically modelled yet many recent claims oppose this theory sir roger penrose an english mathematical physicist argues that the rational processes of the human mind are not completely algorithmic and thus transcends computation and professor stuart hameroff s proposal that consciousness emerges as a macroscopic quantum state from a critical level of coherence of quantum level events in and around cytoskeletal microtubules within neurons although these are all theories with not much or no empirical evidence it is still important to consider each of them because it is vital that we understand the human mind before we can duplicate it
another key problem with duplicating the human mind is how to incorporate the various transitional states of consciousness such as rem sleep hypnosis drug influence and some psychopathological states within a new paradigm if these states are removed from the design due to their complexity or irrelevancy in a computer then it should be pointed out that perhaps consciousness cannot be artificially imitated because these altered states have a biophysical significance for the functionality of the mind
if consciousness is not algorithmic then how is it created obviously we do not know scientists who are interested in subjective awareness study the objective facts of neurology and behaviour and have shed new light on how our nervous system processes and discriminates among stimuli but although such sensory mechanisms are necessary for consciousness it does not help to unlock the secrets of the cognitive mind as we can perceive things and respond to them without being aware of them a prime example of this is sleepwalking when sleepwalking occurs sleepwalking comprises approximately percent of all children and percent of adults many of the victims carry out dangerous or stupid tasks yet some individuals carry out complicated distinctively human like tasks such as driving a car one may dispute whether sleepwalkers are really unconscious or not but if it is in fact true that the individuals have no awareness or recollection of what happened during their sleepwalking episode then perhaps here is the key to the cognitive mind sleepwalking suggests at least two general behavioural deficiencies associated with the absence of consciousness in humans the first is a deficiency in social skills sleepwalkers typically ignore the people they encounter and the rare interactions that occur are perfunctory and clumsy or even violent the other major deficit in sleepwalking behaviour is linguistics most sleepwalkers respond to verbal stimuli with only grunts or monosyllables or make no response at all these two apparent deficiencies may be significant sleepwalkers luse of protolanguage short grammar free utterances with referential meaning but lack syntax may illustrate that the consciousness is a social adaptation and that other animals do not lack understanding or sensation but that they lack language skills and therefore cannot reflect on their sensations and become self aware in principle francis crick co discover of double helix dna structure believed this hypotheses after he and james watson solved the mechanism of inheritance crick moved to neuroscience and spent the rest of his trying to answer the biggest biological question what is the consciousness working closely with christof koch he published his final paper in the philosophical transactions of the royal society of london and in it he proposed that an obscure part of the brain the claustrum acts like a conductor of an orchestra and binds vision olfaction somatic sensation together with the amygdala and other neuronal processing for the unification of thought and emotion and the fact that all mammals have a claustrum means that it is possible that other animals have high intelligence
so how different are the minds of animals in comparison to our own can their minds be algorithmically simulated many scientists are reluctant to discuss animal intelligence as it is not an observable property and nothing can be perceived without reason and therefore there is not much published research on the matter but by avoiding the comparison of some human mental states to other animals we are impeding the use of a comparative method that may unravel the secrets of the cognitive mind however primates and cetacean have been considered by some to be extremely intelligent creatures second only to humans their exalted status in the animal kingdom has lead to their involvement in almost all of published experiments related to animal intelligence these experiments coupled with analysis of primate and cetacean s brain structure has lead to many theories as to the development of higher intelligence as a trait although these theories seem to be plausible there is some controversy over the degree to which non human studies can be used to infer about the structure of human intelligence
by many of the physical methods of comparing intelligence such as measuring the brain size to body size ratio cetacean surpass non human primates and even rival human beings for example dolphins have a cerebral cortex which is about larger a human being their cortex is also stratified in much the same way as humans the frontal lobe of dolphins is also developed to a level comparable to humans in addition the parietal lobe of dolphins which makes sense of the senses is larger than the human parietal and frontal lobes combined the similarities do not end there most cetaceans have large and well developed temporal lobes which contain sections equivalent to broca s and wernicke s areas in humans
dolphins exhibit complex behaviours they have a social hierarchy they demonstrate the ability to learn complex tricks when scavenging for food on the sea floor some dolphins have been seen tearing off pieces of sponge and wrapping them around their bottle nose to prevent abrasions illustrating yet another complex cognitive process thought to be limited to the great apes they apparently communicate by emitting two very distinct kinds of acoustic signals which we call whistles and clicks and lastly dolphins do not use sex purely for procreative purposes some dolphins have been recorded having homosexual sex which demonstrates that they must have some consciousness dolphins have a different brain structure then humans that could perhaps be algorithmic simulated one example of their dissimilar brain structure and intelligence is their sleep technique while most mammals and birds show signs of rapid rem rapid eye movement sleep reptiles and cold blooded animals do not rem sleep stimulates the brain regions used in learning and is often associated with dreaming the fact that cold blooded animals do not have rem sleep could be enough evidence to suggest that they are not conscious and therefore their brains can definitely be emulated furthermore warm blood creatures display signs of rem sleep and thus dream and therefore must have some environmental awareness however dolphins sleep unihemispherically they are conscious breathers and if fall asleep they could drown evolution has solved this problem by letting one half of its brain sleep at a time as dolphins utilise this technique they lack rem sleep and therefore a high intelligence perhaps consciousness is possible that does not incorporate the transitional states mentioned earlier
the evidence for animal consciousness is indirect but so is the evidence for the big bang neutrinos or human evolution as in any event such unusual assertions must be subject to rigorous scientific procedure before they can be accepted as even vague possibilities intriguing but more proof is required however merely because we do not understand something does not mean that it is false or not studying other animal minds is a useful comparative method and could even lead to the creation of artificial intelligence that does not include irrelevant transitional states for an artificial entity based on a model not as complex as our own still the central point being illustrated is how ignorant our understanding of the human brain or any other brain is and how one day a concrete theory can change thanks to enlightening findings
furthermore an analogous incident that exemplifies this argument happened in when an irish workman phineas cage shed new light on the field of neuroscience when a rock blasting accident sent an iron rod through the frontal region of his brain miraculously enough he survived the incident but even more astonishing to the science community at the time were the marked changes in cage s personality after the rode punctured his brain where before cage was characterized by his mild mannered nature he had now become aggressive rude and indulging in the grossest profanity which was not previously his custom manifesting but little deference for his fellows impatient of restraint or advice when it conflicts with his desires according to the boston physician harlow in however cage sustained no impairment with regards to his intelligence or memory
the serendipity of the phineas cage incident demonstrates how architecturally robust the structure of the brain is and by comparison how rigid a computer is all mechanical systems and algorithms would stop functioning correctly or completely if an iron rod punctured them that is with the exception of artificial neural systems and their distributed parallel structure in the last decade ai has began to resurge thanks to the promising approach of artificial neural systems
artificial neural systems or simply neural networks are modelled on the logical associations made by the human brain they are based on mathematical models that accumulate data or knowledge based on parameters set by administrators once the network is trained to recognize these parameters it can make an evaluation reach a conclusion and take action in the s neural networks became widely used with the backpropagationalgorithm first described by paul john werbos in the s marked major achievements in many areas of ai and demonstrations of various applications most notably in ibm s deep blue supercomputer defeated the world chess champion garry kasparov after the match kasparov was quoted as saying the computer played like a god
that chess match and all its implications raised profound questions about neural networks many saw it as evidence that true artificial intelligence had finally been achieved after all a man was beaten by a computer in a game of wits but it is one thing to program a computer to solve the kind of complex mathematical problems found in chess it is quite another for a computer to make logical deductions and decisions on its own
using neural networks to emulate brain function provides many positive properties including parallel functioning relatively quick realisation of complicated tasks distributed information weak computation changes due to network damage phineas cage as well as learning abilities i e adaptation upon changes in environment and improvement based on experience these beneficial properties of neural networks have inspired many scientists to propose them as a solution for most problems so with a sufficiently large network and adequate training the networks could accomplish many arbitrary tasks without knowing a detailed mathematical algorithm of the problem currently the remarkable ability of neural networks is best demonstrated by the ability of honda s asimo humanoid robot that cannot just walk and dance but even ride a bicycle asimo an acronym for advanced step in innovative mobility has flexible joints requiring a four processor computer to control its movement and balance its exceptional human like mobility are only possible because the neural networks that are connected to the robot s motion and positional sensors and control its muscle actuators are capable of being taught to do a particular activity
the significance of this sort of robot motion control is the virtual impossibility of a programmer being able to actually create a set of detailed instructions for walking or riding a bicycle instructions which could then be built into a control program the learning ability of the neural network overcomes the need to precisely define these instructions however despite the impressive performance of the neural networks asimo still cannot think for itself and its behaviour is still firmly anchored on the lower end of the intelligent spectrum such as reaction and regulation
neural networks are slowly finding there way into the commercial world recently siemens launched a new fire detector that uses a number of different sensors and a neural network to determine whether the combination of sensor readings are from a fire or just part of the normal room environment such as dust over fifty percent of fire call outs are false and of these well over half are due to fire detectors being triggered by everyday activities as opposed to actual fires so this is clearly a beneficial use of the paradigm
but are there limitations to the capabilities of neural networks or will they be the solution to creating strong ai artificial neural networks are biologically inspired but that does not mean that they are necessarily biologically plausible many scientists have published their thoughts on the intrinsic limitations of using neural networks one book that received high exposure within the computer scientist community in was perceptron byminsky and papert perceptron brought clarity to the limitations of neural networks although many scientists were aware of limited ability of an incomplex perceptron to classify patterns minsky s and papert s approach of finding what are neural networks good for illustrated what is impeding future development of neural networks within its time period perceptron was exceptionally constructive and its identifiable content gave the impetus for later research that conquered some of the depicted computational problems restricting the model an example is the exclusive or problem the exclusive or problem contains four patterns of two inputs each a pattern is a positive member of a set if either one of the input bits is on but not both thus changing the input pattern by one bit changes the classification of the pattern this is the simplest example of a linearly inseparable problem a perceptron using linear threshold functions requires a layer of internal units to solve this problem and since the connections between the input and internal units could not be trained a perceptron could not learn this classification eventually this restriction was solved by incorporating extra hidden layers although advances in neural network research have solved many of the limitations identified by minsky and papert numerous still remain such as networks using linear threshold units still violate the limited order constraint when faced with linearly inseparable problems additionally the scaling of weights as the size of the problem space increases remains an issue
it is clear that the dismissive views about neural networks disseminated by minsky papert and many other computer scientists have some evidential support but still many researchers have ignored their claims and refused to abandon this biologically inspired system
there have been several recent advances in artificial neural networks by integrating other specialised theories into the multi layered structure in an attempt to improve the system methodology and move one step closer to creating strong ai one promising area is the integration of fuzzy logic invented by professor lotfi zadeh other admirable algorithmic ideas include quantum inspired neural networks quinns and network cavitations proposed by s l thaler
the history of artificial intelligence is replete with theories and failed attempts it is in inevitable that the discipline will progress with technological and scientific discoveries but will they ever reach the final hurdle
read more
rent the runway is valued at million and is well on its way to be a unicorn i joined in to bring data science to then a small company of less than individuals in the main office supporting million customers at peak we had two junior data scientists besides me when i left in february this year rtr was serving million customers the membership program that i was a founding member of and returned to last year had grown to nearly half the overall revenue for comparison a membership only competitor has about data scientists currently
scaling is never easy not even for amazon and google but it is certainly harder to do so thoughtfully and with fewer resources
if you work for goofaceapplezon this series likely won t be relevant to you but if you re not read on
in this post i will discuss strategy next one will be about choosing infra and tech and finally i ll talk about models software and importantly the unique challenges of ml tests you will learn something you can apply to your work depending on your seniority and role
data science for retail
this was not an obvious question in but rtr execs knew they were a different breed
like a traditional e commerce company rtr has inventory customers come on site and need recommendations pricing coupons etc all the way to checkout unlike a traditional e commerce however that isn t the end of the story
the dress needs to be shipped out at the event date to do this we have to get the dress from the previous customer who has a probability of being late dry clean it probability of failure and then make sure we can take order for the next person oh and incidentally we happen to be the largest dry cleaners in the world that means supply side logistics with inventory flow from various stations
often called netflix of fashion one notable difference is that the stakes are very high if you watch first minutes and didn t like the movie skip it and your night is not ruined if the dress doesn t work for a customer for that wedding she is going to or is the bride she likely won t come back
rent the runway is a fashion technology engineering supply chain operations reverse logistics dry cleaning analytics business
such problems need custom solutions to scale we needed artisinal hand rolled ml i was brought in due to my previous experience with barnes amp nobles
machine learning at rtr
here are a few data products that i coded and shepherded
carouseled recommendations based on user s style for our membership program
as far as i know the personalized order of carousels and products for fashion is unique to us with hat tip to netflix and spotify it allows for near realtime recommendations and fast personalization to boot i launched this in working days leveraging past work
personalized event recommendations for our a la carte business done with anthony a very talented data scientist now at google maps
you may also like recommendations with anna now etl at spotify
women like me sort to help with fit with kaleigh now google
demand forecasting inventory management price prediction many folk most notably anthony and rob one of the fastest learners i have met
search a dress by image with gabe work travel balance guru and sandy now at google and the browser extension with nizar now at betterment and sandy
using ai to get instagram posts and refine with humans before showing it as a dress review with hindi caroline and sam read about it https sanealytics com human in a i loop
and many more like inventory buying queue solvers warehouse allocation algorithms etc and all that runs every day without needing a lot of upkeep
complexity
the nice thing about working in something that is cool is that everyone wants to help this is a double edged sword
let s say for a certain data project there are only two folk one data scientist and one product person there only needs to be one line of communication things are simple two minds as one
let s add one more person say infra there needs be three lines of communication everyone needs to be in step with everyone else
how about with people turns out we need lines of communication this is a little bit of an exaggeration because not everyone really needs to talk to everyone else but there are still complex dependencies i m a computer scientist first so unfortunately i do o n for fun now what if you add one more person team
take home lesson the complexity of communication increases exponentially proportional to number of teams involved
strive for simplicity
this same analysis can be done for codebase servers etc you will see a recurring theme of preferring simple over complex as far as teams go your natural tendency would be to align with other engineers but if you have to prioritize make sure you spend more time with the product folk
what should you work on
every process begins on the data side of the equation what is worth solving is more important than how well you solve it if it s the right thing the team will be behind you for the hack and the long haul to help figure out a better solution if not this is not worth pursuing find a new problem sorry neural stain identification to speed up dry cleaning
once you are done understanding and analyzing what the problems are you need to pitch them to the business stakeholders i m serious treat it like a vc pitch it needs to something that shows what the potential upside is you have data after all next a quick demo of poc it need only run on your laptop finally you will get resources time on the roadmap and fellow hobbits for the journey
if you haven t had to do this it s because someone has already fought this round for you thank them for they are noble
for user level recommendations five years ago i had to stand an mpp data warehouse mysql gt vertica write some hairy code to ingest large text files and show that there were actually discrete clusters of users i made a r shiny app demo to show what their recos would be i then tested it over email to show a huge lift double digits in click through rate to get folks excited
once the product is on the roadmap align the team on the metric you want to measure your hypothesis is that moving this metric will move the dollars make sure you state it this way and everyone nods on that one metric this exercise eliminates complexity because you can t tune your algo for everything and the business needs to follow why you re harping on about recall
oh btw the english language isn t helpful here but it s what the message needs to be in and repeated over and over again i ve learnt to stay away from accuracy and i can never explain auc in simple english so that rules them out
what you tune for internally is your problem but this is the metric you are asking to be held up to and you need to validate if improving this actually helps the business dollars
protip obsess over this but not too much any metric you choose will be wrong over time so pick one and move on
strategies for kiss keep it simple stupid
this is fantastic you finally have a well defined problem an objective a team this is almost like kaggle now time to impress everyone with that reinforcement learning variational gan you have been aching to try out
no
linear model first i count logistic or its bayesian cousin in the same breath this needs to be the baseline you will beat over time kiss approved
why is this important because in production you have to build a lot more around it we ll come to that in the third post in the series so you need to deploy something end to end that means from getting data training model predicting writing checks shipping those predictions to the right services and measuring the impact via automated reports there is simply too much to build
another little secret when you re competing against humans linear models are already a big enough step up they might give you the for free you ll have to fight a lot harder for the remaining and if you have been successful in creating a virtuous data cycle even this linear model will get better over time simply because your business is growing
this brings to another point data science as it is right now is a research practice things take time they often fail most companies pump a lot of money into hiring expensive phds but don t see the outcome so they get frustrated and scale back on data science set appropriate expectations
you need to separate research from production which is business speak for cannot fail linear models are easy to debug rarely fail and scale very well they also motivate you to go back to it later and demonstratively make it better in terms of revenue with the right model for the problem
and besides you don t even know if the metric you want to improve has any impact on business do you truly understand the problem yet life is cruel
feedback
your model and impact is only as good as the data it has to this end treat ux and product as an extension of what you can optimize your goal should be to validate the metrics and make feedback loops that give you more data
this means you might have to pause a project too for example i had a novel approach to fit recommendations demoed with data extracted by nlp got the green light and small team got working and discovered that we had signal but it wasn t strong enough we could have still launched but decided to hold back and collect more data we redesigned the survey unlimited members take on returning a product to get data for this directly
focus on feedback loops to give you more data
team
you have a success congratulations after the high fives are over where do you invest
this is where a lot of companies go wrong and grow the team too quickly
one data product will have user interfaces on the web app email etc all needing multiple engineers and ux designers to code up it will need more analysts to understand if its driving revenue generate more data that the etl team will need to consume and sanitize and that s just the support system for one little algorithm you coded up
i argue that you need more etl folks analysts and engineers than data science ml this answer won t be appropriate for all stages so take it with a grain of salt
another issue is that apart from long running research dress wear over time data work tends to be spotty a company of engineers can run about projects in one quarter only one of those will likely be the bet on machine learning there are always other competing priorities
your might have engineers and analysis who want to get into data science it is always satisfying to mentor and figure out a problem together however everyone wants to work on recommendation systems or image processing so it takes a lot of conversations to find a good problem their interests are aligned in they are excited to work on and is a business question that potentially has an impact too hard a problem predict churn needs understanding a lot of variables can kill the enthusiasm of a fledging data scientist if you notice above all the projects have a co pilot who maintain the product once its out in the wild focus on working with only one person for that data product keep n small
downtimes are also a good time to go back and better those models go ahead and try those neural nets now but most of your time should go into finding what the next most important problem to work on is don t get attached to a problem there are lots of low hanging fruit quantify impact in dollars and see if its worth pitching
a big caveat is hiring it is unlikely you will find the same person who can do everything i was the single point of failure for rtr for many years which is obviously undesirable it is easier to find folks with different skills that make the team have all the required talent again these skills won t be obvious when you start so don t grow too quickly but definitely try to build redundancy as you scale
i ran into issues hiring who to lead the etl team for a relatively unknown rtr at the time it took me an year to find the right candidate who happened to be an extremely talented homegrown aspiring data scientist and found that she enjoyed etl more the answer was always complementary skill members
so maybe look for both you might be forced into one of those options if you are not known for data science one funny thing is that graphic designers want to work at apple which already has great ux not say amazon people don t always see the open green fields
partner with non engineers i started an internal rtr deepdress team comprising of all folks in the company curious about applying ai to fashion problems the browser extension instagram and some other product ideas came from that ux designers were more than happy to work on this because they were involved at ideation
good ideas come from everywhere refine
good fences make good neighbors
rtr s backend is standardized to java i had originally written my models in c with r for analysis python data munging was nonexistent in i then moved to write them in java or scala my preference at the time to integrate with products engineering was building the upside was that all i d be writing is a class and the data glue etc is all in engineering s domain so barrier to entry was small
that was a mistake
for one every model needs to be re coded into java which is not fun second once deployed you lose control over it changing the model now means testing the entire service and that s not going to happen unless it is someone s project
the correct way is to treat ml as saas even though it s an internal team i ve slept better since
so we need slas notably the top few are
this looks pretty horrible no cto will sign off on this contract and remember she is one of your investors so you need that
the first strategy is separation of concerns kiss approved
for engineering this means that they don t need to understand the model the runbook says restart and upon startup the service will pick up the previous version of the model which presumably worked a few hours ago no one should have to debug ml code at am also incidentally you get to sleep in because it s not really a problem if it heals itself
for the etl team this means that we will create data transformation jobs schedule and handoff to them any ongoing maintenance from that point will be theirs
second strategy for this is to code for reliability via checks and tests if anything fails the model deploy should fail sorry for the teaser but i will talk about in part
third figure out graceful fallbacks and fallbacks to those fallbacks for example if someone comes to the homepage whose recommendations we haven t computed what should they see new item who should it be recommended to if the service is down what should they see
caching is a strategy here but there is major caveats for example you want the engineering service to cache the unknown user s recommendations every now and then but if the recos now compute and the user is now known you need to tell the engineering service to invalidate it
another problem is synchronization amongst servers if one server knows it as one user and another has previous recos refresh of the same page by the customer would give her different set of products an undesirable experience
partner with your engineering buddies and involve them this is fun stuff and ultimately they have to maintain it
fourth deploy daily hourly continuously this is because your automated tests checks are only as good as you run them and a small team is unlikely to re run the model from last year and will absolutely hate to debug an issue that originally happened months ago but no one noticed till now a continuous deploy will catch the problem when it happens and will revert because of the above fallback mechanism
another reason is to catch the more insidious problems sometimes upstream data new feature something else unknown to you will break your model catch them when they happen
fifth whatever tech model language you choose will be out of fashion next month data science is a fast moving field and even in deep learning there have been at least different libraries last year so design for parts to be switchable we have things running in r c python and scala i ll talk about this more in second and third parts of the series
sixth ml can t solve everything hopefully you have caught these edge cases during the model build phase large sizes low inventory low history etc sometimes you will rightly ignore the problem because it might not be too big or put guardrails around it ideal either way though it needs to be surfaced on a report
this brings me to seventh and final strategy for this post what gets measured gets fixed alternatively make it someone else s problem one off complicated data products depending on data that only that product uses is a recipe for disaster keep the data model consistent with what someone else is using view of customers products etc this way when they find an issue and fix it your problem will get fixed as well
at the very least make a report that tracks the metric that you agreed on and actual business impact see if the metric still tracks that this should be on a report that folks regularly use so you don t have to
i am now working on my own retail ai startup virevol currently hiring for product sales ux front end engineers and ml of course i usually write on https sanealytics com and tweet at https twitter com analyticsaurabh
a very short version of this was given as a talk in gtc nvidia s ai conference upon encouragement from nikolai yakovenko i have turned it into a series of blog posts
see you next time
making palatable meaningful data products from terabytes of data ai ml stats sr data scientist at rent the runway previously barnes amp nobles unilever
deeplearning ai announcing new deep learning courses on coursera
dear friends
i have been working on three new ai projects and am thrilled to announce the first one deeplearning ai a project dedicated to disseminating ai knowledge is launching a new sequence of deep learning courses on coursera these courses will help you master deep learning apply it effectively and build a career in ai
ai is the new electricity
just as electricity transformed every major industry starting about years ago ai is now poised to do the same several large tech companies have built ai divisions and started transforming themselves with ai but in the next few years companies of all sizes and across all industries will realize that they too must be part of this ai powered future
building an ai powered society
i hope we can build an ai powered society that gives everyone affordable healthcare provides every child a personalized education makes inexpensive self driving cars available to all and provides meaningful work for every man and woman an ai powered society that improves every person s life
but no single company can do all the work needed to get us there just as every new cs graduate now knows how to use the cloud every programmer in the future must know how to use ai there are millions of ways deep learning can be used to improve human life so society needs millions of you from all around the world to build great ai systems regardless of whether you are an aspiring software engineer in california a research scientist in china or an ml engineer in india i want you to be able to use deep learning to solve the world s challenges
what you will learn
anyone with basic machine learning knowledge can take this sequence of five courses which make up coursera s new deep learning specialization
you will learn the foundations of deep learning understand how to build neural networks and learn how to lead successful machine learning projects you will learn about convolutional networks rnns lstm adam dropout batchnorm xavier he initialization and more you will work on case studies from healthcare autonomous driving sign language reading music generation and natural language processing you will master not only the theory but also see how it is applied in industry you will practice all these ideas in python and in tensorflow you will also hear from many top leaders in deep learning who will share with you their personal stories and give you career advice
when you earn a deep learning specialization certificate you will be able to confidently put deep learning onto your resume
join me to build an ai powered society
million people have enrolled in my machine learning class since when four stanford students and i launched what subsequently became coursera s first course since then i have been inspired by many of you who have worked hard to understand machine learning built wonderful ai systems and developed amazing careers i hope the deep learning specialization will help you build even more amazing things let you help society even more and go even further in your career
i hope you will join forces with me to build an ai powered society
i will also keep you informed as my other two ai projects develop and will keep looking for ways to support all of you in the global ai community
andrew
ai machine learning deep learning online education
dear friends
drive ai will offer a self driving car service for public use in frisco texas starting in july
self driving cars are no longer a futuristic ai technology they re here and will soon make transportation cheaper and more convenient
the team at drive ai has been working closely with local partners to ensure the deployment of our cars is safe and adds real value to its day to day users
providing a public self driving car service depends on three key elements
self driving technology is still challenging it requires highly skilled ai teams as well as sophisticated software and hardware architectures
drive ai has always had a strong technical team its founders include many ai graduate students from my group at stanford university as well as carol reiley my spouse comprised of deep learning natives the team has designed a self driving architecture using modern ai from the ground up
further by developing the full software stack for self driving in house perception motion planning mapping localization fleet management software mobile app communications our tele choice remote assistance system and more the team is able to move quickly and resolve any dependencies between systems
self driving cars should be deployed in geofenced areas in partnership with governments and private parties to ensure safe smooth operations that add value to its day to day users
as a skilled ai team drive ai has a clear eyed view of ai s limitations the team knows how to build realistic solutions within the current technology s limitations
for example no self driving team has a realistic roadmap to reliably interpret the hand gestures of a construction worker waving for a car to proceed computer vision just isn t good enough yet thus we are partnering with governments and private parties to deploy in geofenced regions where we can find other ways for construction workers to communicate with our fleet operations team
drive ai is particularly grateful to frisco s mayor jeff cheney frisco tma and nctcog s michael morris for their partnership working together our initial pilot will be a six month deployment on a driving route from hall park to an entertainment retail area the star with a planned expansion into frisco station
deploying local on demand shuttle routes benefits everyone office workers can grab lunch without having to drive and look for parking and local business owners can attract more customers a self driving service will boost local commerce reduce traffic jams and lessen the need for parking lots we also aim to unlock access to areas underserved by traditional mass transit and improve connectivity to existing transit lines thoughtful self driving deployments can increase mass transit ridership and reduce individual car usage thus driving down a city s transportation costs
the industry must take a human centered approach to safety taking into account both people inside and outside the car and emphasize communications and community education
whether a self driving car is safe depends not only on the behavior of the car itself but also on the behavior of the people around it it is unwise to rely exclusively on ai technology to ensure safety instead the self driving industry also has to think about the people who will be outside the vehicle which is why we will be undertaking community wide education and training programs where we operate
it is every self driving company s responsibility to ensure safety we believe the self driving car industry should adopt these practices
we deliberately prioritized recognizability over beauty since it is recognizability that enhances safety
in the first phase drive ai will deploy vehicles with safety drivers in texas we are also deploying our tele choice technology to provide a high level of safety and ride comfort for example say our vehicle wants to execute a tricky maneuver at an intersection if it determines that it needs human insight for an additional layer of safety it will first pull to a stop then seek input from a remote operator to proceed over time our deep learning system learns from these cases and improves automatically unlike remote driving where a tele choice operator controls the car directly our tele choice system is designed to be robust to network latency and temporary network outages taking into account even small edge cases like automatically invalidating stale data or requests lagging by ms
in the second phase when road tests show it is safe to do so drive ai will operate with chaperones rather than safety drivers alongside tele choice operators the chaperone will sit in a passenger seat and be available to assist passengers and monitor operations but they will not be expected to take over in a split second
in the final phase we will operate with only passengers in the vehicle assisted remotely by tele choice operators one tele choice operator will be able to monitor multiple vehicles thus enabling more scalable deployments of self driving
there is still much work to be done but the future of self driving is clear
self driving cars have different strengths and weaknesses than human drivers they are always attentive have lt ms reaction times and have no blind spots on the flip side they don t understand certain complex situations such as a construction worker communicating using hand gestures by choosing geofenced regions and working with partners we can take advantage of self driving cars strengths while diminishing their weaknesses with these strategies the self driving industry will be able to deploy safe and valuable transportation services
i remember attending the darpa urban challenge in and seeing the wonderful work of stanford university cmu and many other pioneering self driving teams our work builds on that rich legacy
it is now over a decade later i am thrilled that self driving cars are finally here
to learn more about drive ai s work to advance self driving head to drive ai
andrew ng
ai machine learning deep learning online education
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
user agent disallow m disallow me disallow me disallow me disallow edit disallow edit disallow r disallow t allow allow api users meta allow api users profile stream allow api posts responses allow api posts responsesstream allow api posts related sitemap https machinelearnings co sitemap sitemap xml
file not found
the site configured at this address does not contain the requested file
if this is your site make sure that the filename case matches the url for root urls like http example com you must provide an index html file
read the full documentation for more information about using github pages
